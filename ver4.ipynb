{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa53ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# %pip install langchain langchain_community langchain_openai neo4j python-dotenv pypdf tiktoken\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cae8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (ensure NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, OPENAI_API_KEY are set in your .env file)\n",
    "load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Embedding model setup\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)\n",
    "embedding_dimension = 1536 # Dimension for text-embedding-3-small\n",
    "\n",
    "# Data paths\n",
    "pdf_path = './dataset/criminal-law.pdf'\n",
    "precedent_dir = './dataset/precedent_label/' # Directory containing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cd2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 194 articles from PDF.\n",
      "\n",
      "--- Example Article: 제1조(범죄의 성립과 처벌) ---\n",
      "제1조(범죄의 성립과 처벌) ①범죄의 성립과 처벌은 행위 시의 법률에 의한다.\n",
      "②범죄 후 법률의 변경에 의하여 그 행위가 범죄를 구성하지 아니하거나 형이 구법보다 경한\n",
      "때에는 신법에 의한다.\n",
      "③재판확정 후 법률의 변경에 의하여 그 행위가 범죄를 구성하지 아니하는 때에는 형의 집행\n",
      "을 면제한다.\n",
      " \n",
      "제2조(국내범)제2조(국내범) 본법은 대한민국영역 내에서 죄를 범한 내국인과 외국인에게 적용한다.\n",
      " \n",
      "제3조(내국인의 국외범)제3조(내국인의 국외범) 본법은 대한민국영역 외에서 죄를 범한 내국인에게 적용한다.\n",
      " \n",
      "제4조(국외에 있는 내국선박 등에서 외국인이 범한 죄)제4조(국외에 있는 내국선박 등에서 외국인이 범한 죄) 본법은 대한민국영역 외에 있는 대한민\n",
      "국의 선박 또는 항공기 내에서 죄를 범한 외국인에게 적용한다.\n",
      " \n",
      "제5조(외국인의 국외범)제5조(외국인의 국외범)...\n"
     ]
    }
   ],
   "source": [
    "# # Load PDF\n",
    "# loader = PyPDFLoader(pdf_path)\n",
    "# # pages = loader.load()[2:] # Skip first two pages as before\n",
    "# pages = loader.load()\n",
    "# full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "# # Text Splitter (refined for graph structure)\n",
    "# # We'll primarily focus on splitting by Article for node creation\n",
    "# # article_pattern_precise = re.compile(r'(제\\d+조(?:의\\d+)?\\s*\\(.+?\\))\\s*') # More precise pattern to capture article header\n",
    "\n",
    "# article_pattern_precise = re.compile(r'(제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?)')\n",
    "\n",
    "# separators = [\n",
    "#     # r\"(제\\d+조(?:의\\d+)?\\s*\\(.+?\\))\", # 조 (Article) - Primary separator\n",
    "#     r\"(제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?)\",\n",
    "#     r\"(제\\d+장 [^\\\\n]+)\",             # 장 (Chapter)\n",
    "#     r\"(제\\d+편 [^\\\\n]+)\",             # 편 (Edition)\n",
    "#     \"\\n\\n\",                         # Paragraph\n",
    "#     \"\\n\",                           # Line break\n",
    "#     \" \",                            # Space\n",
    "# ]\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=500, # Adjust as needed\n",
    "#     chunk_overlap=150, # Adjust as needed\n",
    "#     length_function=len,\n",
    "#     separators=separators,\n",
    "#     is_separator_regex=True,\n",
    "# )\n",
    "\n",
    "# raw_chunks = text_splitter.split_text(full_text)\n",
    "\n",
    "# # Process chunks to associate content with articles\n",
    "# articles = {}\n",
    "# current_article_id = None\n",
    "# current_content = \"\"\n",
    "\n",
    "# for chunk in raw_chunks:\n",
    "#     match = article_pattern_precise.search(chunk)\n",
    "#     if match:\n",
    "#         # If we encounter a new article, save the previous one (if any)\n",
    "#         if current_article_id:\n",
    "#             articles[current_article_id] = current_content.strip()\n",
    "\n",
    "#         # Start the new article\n",
    "#         current_article_id = match.group(1).strip()\n",
    "#         # Remove the matched article header from the beginning of the chunk content\n",
    "#         current_content = article_pattern_precise.sub(\"\", chunk, count=1)\n",
    "#     else:\n",
    "#         # Append chunk content to the current article\n",
    "#         if current_article_id: # Only append if we are already inside an article\n",
    "#              current_content += \"\\n\" + chunk\n",
    "\n",
    "# # Save the last processed article\n",
    "# if current_article_id:\n",
    "#     articles[current_article_id] = current_content.strip()\n",
    "\n",
    "\n",
    "# print(f\"Processed {len(articles)} articles from PDF.\")\n",
    "# # Example: Print the first processed article\n",
    "# if articles:\n",
    "#     first_article_id = list(articles.keys())[0]\n",
    "#     print(f\"\\n--- Example Article: {first_article_id} ---\")\n",
    "#     print(articles[first_article_id][:500] + \"...\")\n",
    "\n",
    "# # Convert to Document objects for potential later use or consistency\n",
    "# article_docs = [Document(page_content=content, metadata={\"article_id\": article_id}) for article_id, content in articles.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d6ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 548 articles from PDF.\n",
      "\n",
      "\n",
      "=== 마지막 10개 조항 ===\n",
      "\n",
      "--- Article: 제4조 (형에 관한 경과조치) ---\n",
      "제4조 (형에 관한 경과조치) 이 법 시행전에 종전의 형법규정에 의하여 형의 선고를 받은 자는\n",
      "이 법에 의하여 형의 선고를 받은 것으로 본다. 집행유예 또는 선고유예를 받은 경우에도 이와\n",
      "같다.\n",
      "\n",
      "--- Article: 제5조 (다른 법령과의 관계) ---\n",
      "제5조 (다른 법령과의 관계) 이 법 시행당시 다른 법령에서 종전의 형법 규정(장의 제목을 포함\n",
      "한다)을 인용하고 있는 경우에 이 법중 그에 해당하는 규정이 있는 때에는 종전의 규정에 갈음\n",
      "하여 이 법의 해당 조항을 인용한 것으로 본다.\n",
      "  \n",
      "부칙 <제5454호,1997.12.13>\n",
      "이 법은 1998년 1월 1일부터 시행한다. <단서 생략>\n",
      "  \n",
      "부칙 <제...\n",
      "\n",
      "--- Article: 제7조 ---\n",
      "제7조(제2항 및 제29항\n",
      "을 제외한다)의 규정은 2008년 1월 1일부터 시행한다.\n",
      "\n",
      "--- Article: 제2조 ---\n",
      "제2조 내지\n",
      "\n",
      "--- Article: 제6조 ---\n",
      "제6조 생략\n",
      "\n",
      "--- Article: 제7조 (다른 법률의 개정) ---\n",
      "제7조 (다른 법률의 개정) ①내지 <26>생략\n",
      "<27>형법 일부를 다음과 같이 개정한다.\n",
      "\n",
      "--- Article: 제151조 ---\n",
      "제151조제2항 및\n",
      "\n",
      "--- Article: 제155조 ---\n",
      "제155조제4항중 \"친족, 호주 또는 동거의 가족\"을 각각 \"친족 또는 동거의\n",
      "가족\"으로 한다.\n",
      "\n",
      "--- Article: 제305조의2 ---\n",
      "제305조의2의 개정규정은\n",
      "공포한 날부터 시행한다.\n",
      "②(가석방의 요건에 관한 적용례)\n",
      "\n",
      "--- Article: 제72조 ---\n",
      "제72조제1항의 개정규정은 이 법 시행 당시 수용 중인 사람에\n",
      "대하여도 적용한다.\n",
      "형법\n",
      " 제 작 자   :송진아\n",
      "메일주소  :blue4890@hanmail.net\n",
      "제작일자  :2013.11.8\n",
      " 법제처 국가법령정보센터\n"
     ]
    }
   ],
   "source": [
    "# 청킹이 아닌 정규식 패턴 매칭으로 각 조항 추출하기\n",
    "import re\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "# pages = loader.load()[2:] # Skip first two pages as before\n",
    "pages = loader.load()\n",
    "full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "# 전체 텍스트에서 모든 조항 시작 위치 찾기\n",
    "article_pattern = r'제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?'\n",
    "matches = list(re.finditer(article_pattern, full_text))\n",
    "\n",
    "articles = {}\n",
    "for i in range(len(matches)):\n",
    "    current_match = matches[i]\n",
    "    current_article_id = current_match.group(0).strip()  # 현재 조항 ID\n",
    "    \n",
    "    # 현재 조항 시작 위치\n",
    "    start_pos = current_match.start()\n",
    "    \n",
    "    # 다음 조항 시작 위치 (없으면 텍스트 끝까지)\n",
    "    end_pos = matches[i+1].start() if i < len(matches)-1 else len(full_text)\n",
    "    \n",
    "    # 현재 조항의 전체 내용 (ID 포함)\n",
    "    article_text = full_text[start_pos:end_pos].strip()\n",
    "    \n",
    "    # 저장 (ID는 조항 번호만)\n",
    "    articles[current_article_id] = article_text\n",
    "\n",
    "print(f\"Processed {len(articles)} articles from PDF.\")\n",
    "\n",
    "# 예시 출력\n",
    "if articles:\n",
    "    article_ids = list(articles.keys())\n",
    "    # print(\"\\n=== 처음 5개 조항 ===\")\n",
    "    # for i in range(min(5, len(article_ids))):  # 처음 5개 조항만 출력\n",
    "    #     article_id = article_ids[i]\n",
    "    #     content = articles[article_id]\n",
    "    #     print(f\"\\n--- Article: {article_id} ---\")\n",
    "    #     print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "        \n",
    "        \n",
    "        # 마지막 10개 조항 출력\n",
    "    print(\"\\n\\n=== 마지막 10개 조항 ===\")\n",
    "    for i in range(max(0, len(article_ids) - 10), len(article_ids)):\n",
    "        article_id = article_ids[i]\n",
    "        content = articles[article_id]\n",
    "        print(f\"\\n--- Article: {article_id} ---\")\n",
    "        print(content[:200] + \"...\" if len(content) > 200 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc2353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5404 precedents.\n",
      "\n",
      "--- Example Precedent ---\n",
      "{\n",
      "  \"case_id\": \"88도2209\",\n",
      "  \"case_name\": \"매장및묘지등에관한법률위반, 사문서위조, 동행사, 조세범처벌법위반, 특정범죄가중처벌등에관한법률위반\",\n",
      "  \"judgment_summary\": \"가. 작성명의자의 인영이나 주민등록번호의 등재가 누락된 문서가 사문서위조죄의 객체인 사문서에 해당하는지 여부\\n나. 사문서위조 및 동행사죄가 조세범처벌법 제9조 소정의 조세포탈의 수단으로 행해진 경우 후자의 죄에 흡수되는지 여부(소극)\",\n",
      "  \"full_summary\": \"사문서의 작성명의자의 인장이 압날되지 아니하고 주민등록번호가 기재되지 않았다고 하더라도, 일반인으로 하여금 그 작상명의자가 진정하게 작성한 사문서로 믿기에 충분할 정도의 형식과 외관을 갖추었으면 사문서위조죄 및 동행사죄의 객체가 되는 사문서라고 보아야 할 것이고, 사문서위조 및 동행사죄가 조세범처벌법 제9조 제1항 소정의 “사기 기타 부정한 행위로써 조세를 포탈”하기 위한 수단으로 행하여졌다고 하여 조세범처벌법 제9조 소정의 조세포탈죄에 흡수된다고 볼 수도 없는 것이므로, 논지는 이유가 없다.\",\n",
      "  \"keywords\": [\n",
      "    \"사문서위조\",\n",
      "    \"동행사\"\n",
      "  ],\n",
      "  \"referenced_rules\": [\n",
      "    \"제9조\",\n",
      "    \"제37조\",\n",
      "    \"제231조\",\n",
      "    \"제234조\"\n",
      "  ],\n",
      "  \"referenced_cases\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load precedent JSON files\n",
    "precedents = []\n",
    "for filename in os.listdir(precedent_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(precedent_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # Extract relevant fields\n",
    "                precedent_info = {\n",
    "                    \"case_id\": data.get(\"info\", {}).get(\"caseNoID\", filename.replace(\".json\", \"\")),\n",
    "                    \"case_name\": data.get(\"info\", {}).get(\"caseNm\"),\n",
    "                    \"judgment_summary\": data.get(\"jdgmn\"),\n",
    "                    \"full_summary\": \" \".join([s.get(\"summ_contxt\", \"\") for s in data.get(\"Summary\", [])]),\n",
    "                    \"keywords\": [kw.get(\"keyword\") for kw in data.get(\"keyword_tagg\", []) if kw.get(\"keyword\")],\n",
    "                    \"referenced_rules\": data.get(\"Reference_info\", {}).get(\"reference_rules\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_rules\") else [],\n",
    "                    \"referenced_cases\": data.get(\"Reference_info\", {}).get(\"reference_court_case\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_court_case\") else [],\n",
    "                }\n",
    "                # Clean up referenced rules (extract article numbers)\n",
    "                cleaned_rules = []\n",
    "                rule_pattern = re.compile(r'제\\d+조(?:의\\d+)?') # Pattern to find \"제X조\" or \"제X조의Y\"\n",
    "                for rule in precedent_info[\"referenced_rules\"]:\n",
    "                    # Find all matches in the rule string\n",
    "                    matches = rule_pattern.findall(rule.strip())\n",
    "                    cleaned_rules.extend(matches)\n",
    "                precedent_info[\"referenced_rules\"] = list(set(cleaned_rules)) # Keep unique article numbers\n",
    "\n",
    "                precedents.append(precedent_info)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not decode JSON from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(precedents)} precedents.\")\n",
    "# Example: Print the first loaded precedent\n",
    "if precedents:\n",
    "    print(\"\\n--- Example Precedent ---\")\n",
    "    print(json.dumps(precedents[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b4b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 1000 precedents out of 5404 total precedents.\n"
     ]
    }
   ],
   "source": [
    "# 로드된 판례 중 무작위로 1,000개만 선택\n",
    "import random\n",
    "random.seed(42)  # 재현성을 위한 시드 설정 (선택사항)\n",
    "\n",
    "# 전체 판례 수 저장\n",
    "total_precedents = len(precedents)\n",
    "\n",
    "# 무작위로 1,000개 선택 (또는 전체 판례 수가 1,000개보다 적다면 모두 선택)\n",
    "sample_size = min(1000, total_precedents)\n",
    "precedents = random.sample(precedents, sample_size)\n",
    "\n",
    "print(f\"Randomly selected {len(precedents)} precedents out of {total_precedents} total precedents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af35f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Neo4j.\n",
      "Article vector index created or already exists.\n",
      "Precedent vector index created or already exists.\n",
      "Waiting for indexes to populate...\n",
      "Indexes should be online.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Successfully connected to Neo4j.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Neo4j: {e}\")\n",
    "    # Stop execution if connection fails\n",
    "    raise\n",
    "\n",
    "# Create constraints and indexes for faster lookups and embedding search\n",
    "def setup_neo4j(driver, dimension):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # Constraints for uniqueness\n",
    "        session.run(\"CREATE CONSTRAINT article_id IF NOT EXISTS FOR (a:Article) REQUIRE a.id IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT precedent_id IF NOT EXISTS FOR (p:Precedent) REQUIRE p.id IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT keyword_text IF NOT EXISTS FOR (k:Keyword) REQUIRE k.text IS UNIQUE\")\n",
    "\n",
    "        # Vector index for Articles\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX article_embedding IF NOT EXISTS \"\n",
    "                \"FOR (a:Article) ON (a.embedding) \"\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "            )\n",
    "            print(\"Article vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Article vector index (may require Neo4j 5.11+ and APOC): {e}\")\n",
    "            print(\"Continuing without vector index creation for Article.\")\n",
    "\n",
    "\n",
    "        # Vector index for Precedents\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX precedent_embedding IF NOT EXISTS \"\n",
    "                \"FOR (p:Precedent) ON (p.embedding) \"\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "            )\n",
    "            print(\"Precedent vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Precedent vector index (may require Neo4j 5.11+ and APOC): {e}\")\n",
    "            print(\"Continuing without vector index creation for Precedent.\")\n",
    "\n",
    "        # Wait for indexes to come online (important!)\n",
    "        print(\"Waiting for indexes to populate...\")\n",
    "        session.run(\"CALL db.awaitIndexes(300)\") # Wait up to 300 seconds\n",
    "        print(\"Indexes should be online.\")\n",
    "\n",
    "\n",
    "setup_neo4j(driver, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091dcd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 548 Article nodes...\n",
      "  Processed 50/548 articles...\n",
      "  Processed 100/548 articles...\n",
      "  Processed 150/548 articles...\n",
      "  Processed 200/548 articles...\n",
      "  Processed 250/548 articles...\n",
      "  Processed 300/548 articles...\n",
      "  Processed 350/548 articles...\n",
      "  Processed 400/548 articles...\n",
      "  Processed 450/548 articles...\n",
      "  Processed 500/548 articles...\n",
      "Finished creating 548 Article nodes in 398.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Article nodes and generate/store embeddings\n",
    "def create_article_nodes(driver, articles_dict, embed_model):\n",
    "    print(f\"Creating {len(articles_dict)} Article nodes...\")\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for article_id, content in articles_dict.items():\n",
    "            if not content: # Skip empty content\n",
    "                print(f\"Skipping article {article_id} due to empty content.\")\n",
    "                continue\n",
    "            try:\n",
    "                # Generate embedding\n",
    "                embedding = embed_model.embed_query(content)\n",
    "\n",
    "                # Create node in Neo4j\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (a:Article {id: $article_id})\n",
    "                    SET a.text = $content,\n",
    "                        a.embedding = $embedding\n",
    "                    \"\"\",\n",
    "                    article_id=article_id,\n",
    "                    content=content,\n",
    "                    embedding=embedding\n",
    "                )\n",
    "                count += 1\n",
    "                if count % 50 == 0:\n",
    "                    print(f\"  Processed {count}/{len(articles_dict)} articles...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article {article_id}: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished creating {count} Article nodes in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "create_article_nodes(driver, articles, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881f8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1000 Precedent nodes and relationships...\n",
      "  Processed 100/1000 precedents...\n",
      "  Processed 200/1000 precedents...\n",
      "  Processed 300/1000 precedents...\n",
      "  Processed 400/1000 precedents...\n",
      "  Processed 500/1000 precedents...\n",
      "  Processed 600/1000 precedents...\n",
      "  Processed 700/1000 precedents...\n",
      "  Processed 800/1000 precedents...\n",
      "  Processed 900/1000 precedents...\n",
      "  Processed 1000/1000 precedents...\n",
      "Finished creating 1000 Precedent nodes and relationships in 1316.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Precedent nodes, Keyword nodes, and relationships\n",
    "def create_precedent_nodes_and_relationships(driver, precedents_list, embed_model):\n",
    "    print(f\"Creating {len(precedents_list)} Precedent nodes and relationships...\")\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for precedent in precedents_list:\n",
    "            # Use full_summary for embedding, or judgment_summary if full is empty\n",
    "            text_to_embed = precedent.get(\"full_summary\") or precedent.get(\"judgment_summary\")\n",
    "            if not text_to_embed:\n",
    "                print(f\"Skipping precedent {precedent.get('case_id')} due to empty summary.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Generate embedding\n",
    "                embedding = embed_model.embed_query(text_to_embed)\n",
    "\n",
    "                # Create Precedent node\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (p:Precedent {id: $case_id})\n",
    "                    SET p.name = $case_name,\n",
    "                        p.judgment_summary = $judgment_summary,\n",
    "                        p.full_summary = $full_summary,\n",
    "                        p.embedding = $embedding\n",
    "                    \"\"\",\n",
    "                    case_id=precedent[\"case_id\"],\n",
    "                    case_name=precedent[\"case_name\"],\n",
    "                    judgment_summary=precedent[\"judgment_summary\"],\n",
    "                    full_summary=precedent[\"full_summary\"],\n",
    "                    embedding=embedding\n",
    "                )\n",
    "\n",
    "                # Create Keyword nodes and relationships\n",
    "                for keyword_text in precedent[\"keywords\"]:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (k:Keyword {text: $keyword_text})\n",
    "                        WITH k\n",
    "                        MATCH (p:Precedent {id: $case_id})\n",
    "                        MERGE (p)-[:HAS_KEYWORD]->(k)\n",
    "                        \"\"\",\n",
    "                        keyword_text=keyword_text,\n",
    "                        case_id=precedent[\"case_id\"]\n",
    "                    )\n",
    "\n",
    "                # Create relationships to referenced Articles\n",
    "                # Note: This uses the cleaned article IDs extracted earlier\n",
    "                # It tries to match based on the \"제X조\" format.\n",
    "                for article_id_ref in precedent[\"referenced_rules\"]:\n",
    "                     # Find Article nodes that START WITH the referenced ID (e.g., \"제21조\" should match \"제21조(정당방위)\")\n",
    "                     # This is less precise but necessary if the exact title isn't in the reference.\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (p:Precedent {id: $case_id})\n",
    "                        MATCH (a:Article)\n",
    "                        WHERE a.id STARTS WITH $article_id_ref\n",
    "                        MERGE (p)-[:REFERENCES_ARTICLE]->(a)\n",
    "                        \"\"\",\n",
    "                        case_id=precedent[\"case_id\"],\n",
    "                        article_id_ref=article_id_ref # Use the extracted \"제X조\"\n",
    "                    )\n",
    "\n",
    "                # Potential: Create relationships to other referenced Precedents (if needed)\n",
    "                # for ref_case_id in precedent[\"referenced_cases\"]:\n",
    "                #    session.run(...) # MERGE (p)-[:REFERENCES_CASE]->(other_p:Precedent {id: ref_case_id})\n",
    "\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"  Processed {count}/{len(precedents_list)} precedents...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing precedent {precedent.get('case_id')}: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished creating {count} Precedent nodes and relationships in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "create_precedent_nodes_and_relationships(driver, precedents, embedding_model)\n",
    "\n",
    "# Close the driver connection when done\n",
    "# driver.close() # Keep it open for querying in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d358b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying RAG for: '정당방위의 요건은 무엇인가?' ---\n",
      "Query completed in 1.72 seconds.\n",
      "\n",
      "--- Top Results ---\n",
      "1. Type: Precedent, ID: 92도2540, Score: 0.7387\n",
      "   Name: 살인\n",
      "   Keywords: ['타인의 법익', '상당한 이유']\n",
      "   Referenced Articles: ['제10조(심신장애자)', '제21조(정당방위)', '제308조(사자의 명예훼손)', '제308조', '제10조 (폐지되는 법률등)']\n",
      "   Text Preview: 정당방위의 성립요건으로서의 방어행위에는 순수한 수비적 방어뿐 아니라 적극적 반격을 포함하는 반격방어의 형태도 포함됨은 소론과 같다고 하겠으나, 그 방어행위는 자기 또는 타인의 법익침해를 방위하기 위한 행위로서 상당한 이유가 있어야 하는 것인데, 피고인들의 판시 행위가 위에서 본 바와 같이 그 상당성을 결여한 것인 이상 정당방위행위로 평가될 수는 없는 것이므로, 원심이 피고인들의 이 사건 범행이 현재의 부당한 침해를 방위할 의사로 행해졌다기보다는 공격의 의사로 행하여졌다고 인정한 것이 적절하지 못하다고 하더라도, 정당방위행위가 되지 ...\n",
      "--------------------\n",
      "2. Type: Precedent, ID: 2009도2114, Score: 0.6939\n",
      "   Name: 특수공무집행방해[변경된죄명:폭력행위등처벌에관한법률위반(공동폭행)]\n",
      "   Keywords: ['사회상규에 위배', '소극적인 방어행위']\n",
      "   Referenced Articles: ['제6조(대한민국과 대한민국 국민에 대한 국외범)', '제20조(정당행위)', '제21조(정당방위)', '제136조(공무집행방해)', '제136조', '제260조(폭행, 존속폭행)', '제260조', '제6조 (경합범에 대한 신법의 적용례)', '제6조']\n",
      "   Text Preview: 비록 경찰관들의 위법한 상경 제지 행위에 대항하기 위하여 한 것이라 하더라도, 피고인들이 다른 시위참가자들과 공동하여 위와 같이 경찰관들을 때리고 진압방패와 채증장비를 빼앗는 등의 폭행행위를 한 것은 소극적인 방어행위를 넘어서 공격의 의사를 포함하여 이루어진 것으로서 그 수단과 방법에 있어서 상당성이 인정된다고 보기 어려우며 긴급하고 불가피한 수단이었다고 볼 수도 없으므로, 이를 사회상규에 위배되지 아니하는 정당행위나 현재의 부당한 침해를 방어하기 위한 정당방위에 해당한다고 볼 수 없다.\n",
      "그럼에도 불구하고, 원심은 그 판시와 같은 ...\n",
      "--------------------\n",
      "3. Type: Precedent, ID: 83누383, Score: 0.6789\n",
      "   Name: 영업정지처분무효확인\n",
      "   Keywords: ['법령 위반행위']\n",
      "   Referenced Articles: ['제1조(범죄의 성립과 처벌)', '제34조(간접정범, 특수한 교사, 방조에 대한 형의 가중)', '제37조(경합범)', '제38조(경합범과 처벌례)', '제34조', '제1조 (구형법 기타 법령과 형의 경중)', '제1조 (시행일)']\n",
      "   Text Preview: 정당한 절차에 의하지 않고 구두에 의한 하도급계약을 체결하여 공사를 시작한 때에건설업법 제34조 제3항의 위반행위를 범한 것이 되니 그 위반행위를 이유로 한 행정상의 제재처분(행위당시에는 필요적 취소사유)을 하려면 그 위반행위 이후 법령의 변경에 의하여 처분의 종류를 달리(영업정지 사유로) 규정하였다 하더라도 그 법률적용에 관한특별한 규정이 없다면 위반행위 당시에 시행되던 법령을 근거로 처분을 하여야 마땅하다....\n",
      "--------------------\n",
      "\n",
      "Neo4j driver closed.\n"
     ]
    }
   ],
   "source": [
    "# Example RAG query using vector similarity search\n",
    "def query_graph_rag(driver, query_text, embed_model, top_k=3):\n",
    "    print(f\"\\n--- Querying RAG for: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "\n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # Find similar Articles\n",
    "        try:\n",
    "            article_res = session.run(\n",
    "                \"\"\"\n",
    "                CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) YIELD node, score\n",
    "                RETURN node.id AS article_id, node.text AS text, score\n",
    "                \"\"\",\n",
    "                top_k=top_k,\n",
    "                query_embedding=query_embedding\n",
    "            )\n",
    "            for record in article_res:\n",
    "                 results.append({\n",
    "                     \"type\": \"Article\",\n",
    "                     \"id\": record[\"article_id\"],\n",
    "                     \"score\": record[\"score\"],\n",
    "                     \"text\": record[\"text\"][:300] + \"...\" # Preview\n",
    "                 })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not query Article vector index: {e}\")\n",
    "\n",
    "\n",
    "        # Find similar Precedents\n",
    "        try:\n",
    "            precedent_res = session.run(\n",
    "                \"\"\"\n",
    "                CALL db.index.vector.queryNodes('precedent_embedding', $top_k, $query_embedding) YIELD node, score\n",
    "                MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                RETURN node.id AS case_id, node.name as case_name, node.full_summary AS text, score,\n",
    "                       collect(DISTINCT a.id) as referenced_articles,\n",
    "                       collect(DISTINCT k.text) as keywords\n",
    "                \"\"\",\n",
    "                top_k=top_k,\n",
    "                query_embedding=query_embedding\n",
    "            )\n",
    "            for record in precedent_res:\n",
    "                 results.append({\n",
    "                     \"type\": \"Precedent\",\n",
    "                     \"id\": record[\"case_id\"],\n",
    "                     \"name\": record[\"case_name\"],\n",
    "                     \"score\": record[\"score\"],\n",
    "                     \"text\": record[\"text\"][:300] + \"...\", # Preview\n",
    "                     \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                     \"keywords\": record[\"keywords\"]\n",
    "                 })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not query Precedent vector index: {e}\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Query completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Sort results by score (descending) and take top K overall\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"\\n--- Top Results ---\")\n",
    "    for i, res in enumerate(results[:top_k]):\n",
    "        print(f\"{i+1}. Type: {res['type']}, ID: {res['id']}, Score: {res['score']:.4f}\")\n",
    "        if res['type'] == 'Precedent':\n",
    "            print(f\"   Name: {res.get('name')}\")\n",
    "            print(f\"   Keywords: {res.get('keywords')}\")\n",
    "            print(f\"   Referenced Articles: {res.get('referenced_articles')}\")\n",
    "        print(f\"   Text Preview: {res['text']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k] # Return top K overall results\n",
    "\n",
    "\n",
    "# Test query\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = query_graph_rag(driver, query, embedding_model, top_k=3)\n",
    "\n",
    "# Close driver when completely finished\n",
    "driver.close()\n",
    "print(\"\\nNeo4j driver closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb9281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
