{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa53ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# %pip install langchain langchain_community langchain_openai neo4j python-dotenv pypdf tiktoken\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cae8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (ensure NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, OPENAI_API_KEY are set in your .env file)\n",
    "load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Embedding model setup\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=OPENAI_API_KEY)\n",
    "embedding_dimension = 1536 # Dimension for text-embedding-3-small\n",
    "\n",
    "# Data paths\n",
    "pdf_path = './dataset/criminal-law.pdf'\n",
    "precedent_dir = './dataset/precedent_label/' # Directory containing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65cd2b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 194 articles from PDF.\n",
      "\n",
      "--- Example Article: 제1조(범죄의 성립과 처벌) ---\n",
      "제1조(범죄의 성립과 처벌) ①범죄의 성립과 처벌은 행위 시의 법률에 의한다.\n",
      "②범죄 후 법률의 변경에 의하여 그 행위가 범죄를 구성하지 아니하거나 형이 구법보다 경한\n",
      "때에는 신법에 의한다.\n",
      "③재판확정 후 법률의 변경에 의하여 그 행위가 범죄를 구성하지 아니하는 때에는 형의 집행\n",
      "을 면제한다.\n",
      " \n",
      "제2조(국내범)제2조(국내범) 본법은 대한민국영역 내에서 죄를 범한 내국인과 외국인에게 적용한다.\n",
      " \n",
      "제3조(내국인의 국외범)제3조(내국인의 국외범) 본법은 대한민국영역 외에서 죄를 범한 내국인에게 적용한다.\n",
      " \n",
      "제4조(국외에 있는 내국선박 등에서 외국인이 범한 죄)제4조(국외에 있는 내국선박 등에서 외국인이 범한 죄) 본법은 대한민국영역 외에 있는 대한민\n",
      "국의 선박 또는 항공기 내에서 죄를 범한 외국인에게 적용한다.\n",
      " \n",
      "제5조(외국인의 국외범)제5조(외국인의 국외범)...\n"
     ]
    }
   ],
   "source": [
    "# # Load PDF\n",
    "# loader = PyPDFLoader(pdf_path)\n",
    "# # pages = loader.load()[2:] # Skip first two pages as before\n",
    "# pages = loader.load()\n",
    "# full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "# # Text Splitter (refined for graph structure)\n",
    "# # We'll primarily focus on splitting by Article for node creation\n",
    "# # article_pattern_precise = re.compile(r'(제\\d+조(?:의\\d+)?\\s*\\(.+?\\))\\s*') # More precise pattern to capture article header\n",
    "\n",
    "# article_pattern_precise = re.compile(r'(제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?)')\n",
    "\n",
    "# separators = [\n",
    "#     # r\"(제\\d+조(?:의\\d+)?\\s*\\(.+?\\))\", # 조 (Article) - Primary separator\n",
    "#     r\"(제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?)\",\n",
    "#     r\"(제\\d+장 [^\\\\n]+)\",             # 장 (Chapter)\n",
    "#     r\"(제\\d+편 [^\\\\n]+)\",             # 편 (Edition)\n",
    "#     \"\\n\\n\",                         # Paragraph\n",
    "#     \"\\n\",                           # Line break\n",
    "#     \" \",                            # Space\n",
    "# ]\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=500, # Adjust as needed\n",
    "#     chunk_overlap=150, # Adjust as needed\n",
    "#     length_function=len,\n",
    "#     separators=separators,\n",
    "#     is_separator_regex=True,\n",
    "# )\n",
    "\n",
    "# raw_chunks = text_splitter.split_text(full_text)\n",
    "\n",
    "# # Process chunks to associate content with articles\n",
    "# articles = {}\n",
    "# current_article_id = None\n",
    "# current_content = \"\"\n",
    "\n",
    "# for chunk in raw_chunks:\n",
    "#     match = article_pattern_precise.search(chunk)\n",
    "#     if match:\n",
    "#         # If we encounter a new article, save the previous one (if any)\n",
    "#         if current_article_id:\n",
    "#             articles[current_article_id] = current_content.strip()\n",
    "\n",
    "#         # Start the new article\n",
    "#         current_article_id = match.group(1).strip()\n",
    "#         # Remove the matched article header from the beginning of the chunk content\n",
    "#         current_content = article_pattern_precise.sub(\"\", chunk, count=1)\n",
    "#     else:\n",
    "#         # Append chunk content to the current article\n",
    "#         if current_article_id: # Only append if we are already inside an article\n",
    "#              current_content += \"\\n\" + chunk\n",
    "\n",
    "# # Save the last processed article\n",
    "# if current_article_id:\n",
    "#     articles[current_article_id] = current_content.strip()\n",
    "\n",
    "\n",
    "# print(f\"Processed {len(articles)} articles from PDF.\")\n",
    "# # Example: Print the first processed article\n",
    "# if articles:\n",
    "#     first_article_id = list(articles.keys())[0]\n",
    "#     print(f\"\\n--- Example Article: {first_article_id} ---\")\n",
    "#     print(articles[first_article_id][:500] + \"...\")\n",
    "\n",
    "# # Convert to Document objects for potential later use or consistency\n",
    "# article_docs = [Document(page_content=content, metadata={\"article_id\": article_id}) for article_id, content in articles.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d6ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 548 articles from PDF.\n",
      "\n",
      "\n",
      "=== 마지막 10개 조항 ===\n",
      "\n",
      "--- Article: 제4조 (형에 관한 경과조치) ---\n",
      "제4조 (형에 관한 경과조치) 이 법 시행전에 종전의 형법규정에 의하여 형의 선고를 받은 자는\n",
      "이 법에 의하여 형의 선고를 받은 것으로 본다. 집행유예 또는 선고유예를 받은 경우에도 이와\n",
      "같다.\n",
      "\n",
      "--- Article: 제5조 (다른 법령과의 관계) ---\n",
      "제5조 (다른 법령과의 관계) 이 법 시행당시 다른 법령에서 종전의 형법 규정(장의 제목을 포함\n",
      "한다)을 인용하고 있는 경우에 이 법중 그에 해당하는 규정이 있는 때에는 종전의 규정에 갈음\n",
      "하여 이 법의 해당 조항을 인용한 것으로 본다.\n",
      "  \n",
      "부칙 <제5454호,1997.12.13>\n",
      "이 법은 1998년 1월 1일부터 시행한다. <단서 생략>\n",
      "  \n",
      "부칙 <제...\n",
      "\n",
      "--- Article: 제7조 ---\n",
      "제7조(제2항 및 제29항\n",
      "을 제외한다)의 규정은 2008년 1월 1일부터 시행한다.\n",
      "\n",
      "--- Article: 제2조 ---\n",
      "제2조 내지\n",
      "\n",
      "--- Article: 제6조 ---\n",
      "제6조 생략\n",
      "\n",
      "--- Article: 제7조 (다른 법률의 개정) ---\n",
      "제7조 (다른 법률의 개정) ①내지 <26>생략\n",
      "<27>형법 일부를 다음과 같이 개정한다.\n",
      "\n",
      "--- Article: 제151조 ---\n",
      "제151조제2항 및\n",
      "\n",
      "--- Article: 제155조 ---\n",
      "제155조제4항중 \"친족, 호주 또는 동거의 가족\"을 각각 \"친족 또는 동거의\n",
      "가족\"으로 한다.\n",
      "\n",
      "--- Article: 제305조의2 ---\n",
      "제305조의2의 개정규정은\n",
      "공포한 날부터 시행한다.\n",
      "②(가석방의 요건에 관한 적용례)\n",
      "\n",
      "--- Article: 제72조 ---\n",
      "제72조제1항의 개정규정은 이 법 시행 당시 수용 중인 사람에\n",
      "대하여도 적용한다.\n",
      "형법\n",
      " 제 작 자   :송진아\n",
      "메일주소  :blue4890@hanmail.net\n",
      "제작일자  :2013.11.8\n",
      " 법제처 국가법령정보센터\n"
     ]
    }
   ],
   "source": [
    "# 청킹이 아닌 정규식 패턴 매칭으로 각 조항 추출하기\n",
    "import re\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "# pages = loader.load()[2:] # Skip first two pages as before\n",
    "pages = loader.load()\n",
    "full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "# 전체 텍스트에서 모든 조항 시작 위치 찾기\n",
    "article_pattern = r'제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?'\n",
    "matches = list(re.finditer(article_pattern, full_text))\n",
    "\n",
    "articles = {}\n",
    "for i in range(len(matches)):\n",
    "    current_match = matches[i]\n",
    "    current_article_id = current_match.group(0).strip()  # 현재 조항 ID\n",
    "    \n",
    "    # 현재 조항 시작 위치\n",
    "    start_pos = current_match.start()\n",
    "    \n",
    "    # 다음 조항 시작 위치 (없으면 텍스트 끝까지)\n",
    "    end_pos = matches[i+1].start() if i < len(matches)-1 else len(full_text)\n",
    "    \n",
    "    # 현재 조항의 전체 내용 (ID 포함)\n",
    "    article_text = full_text[start_pos:end_pos].strip()\n",
    "    \n",
    "    # 저장 (ID는 조항 번호만)\n",
    "    articles[current_article_id] = article_text\n",
    "\n",
    "print(f\"Processed {len(articles)} articles from PDF.\")\n",
    "\n",
    "# 예시 출력\n",
    "if articles:\n",
    "    article_ids = list(articles.keys())\n",
    "    # print(\"\\n=== 처음 5개 조항 ===\")\n",
    "    # for i in range(min(5, len(article_ids))):  # 처음 5개 조항만 출력\n",
    "    #     article_id = article_ids[i]\n",
    "    #     content = articles[article_id]\n",
    "    #     print(f\"\\n--- Article: {article_id} ---\")\n",
    "    #     print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "        \n",
    "        \n",
    "        # 마지막 10개 조항 출력\n",
    "    print(\"\\n\\n=== 마지막 10개 조항 ===\")\n",
    "    for i in range(max(0, len(article_ids) - 10), len(article_ids)):\n",
    "        article_id = article_ids[i]\n",
    "        content = articles[article_id]\n",
    "        print(f\"\\n--- Article: {article_id} ---\")\n",
    "        print(content[:200] + \"...\" if len(content) > 200 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc2353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5404 precedents.\n",
      "\n",
      "--- Example Precedent ---\n",
      "{\n",
      "  \"case_id\": \"88도2209\",\n",
      "  \"case_name\": \"매장및묘지등에관한법률위반, 사문서위조, 동행사, 조세범처벌법위반, 특정범죄가중처벌등에관한법률위반\",\n",
      "  \"judgment_summary\": \"가. 작성명의자의 인영이나 주민등록번호의 등재가 누락된 문서가 사문서위조죄의 객체인 사문서에 해당하는지 여부\\n나. 사문서위조 및 동행사죄가 조세범처벌법 제9조 소정의 조세포탈의 수단으로 행해진 경우 후자의 죄에 흡수되는지 여부(소극)\",\n",
      "  \"full_summary\": \"사문서의 작성명의자의 인장이 압날되지 아니하고 주민등록번호가 기재되지 않았다고 하더라도, 일반인으로 하여금 그 작상명의자가 진정하게 작성한 사문서로 믿기에 충분할 정도의 형식과 외관을 갖추었으면 사문서위조죄 및 동행사죄의 객체가 되는 사문서라고 보아야 할 것이고, 사문서위조 및 동행사죄가 조세범처벌법 제9조 제1항 소정의 “사기 기타 부정한 행위로써 조세를 포탈”하기 위한 수단으로 행하여졌다고 하여 조세범처벌법 제9조 소정의 조세포탈죄에 흡수된다고 볼 수도 없는 것이므로, 논지는 이유가 없다.\",\n",
      "  \"keywords\": [\n",
      "    \"사문서위조\",\n",
      "    \"동행사\"\n",
      "  ],\n",
      "  \"referenced_rules\": [\n",
      "    \"제9조\",\n",
      "    \"제37조\",\n",
      "    \"제231조\",\n",
      "    \"제234조\"\n",
      "  ],\n",
      "  \"referenced_cases\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load precedent JSON files\n",
    "precedents = []\n",
    "for filename in os.listdir(precedent_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(precedent_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # Extract relevant fields\n",
    "                precedent_info = {\n",
    "                    \"case_id\": data.get(\"info\", {}).get(\"caseNoID\", filename.replace(\".json\", \"\")),\n",
    "                    \"case_name\": data.get(\"info\", {}).get(\"caseNm\"),\n",
    "                    \"judgment_summary\": data.get(\"jdgmn\"),\n",
    "                    \"full_summary\": \" \".join([s.get(\"summ_contxt\", \"\") for s in data.get(\"Summary\", [])]),\n",
    "                    \"keywords\": [kw.get(\"keyword\") for kw in data.get(\"keyword_tagg\", []) if kw.get(\"keyword\")],\n",
    "                    \"referenced_rules\": data.get(\"Reference_info\", {}).get(\"reference_rules\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_rules\") else [],\n",
    "                    \"referenced_cases\": data.get(\"Reference_info\", {}).get(\"reference_court_case\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_court_case\") else [],\n",
    "                }\n",
    "                # Clean up referenced rules (extract article numbers)\n",
    "                cleaned_rules = []\n",
    "                rule_pattern = re.compile(r'제\\d+조(?:의\\d+)?') # Pattern to find \"제X조\" or \"제X조의Y\"\n",
    "                for rule in precedent_info[\"referenced_rules\"]:\n",
    "                    # Find all matches in the rule string\n",
    "                    matches = rule_pattern.findall(rule.strip())\n",
    "                    cleaned_rules.extend(matches)\n",
    "                precedent_info[\"referenced_rules\"] = list(set(cleaned_rules)) # Keep unique article numbers\n",
    "\n",
    "                precedents.append(precedent_info)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not decode JSON from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(precedents)} precedents.\")\n",
    "# Example: Print the first loaded precedent\n",
    "if precedents:\n",
    "    print(\"\\n--- Example Precedent ---\")\n",
    "    print(json.dumps(precedents[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b4b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 1000 precedents out of 5404 total precedents.\n"
     ]
    }
   ],
   "source": [
    "# 로드된 판례 중 무작위로 1,000개만 선택\n",
    "import random\n",
    "random.seed(42)  # 재현성을 위한 시드 설정 (선택사항)\n",
    "\n",
    "# 전체 판례 수 저장\n",
    "total_precedents = len(precedents)\n",
    "\n",
    "# 무작위로 1,000개 선택 (또는 전체 판례 수가 1,000개보다 적다면 모두 선택)\n",
    "sample_size = min(1000, total_precedents)\n",
    "precedents = random.sample(precedents, sample_size)\n",
    "\n",
    "print(f\"Randomly selected {len(precedents)} precedents out of {total_precedents} total precedents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af35f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Neo4j.\n",
      "Article vector index created or already exists.\n",
      "Precedent vector index created or already exists.\n",
      "Waiting for indexes to populate...\n",
      "Indexes should be online.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Neo4j\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Successfully connected to Neo4j.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Neo4j: {e}\")\n",
    "    # Stop execution if connection fails\n",
    "    raise\n",
    "\n",
    "# Create constraints and indexes for faster lookups and embedding search\n",
    "def setup_neo4j(driver, dimension):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # Constraints for uniqueness\n",
    "        session.run(\"CREATE CONSTRAINT article_id IF NOT EXISTS FOR (a:Article) REQUIRE a.id IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT precedent_id IF NOT EXISTS FOR (p:Precedent) REQUIRE p.id IS UNIQUE\")\n",
    "        session.run(\"CREATE CONSTRAINT keyword_text IF NOT EXISTS FOR (k:Keyword) REQUIRE k.text IS UNIQUE\")\n",
    "\n",
    "        # Vector index for Articles\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX article_embedding IF NOT EXISTS \"\n",
    "                \"FOR (a:Article) ON (a.embedding) \"\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "            )\n",
    "            print(\"Article vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Article vector index (may require Neo4j 5.11+ and APOC): {e}\")\n",
    "            print(\"Continuing without vector index creation for Article.\")\n",
    "\n",
    "\n",
    "        # Vector index for Precedents\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX precedent_embedding IF NOT EXISTS \"\n",
    "                \"FOR (p:Precedent) ON (p.embedding) \"\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "            )\n",
    "            print(\"Precedent vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Precedent vector index (may require Neo4j 5.11+ and APOC): {e}\")\n",
    "            print(\"Continuing without vector index creation for Precedent.\")\n",
    "\n",
    "        # Wait for indexes to come online (important!)\n",
    "        print(\"Waiting for indexes to populate...\")\n",
    "        session.run(\"CALL db.awaitIndexes(300)\") # Wait up to 300 seconds\n",
    "        print(\"Indexes should be online.\")\n",
    "\n",
    "\n",
    "setup_neo4j(driver, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "091dcd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 548 Article nodes...\n",
      "  Processed 50/548 articles...\n",
      "  Processed 100/548 articles...\n",
      "  Processed 150/548 articles...\n",
      "  Processed 200/548 articles...\n",
      "  Processed 250/548 articles...\n",
      "  Processed 300/548 articles...\n",
      "  Processed 350/548 articles...\n",
      "  Processed 400/548 articles...\n",
      "  Processed 450/548 articles...\n",
      "  Processed 500/548 articles...\n",
      "Finished creating 548 Article nodes in 398.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Article nodes and generate/store embeddings\n",
    "def create_article_nodes(driver, articles_dict, embed_model):\n",
    "    print(f\"Creating {len(articles_dict)} Article nodes...\")\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for article_id, content in articles_dict.items():\n",
    "            if not content: # Skip empty content\n",
    "                print(f\"Skipping article {article_id} due to empty content.\")\n",
    "                continue\n",
    "            try:\n",
    "                # Generate embedding\n",
    "                embedding = embed_model.embed_query(content)\n",
    "\n",
    "                # Create node in Neo4j\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (a:Article {id: $article_id})\n",
    "                    SET a.text = $content,\n",
    "                        a.embedding = $embedding\n",
    "                    \"\"\",\n",
    "                    article_id=article_id,\n",
    "                    content=content,\n",
    "                    embedding=embedding\n",
    "                )\n",
    "                count += 1\n",
    "                if count % 50 == 0:\n",
    "                    print(f\"  Processed {count}/{len(articles_dict)} articles...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article {article_id}: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished creating {count} Article nodes in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "create_article_nodes(driver, articles, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "881f8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 1000 Precedent nodes and relationships...\n",
      "  Processed 100/1000 precedents...\n",
      "  Processed 200/1000 precedents...\n",
      "  Processed 300/1000 precedents...\n",
      "  Processed 400/1000 precedents...\n",
      "  Processed 500/1000 precedents...\n",
      "  Processed 600/1000 precedents...\n",
      "  Processed 700/1000 precedents...\n",
      "  Processed 800/1000 precedents...\n",
      "  Processed 900/1000 precedents...\n",
      "  Processed 1000/1000 precedents...\n",
      "Finished creating 1000 Precedent nodes and relationships in 1316.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Create Precedent nodes, Keyword nodes, and relationships\n",
    "def create_precedent_nodes_and_relationships(driver, precedents_list, embed_model):\n",
    "    print(f\"Creating {len(precedents_list)} Precedent nodes and relationships...\")\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for precedent in precedents_list:\n",
    "            # Use full_summary for embedding, or judgment_summary if full is empty\n",
    "            text_to_embed = precedent.get(\"full_summary\") or precedent.get(\"judgment_summary\")\n",
    "            if not text_to_embed:\n",
    "                print(f\"Skipping precedent {precedent.get('case_id')} due to empty summary.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Generate embedding\n",
    "                embedding = embed_model.embed_query(text_to_embed)\n",
    "\n",
    "                # Create Precedent node\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (p:Precedent {id: $case_id})\n",
    "                    SET p.name = $case_name,\n",
    "                        p.judgment_summary = $judgment_summary,\n",
    "                        p.full_summary = $full_summary,\n",
    "                        p.embedding = $embedding\n",
    "                    \"\"\",\n",
    "                    case_id=precedent[\"case_id\"],\n",
    "                    case_name=precedent[\"case_name\"],\n",
    "                    judgment_summary=precedent[\"judgment_summary\"],\n",
    "                    full_summary=precedent[\"full_summary\"],\n",
    "                    embedding=embedding\n",
    "                )\n",
    "\n",
    "                # Create Keyword nodes and relationships\n",
    "                for keyword_text in precedent[\"keywords\"]:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (k:Keyword {text: $keyword_text})\n",
    "                        WITH k\n",
    "                        MATCH (p:Precedent {id: $case_id})\n",
    "                        MERGE (p)-[:HAS_KEYWORD]->(k)\n",
    "                        \"\"\",\n",
    "                        keyword_text=keyword_text,\n",
    "                        case_id=precedent[\"case_id\"]\n",
    "                    )\n",
    "\n",
    "                # Create relationships to referenced Articles\n",
    "                # Note: This uses the cleaned article IDs extracted earlier\n",
    "                # It tries to match based on the \"제X조\" format.\n",
    "                for article_id_ref in precedent[\"referenced_rules\"]:\n",
    "                     # Find Article nodes that START WITH the referenced ID (e.g., \"제21조\" should match \"제21조(정당방위)\")\n",
    "                     # This is less precise but necessary if the exact title isn't in the reference.\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (p:Precedent {id: $case_id})\n",
    "                        MATCH (a:Article)\n",
    "                        WHERE a.id STARTS WITH $article_id_ref\n",
    "                        MERGE (p)-[:REFERENCES_ARTICLE]->(a)\n",
    "                        \"\"\",\n",
    "                        case_id=precedent[\"case_id\"],\n",
    "                        article_id_ref=article_id_ref # Use the extracted \"제X조\"\n",
    "                    )\n",
    "\n",
    "                # Potential: Create relationships to other referenced Precedents (if needed)\n",
    "                # for ref_case_id in precedent[\"referenced_cases\"]:\n",
    "                #    session.run(...) # MERGE (p)-[:REFERENCES_CASE]->(other_p:Precedent {id: ref_case_id})\n",
    "\n",
    "                count += 1\n",
    "                if count % 100 == 0:\n",
    "                    print(f\"  Processed {count}/{len(precedents_list)} precedents...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing precedent {precedent.get('case_id')}: {e}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Finished creating {count} Precedent nodes and relationships in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "create_precedent_nodes_and_relationships(driver, precedents, embedding_model)\n",
    "\n",
    "# Close the driver connection when done\n",
    "# driver.close() # Keep it open for querying in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d358b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Querying RAG for: '정당방위의 요건은 무엇인가?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_82042/3806495168.py:10: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=\"neo4j\") as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query completed in 3.24 seconds.\n",
      "\n",
      "--- Top Results ---\n",
      "1. Type: Precedent, ID: 92도2540, Score: 0.7387\n",
      "   Name: 살인\n",
      "   Keywords: ['타인의 법익', '상당한 이유']\n",
      "   Referenced Articles: ['제10조(심신장애자)', '제21조(정당방위)', '제308조(사자의 명예훼손)', '제308조', '제10조 (폐지되는 법률등)']\n",
      "   Text Preview: 정당방위의 성립요건으로서의 방어행위에는 순수한 수비적 방어뿐 아니라 적극적 반격을 포함하는 반격방어의 형태도 포함됨은 소론과 같다고 하겠으나, 그 방어행위는 자기 또는 타인의 법익침해를 방위하기 위한 행위로서 상당한 이유가 있어야 하는 것인데, 피고인들의 판시 행위가 위에서 본 바와 같이 그 상당성을 결여한 것인 이상 정당방위행위로 평가될 수는 없는 것이므로, 원심이 피고인들의 이 사건 범행이 현재의 부당한 침해를 방위할 의사로 행해졌다기보다는 공격의 의사로 행하여졌다고 인정한 것이 적절하지 못하다고 하더라도, 정당방위행위가 되지 ...\n",
      "--------------------\n",
      "2. Type: Precedent, ID: 2009도2114, Score: 0.6939\n",
      "   Name: 특수공무집행방해[변경된죄명:폭력행위등처벌에관한법률위반(공동폭행)]\n",
      "   Keywords: ['사회상규에 위배', '소극적인 방어행위']\n",
      "   Referenced Articles: ['제6조(대한민국과 대한민국 국민에 대한 국외범)', '제20조(정당행위)', '제21조(정당방위)', '제136조(공무집행방해)', '제136조', '제260조(폭행, 존속폭행)', '제260조', '제6조 (경합범에 대한 신법의 적용례)', '제6조']\n",
      "   Text Preview: 비록 경찰관들의 위법한 상경 제지 행위에 대항하기 위하여 한 것이라 하더라도, 피고인들이 다른 시위참가자들과 공동하여 위와 같이 경찰관들을 때리고 진압방패와 채증장비를 빼앗는 등의 폭행행위를 한 것은 소극적인 방어행위를 넘어서 공격의 의사를 포함하여 이루어진 것으로서 그 수단과 방법에 있어서 상당성이 인정된다고 보기 어려우며 긴급하고 불가피한 수단이었다고 볼 수도 없으므로, 이를 사회상규에 위배되지 아니하는 정당행위나 현재의 부당한 침해를 방어하기 위한 정당방위에 해당한다고 볼 수 없다.\n",
      "그럼에도 불구하고, 원심은 그 판시와 같은 ...\n",
      "--------------------\n",
      "3. Type: Precedent, ID: 83누383, Score: 0.6789\n",
      "   Name: 영업정지처분무효확인\n",
      "   Keywords: ['법령 위반행위']\n",
      "   Referenced Articles: ['제1조(범죄의 성립과 처벌)', '제34조(간접정범, 특수한 교사, 방조에 대한 형의 가중)', '제37조(경합범)', '제38조(경합범과 처벌례)', '제34조', '제1조 (구형법 기타 법령과 형의 경중)', '제1조 (시행일)']\n",
      "   Text Preview: 정당한 절차에 의하지 않고 구두에 의한 하도급계약을 체결하여 공사를 시작한 때에건설업법 제34조 제3항의 위반행위를 범한 것이 되니 그 위반행위를 이유로 한 행정상의 제재처분(행위당시에는 필요적 취소사유)을 하려면 그 위반행위 이후 법령의 변경에 의하여 처분의 종류를 달리(영업정지 사유로) 규정하였다 하더라도 그 법률적용에 관한특별한 규정이 없다면 위반행위 당시에 시행되던 법령을 근거로 처분을 하여야 마땅하다....\n",
      "--------------------\n",
      "\n",
      "Neo4j driver closed.\n"
     ]
    }
   ],
   "source": [
    "# Example RAG query using vector similarity search\n",
    "def query_graph_rag(driver, query_text, embed_model, top_k=3):\n",
    "    print(f\"\\n--- Querying RAG for: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "\n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # Find similar Articles\n",
    "        try:\n",
    "            article_res = session.run(\n",
    "                \"\"\"\n",
    "                CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) YIELD node, score\n",
    "                RETURN node.id AS article_id, node.text AS text, score\n",
    "                \"\"\",\n",
    "                top_k=top_k,\n",
    "                query_embedding=query_embedding\n",
    "            )\n",
    "            for record in article_res:\n",
    "                 results.append({\n",
    "                     \"type\": \"Article\",\n",
    "                     \"id\": record[\"article_id\"],\n",
    "                     \"score\": record[\"score\"],\n",
    "                     \"text\": record[\"text\"][:300] + \"...\" # Preview\n",
    "                 })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not query Article vector index: {e}\")\n",
    "\n",
    "\n",
    "        # Find similar Precedents\n",
    "        try:\n",
    "            precedent_res = session.run(\n",
    "                \"\"\"\n",
    "                CALL db.index.vector.queryNodes('precedent_embedding', $top_k, $query_embedding) YIELD node, score\n",
    "                MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                RETURN node.id AS case_id, node.name as case_name, node.full_summary AS text, score,\n",
    "                       collect(DISTINCT a.id) as referenced_articles,\n",
    "                       collect(DISTINCT k.text) as keywords\n",
    "                \"\"\",\n",
    "                top_k=top_k,\n",
    "                query_embedding=query_embedding\n",
    "            )\n",
    "            for record in precedent_res:\n",
    "                 results.append({\n",
    "                     \"type\": \"Precedent\",\n",
    "                     \"id\": record[\"case_id\"],\n",
    "                     \"name\": record[\"case_name\"],\n",
    "                     \"score\": record[\"score\"],\n",
    "                     \"text\": record[\"text\"][:300] + \"...\", # Preview\n",
    "                     \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                     \"keywords\": record[\"keywords\"]\n",
    "                 })\n",
    "        except Exception as e:\n",
    "            print(f\"Could not query Precedent vector index: {e}\")\n",
    "\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Query completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # Sort results by score (descending) and take top K overall\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"\\n--- Top Results ---\")\n",
    "    for i, res in enumerate(results[:top_k]):\n",
    "        print(f\"{i+1}. Type: {res['type']}, ID: {res['id']}, Score: {res['score']:.4f}\")\n",
    "        if res['type'] == 'Precedent':\n",
    "            print(f\"   Name: {res.get('name')}\")\n",
    "            print(f\"   Keywords: {res.get('keywords')}\")\n",
    "            print(f\"   Referenced Articles: {res.get('referenced_articles')}\")\n",
    "        print(f\"   Text Preview: {res['text']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k] # Return top K overall results\n",
    "\n",
    "\n",
    "# Test query\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = query_graph_rag(driver, query, embedding_model, top_k=3)\n",
    "\n",
    "# Close driver when completely finished\n",
    "driver.close()\n",
    "print(\"\\nNeo4j driver closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28bb9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_query_rag(driver, query_text, embed_model, top_k=3):\n",
    "    print(f\"\\n--- 하이브리드 검색 실행: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 벡터 검색을 위한 임베딩\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "    \n",
    "    # 간단한 키워드 추출 (1글자 이하 단어 제외)\n",
    "    keywords = [w for w in re.findall(r'\\w+', query_text) if len(w) > 1]\n",
    "    \n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # Article 하이브리드 검색\n",
    "        try:\n",
    "            # 키워드 필터 준비\n",
    "            keyword_conditions = []\n",
    "            for keyword in keywords:\n",
    "                keyword_conditions.append(f\"node.text CONTAINS '{keyword}'\")\n",
    "            \n",
    "            # 키워드가 있는 경우에만 필터 적용\n",
    "            keyword_filter = \" OR \".join(keyword_conditions) if keyword_conditions else \"true\"\n",
    "            \n",
    "            article_query = f\"\"\"\n",
    "            MATCH (node:Article)\n",
    "            WHERE {keyword_filter}\n",
    "            WITH node, 0.2 as keyword_match\n",
    "            CALL db.index.vector.queryNodes('article_embedding', 50, $query_embedding) \n",
    "                YIELD node as vector_node, score as vector_score\n",
    "            WHERE node = vector_node\n",
    "            WITH node, keyword_match + vector_score * 0.8 as combined_score\n",
    "            RETURN node.id AS id, 'Article' as type, node.text AS text, \n",
    "                   combined_score as score\n",
    "            ORDER BY combined_score DESC\n",
    "            LIMIT $top_k\n",
    "            \"\"\"\n",
    "            \n",
    "            article_res = session.run(\n",
    "                article_query,\n",
    "                query_embedding=query_embedding,\n",
    "                top_k=top_k\n",
    "            )\n",
    "            \n",
    "            for record in article_res:\n",
    "                results.append({\n",
    "                    \"type\": record[\"type\"],\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"score\": record[\"score\"],\n",
    "                    \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Article 하이브리드 검색 오류: {e}\")\n",
    "            \n",
    "            # 백업: 기본 벡터 검색\n",
    "            try:\n",
    "                article_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    RETURN node.id AS id, 'Article' as type, node.text AS text, score\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in article_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"]\n",
    "                    })\n",
    "            except Exception as e2:\n",
    "                print(f\"기본 Article 벡터 검색 오류: {e2}\")\n",
    "\n",
    "        # Precedent 하이브리드 검색\n",
    "        try:\n",
    "            keyword_filter = \" OR \".join([f\"node.full_summary CONTAINS '{k}' OR node.judgment_summary CONTAINS '{k}'\" \n",
    "                                         for k in keywords]) if keywords else \"true\"\n",
    "            \n",
    "            precedent_query = f\"\"\"\n",
    "            MATCH (node:Precedent)\n",
    "            WHERE {keyword_filter}\n",
    "            WITH node, 0.2 as keyword_match\n",
    "            CALL db.index.vector.queryNodes('precedent_embedding', 50, $query_embedding) \n",
    "                YIELD node as vector_node, score as vector_score\n",
    "            WHERE node = vector_node\n",
    "            WITH node, keyword_match + vector_score * 0.8 as combined_score\n",
    "            MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "            OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "            RETURN node.id AS id, 'Precedent' as type, \n",
    "                   node.name AS name, node.full_summary AS text, \n",
    "                   combined_score as score,\n",
    "                   collect(DISTINCT a.id) as referenced_articles,\n",
    "                   collect(DISTINCT k.text) as keywords\n",
    "            ORDER BY combined_score DESC\n",
    "            LIMIT $top_k\n",
    "            \"\"\"\n",
    "            \n",
    "            precedent_res = session.run(\n",
    "                precedent_query,\n",
    "                query_embedding=query_embedding,\n",
    "                top_k=top_k\n",
    "            )\n",
    "            \n",
    "            for record in precedent_res:\n",
    "                results.append({\n",
    "                    \"type\": record[\"type\"],\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"name\": record[\"name\"],\n",
    "                    \"score\": record[\"score\"],\n",
    "                    \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                    \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                    \"keywords\": record[\"keywords\"]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Precedent 하이브리드 검색 오류: {e}\")\n",
    "            \n",
    "            # 백업: 기본 벡터 검색\n",
    "            try:\n",
    "                precedent_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                    OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                    RETURN node.id AS id, 'Precedent' as type, \n",
    "                           node.name AS name, node.full_summary AS text, \n",
    "                           score,\n",
    "                           collect(DISTINCT a.id) as referenced_articles,\n",
    "                           collect(DISTINCT k.text) as keywords\n",
    "                    ORDER BY score DESC\n",
    "                    LIMIT $top_k\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in precedent_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"name\": record[\"name\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                        \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                        \"keywords\": record[\"keywords\"]\n",
    "                    })\n",
    "            except Exception as e2:\n",
    "                print(f\"기본 Precedent 벡터 검색 오류: {e2}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"검색 완료: {end_time - start_time:.2f}초 소요\")\n",
    "\n",
    "    # 결과를 스코어로 정렬\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"\\n--- 검색 결과 ---\")\n",
    "    for i, res in enumerate(results[:top_k]):\n",
    "        print(f\"{i+1}. 유형: {res['type']}, ID: {res['id']}, 스코어: {res['score']:.4f}\")\n",
    "        if res['type'] == 'Precedent':\n",
    "            print(f\"   이름: {res.get('name')}\")\n",
    "            print(f\"   키워드: {res.get('keywords')}\")\n",
    "            print(f\"   참조 법조항: {res.get('referenced_articles')}\")\n",
    "        print(f\"   미리보기: {res['text']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a43ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_rag(driver, query_text, embed_model, top_k=3):\n",
    "    print(f\"\\n--- 다단계 검색 실행: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 임베딩 생성\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "    \n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # 1단계: 관련 법조항 찾기\n",
    "        article_results = []\n",
    "        try:\n",
    "            articles = session.run(\n",
    "                \"\"\"\n",
    "                CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) \n",
    "                YIELD node, score\n",
    "                RETURN node.id AS id, node.text AS text, score\n",
    "                ORDER BY score DESC\n",
    "                \"\"\",\n",
    "                top_k=top_k,\n",
    "                query_embedding=query_embedding\n",
    "            )\n",
    "            \n",
    "            for record in articles:\n",
    "                article_results.append({\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"text\": record[\"text\"],\n",
    "                    \"score\": record[\"score\"]\n",
    "                })\n",
    "                \n",
    "                # 각 법조항을 결과에 추가\n",
    "                results.append({\n",
    "                    \"type\": \"Article\",\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"score\": record[\"score\"],\n",
    "                    \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"법조항 검색 오류: {e}\")\n",
    "        \n",
    "        # 2단계: 각 법조항을 참조하는 판례 찾기\n",
    "        for article in article_results:\n",
    "            try:\n",
    "                # 해당 법조항을 참조하는 판례 중에서도 쿼리와 관련성이 높은 판례 검색\n",
    "                precedents = session.run(\n",
    "                    \"\"\"\n",
    "                    MATCH (p:Precedent)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                    WHERE a.id STARTS WITH $article_id\n",
    "                    WITH p\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', 10, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    WHERE p = node\n",
    "                    MATCH (p)-[:REFERENCES_ARTICLE]->(ref_article:Article)\n",
    "                    OPTIONAL MATCH (p)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                    RETURN p.id AS id, p.name as name, p.full_summary AS text, \n",
    "                           score,\n",
    "                           collect(DISTINCT ref_article.id) as referenced_articles,\n",
    "                           collect(DISTINCT k.text) as keywords\n",
    "                    ORDER BY score DESC\n",
    "                    LIMIT 2\n",
    "                    \"\"\",\n",
    "                    article_id=article[\"id\"],\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in precedents:\n",
    "                    # 중복 제거를 위한 ID 확인\n",
    "                    if not any(r[\"type\"] == \"Precedent\" and r[\"id\"] == record[\"id\"] for r in results):\n",
    "                        results.append({\n",
    "                            \"type\": \"Precedent\",\n",
    "                            \"id\": record[\"id\"],\n",
    "                            \"name\": record[\"name\"],\n",
    "                            \"score\": record[\"score\"],\n",
    "                            \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                            \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                            \"keywords\": record[\"keywords\"]\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"판례 검색 오류 (법조항 {article['id']}): {e}\")\n",
    "        \n",
    "        # 3단계(선택): 벡터 검색으로 최상위 판례 직접 찾기\n",
    "        if len([r for r in results if r[\"type\"] == \"Precedent\"]) < 2:\n",
    "            try:\n",
    "                direct_precedents = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', 3, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                    OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                    RETURN node.id AS id, 'Precedent' as type, \n",
    "                           node.name AS name, node.full_summary AS text, \n",
    "                           score,\n",
    "                           collect(DISTINCT a.id) as referenced_articles,\n",
    "                           collect(DISTINCT k.text) as keywords\n",
    "                    \"\"\",\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in direct_precedents:\n",
    "                    if not any(r[\"type\"] == \"Precedent\" and r[\"id\"] == record[\"id\"] for r in results):\n",
    "                        results.append({\n",
    "                            \"type\": record[\"type\"],\n",
    "                            \"id\": record[\"id\"],\n",
    "                            \"name\": record[\"name\"],\n",
    "                            \"score\": record[\"score\"],\n",
    "                            \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                            \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                            \"keywords\": record[\"keywords\"]\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"직접 판례 검색 오류: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"검색 완료: {end_time - start_time:.2f}초 소요\")\n",
    "\n",
    "    # 결과를 스코어로 정렬\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"\\n--- 검색 결과 ---\")\n",
    "    for i, res in enumerate(results[:top_k]):\n",
    "        print(f\"{i+1}. 유형: {res['type']}, ID: {res['id']}, 스코어: {res['score']:.4f}\")\n",
    "        if res['type'] == 'Precedent':\n",
    "            print(f\"   이름: {res.get('name')}\")\n",
    "            print(f\"   키워드: {res.get('keywords')}\")\n",
    "            print(f\"   참조 법조항: {res.get('referenced_articles')}\")\n",
    "        print(f\"   미리보기: {res['text']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "043819ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_enhanced_rag(driver, query_text, embed_model, top_k=3):\n",
    "    print(f\"\\n--- 그래프 기반 검색 실행: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 임베딩 생성\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "    \n",
    "    # 키워드 추출\n",
    "    keywords = [w for w in re.findall(r'\\w+', query_text) if len(w) > 1]\n",
    "    \n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        try:\n",
    "            # 그래프 구조를 활용한 검색\n",
    "            cypher_query = \"\"\"\n",
    "            // 1. 벡터 검색으로 시작 법조항 찾기\n",
    "            CALL db.index.vector.queryNodes('article_embedding', 5, $query_embedding) \n",
    "            YIELD node as article, score as article_score\n",
    "            \n",
    "            // 2. 해당 법조항과 연결된 판례와 키워드 찾기\n",
    "            OPTIONAL MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article)\n",
    "            OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "            \n",
    "            // 3. 결과 집계 및 점수 계산\n",
    "            WITH article, article_score, precedent, \n",
    "                 collect(DISTINCT keyword.text) as keywords,\n",
    "                 count(precedent) as precedent_count\n",
    "            \n",
    "            // 법조항 점수 = 벡터 점수 + 판례 인용 수에 따른 보너스\n",
    "            WITH article, article_score + (precedent_count * 0.01) as final_score,\n",
    "                 precedent_count, keywords\n",
    "            \n",
    "            RETURN article.id as id, \n",
    "                   'Article' as type, \n",
    "                   article.text as text, \n",
    "                   final_score as score,\n",
    "                   precedent_count,\n",
    "                   keywords\n",
    "            ORDER BY final_score DESC\n",
    "            LIMIT $article_limit\n",
    "            \"\"\"\n",
    "            \n",
    "            # 법조항 검색\n",
    "            article_results = session.run(\n",
    "                cypher_query,\n",
    "                query_embedding=query_embedding,\n",
    "                article_limit=top_k\n",
    "            )\n",
    "            \n",
    "            for record in article_results:\n",
    "                results.append({\n",
    "                    \"type\": record[\"type\"],\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"score\": record[\"score\"],\n",
    "                    \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                    \"precedent_count\": record[\"precedent_count\"],\n",
    "                    \"related_keywords\": record[\"keywords\"]\n",
    "                })\n",
    "            \n",
    "            # 관련 판례 검색\n",
    "            for article_result in results[:3]:  # 상위 3개 법조항에 대해서만\n",
    "                if article_result[\"type\"] == \"Article\":\n",
    "                    precedent_query = \"\"\"\n",
    "                    // 1. 특정 법조항을 참조하는 판례 찾기\n",
    "                    MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article:Article)\n",
    "                    WHERE article.id STARTS WITH $article_id\n",
    "                    \n",
    "                    // 2. 해당 판례와 키워드\n",
    "                    OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "                    \n",
    "                    // 3. 벡터 유사도 계산\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', 20, $query_embedding) \n",
    "                    YIELD node as vector_node, score as vector_score\n",
    "                    WHERE precedent = vector_node\n",
    "                    \n",
    "                    // 4. 검색어와 관련된 키워드가 있는지 확인하여 보너스 점수\n",
    "                    WITH precedent, vector_score, \n",
    "                         collect(DISTINCT keyword.text) as keywords,\n",
    "                         sum(CASE WHEN $query_keywords IS NULL THEN 0\n",
    "                              WHEN any(k IN $query_keywords WHERE keyword.text CONTAINS k) \n",
    "                              THEN 0.05 ELSE 0 END) as keyword_bonus\n",
    "                    \n",
    "                    // 5. 다른 법조항도 참조하는지 확인\n",
    "                    MATCH (precedent)-[:REFERENCES_ARTICLE]->(ref_article:Article)\n",
    "                    \n",
    "                    // 6. 최종 결과 반환\n",
    "                    RETURN precedent.id as id,\n",
    "                           'Precedent' as type,\n",
    "                           precedent.name as name,\n",
    "                           precedent.full_summary as text,\n",
    "                           vector_score + keyword_bonus as score,\n",
    "                           keywords,\n",
    "                           collect(DISTINCT ref_article.id) as referenced_articles\n",
    "                    ORDER BY score DESC\n",
    "                    LIMIT 2\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    precedent_results = session.run(\n",
    "                        precedent_query,\n",
    "                        article_id=article_result[\"id\"],\n",
    "                        query_embedding=query_embedding,\n",
    "                        query_keywords=keywords\n",
    "                    )\n",
    "                    \n",
    "                    for record in precedent_results:\n",
    "                        # 중복 제거\n",
    "                        if not any(r[\"type\"] == \"Precedent\" and r[\"id\"] == record[\"id\"] for r in results):\n",
    "                            results.append({\n",
    "                                \"type\": record[\"type\"],\n",
    "                                \"id\": record[\"id\"],\n",
    "                                \"name\": record[\"name\"],\n",
    "                                \"score\": record[\"score\"],\n",
    "                                \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                                \"keywords\": record[\"keywords\"],\n",
    "                                \"referenced_articles\": record[\"referenced_articles\"]\n",
    "                            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"그래프 검색 오류: {e}\")\n",
    "            # 백업: 기본 벡터 검색\n",
    "            try:\n",
    "                # Article 검색\n",
    "                article_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    RETURN node.id AS id, 'Article' as type, node.text AS text, score\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in article_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"]\n",
    "                    })\n",
    "                \n",
    "                # Precedent 검색\n",
    "                precedent_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                    OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                    RETURN node.id AS id, 'Precedent' as type, \n",
    "                           node.name AS name, node.full_summary AS text, \n",
    "                           score,\n",
    "                           collect(DISTINCT a.id) as referenced_articles,\n",
    "                           collect(DISTINCT k.text) as keywords\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in precedent_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"name\": record[\"name\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                        \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                        \"keywords\": record[\"keywords\"]\n",
    "                    })\n",
    "            except Exception as e2:\n",
    "                print(f\"백업 검색 오류: {e2}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"검색 완료: {end_time - start_time:.2f}초 소요\")\n",
    "\n",
    "    # 결과를 스코어로 정렬\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    print(\"\\n--- 검색 결과 ---\")\n",
    "    for i, res in enumerate(results[:top_k]):\n",
    "        print(f\"{i+1}. 유형: {res['type']}, ID: {res['id']}, 스코어: {res['score']:.4f}\")\n",
    "        if res['type'] == 'Precedent':\n",
    "            print(f\"   이름: {res.get('name')}\")\n",
    "            print(f\"   키워드: {res.get('keywords')}\")\n",
    "            print(f\"   참조 법조항: {res.get('referenced_articles')}\")\n",
    "        elif res['type'] == 'Article':\n",
    "            print(f\"   관련 판례 수: {res.get('precedent_count', 0)}\")\n",
    "            print(f\"   관련 키워드: {res.get('related_keywords')}\")\n",
    "        print(f\"   미리보기: {res['text']}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75ae38b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 하이브리드 검색 실행: '정당방위의 요건은 무엇인가?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_82042/3526074224.py:12: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=\"neo4j\") as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 완료: 3.40초 소요\n",
      "\n",
      "--- 검색 결과 ---\n",
      "1. 유형: Precedent, ID: 92도2540, 스코어: 0.7910\n",
      "   이름: 살인\n",
      "   키워드: ['타인의 법익', '상당한 이유']\n",
      "   참조 법조항: ['제10조(심신장애자)', '제21조(정당방위)', '제308조(사자의 명예훼손)', '제308조', '제10조 (폐지되는 법률등)']\n",
      "   미리보기: 정당방위의 성립요건으로서의 방어행위에는 순수한 수비적 방어뿐 아니라 적극적 반격을 포함하는 반격방어의 형태도 포함됨은 소론과 같다고 하겠으나, 그 방어행위는 자기 또는 타인의 법익침해를 방위하기 위한 행위로서 상당한 이유가 있어야 하는 것인데, 피고인들의 판시 행위가 위에서 본 바와 같이 그 상당성을 결여한 것인 이상 정당방위행위로 평가될 수는 없는 것이므로, 원심이 피고인들의 이 사건 범행이 현재의 부당한 침해를 방위할 의사로 행해졌다기보다는 공격의 의사로 행하여졌다고 인정한 것이 적절하지 못하다고 하더라도, 정당방위행위가 되지 ...\n",
      "--------------------\n",
      "2. 유형: Precedent, ID: 2003도4934, 스코어: 0.7295\n",
      "   이름: 명예훼손(일부 인정된 죄명 : 모욕)·폭행\n",
      "   키워드: ['사회상규에 위배되지 아니하는 행위', '행위의 수단이나 방법의 상당성']\n",
      "   참조 법조항: ['제20조(정당행위)', '제21조(정당방위)', '제232조(자격모용에 의한 사문서의 작성)', '제232조의2(사전자기록위작ㆍ변작)', '제260조(폭행, 존속폭행)', '제260조', '제307조(명예훼손)', '제307조', '제311조(모욕)', '제312조(고소와 피해자의 의사)', '제311조', '제314조(업무방해)', '제316조(비밀침해)']\n",
      "   미리보기: 형법 제20조 소정의 ‘사회상규에 위배되지 아니하는 행위’라 함은 법질서 전체의 정신이나 그 배후에 놓여 있는 사회윤리 내지 사회통념에 비추어 용인될 수 있는 행위를 말하고, 어떠한 행위가 사회상규에 위배되지 아니하는 정당한 행위로서 위법성이 조각되는 것인지는 구체적인 사정 아래서 합목적적, 합리적으로 고찰하여 개별적으로 판단되어야 하므로, 이와 같은 정당행위가 인정되려면, 첫째 그 행위의 동기나 목적의 정당성, 둘째 행위의 수단이나 방법의 상당성, 셋째 보호이익과 침해이익의 법익 균형성, 넷째 긴급성, 다섯째 그 행위 이외의 다른...\n",
      "--------------------\n",
      "3. 유형: Precedent, ID: 83도3124, 스코어: 0.7163\n",
      "   이름: 출판물에의한명예훼손\n",
      "   키워드: ['불특정 다수인']\n",
      "   참조 법조항: ['제20조(정당행위)', '제307조(명예훼손)', '제309조(출판물 등에 의한 명예훼손)', '제307조', '제310조(위법성의 조각)', '제309조']\n",
      "   미리보기: 명예훼손죄의 요건인 공연성은 불특정 또는 다수인이 인식할 수 있는 상태를 말하므로, 원심확정과 같이 피고인들이 이 사건 출판물 15부를 피고인들이 소속된 교회의 교인 15인에게 배부한 이상 공연성의 요건은 충족된 것이라고 보겠으며 배부받은 사람중 일부가 소론과 같이 위 출판물작성에 가담한 사람들이라고 하여도 결론에 아무런 소장이 없으니, 명예훼손죄의 성립을 인정한 원심조치에 소론과 같이 공연성에 관한 법리를 오해한 위법이 없다. 또 위 출판물에 게재된 내용이 허위사실인 이상 당연히 위법성이 인정되는 것이고 사회통념상 위법성이 인정되...\n",
      "--------------------\n",
      "\n",
      "Neo4j 드라이버 연결 종료\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 검색 함수 선택 (세 가지 중 하나 사용)\n",
    "search_function = hybrid_query_rag  # 또는 multi_step_rag 또는 graph_enhanced_rag\n",
    "\n",
    "# 테스트 쿼리\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = search_function(driver, query, embedding_model, top_k=3)\n",
    "\n",
    "# 드라이버 연결 종료\n",
    "driver.close()\n",
    "print(\"\\nNeo4j 드라이버 연결 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14ec350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 다단계 검색 실행: '정당방위의 요건은 무엇인가?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_82042/486282187.py:9: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=\"neo4j\") as session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 완료: 3.40초 소요\n",
      "\n",
      "--- 검색 결과 ---\n",
      "1. 유형: Precedent, ID: 92도2540, 스코어: 0.7386\n",
      "   이름: 살인\n",
      "   키워드: ['타인의 법익', '상당한 이유']\n",
      "   참조 법조항: ['제10조(심신장애자)', '제21조(정당방위)', '제308조(사자의 명예훼손)', '제308조', '제10조 (폐지되는 법률등)']\n",
      "   미리보기: 정당방위의 성립요건으로서의 방어행위에는 순수한 수비적 방어뿐 아니라 적극적 반격을 포함하는 반격방어의 형태도 포함됨은 소론과 같다고 하겠으나, 그 방어행위는 자기 또는 타인의 법익침해를 방위하기 위한 행위로서 상당한 이유가 있어야 하는 것인데, 피고인들의 판시 행위가 위에서 본 바와 같이 그 상당성을 결여한 것인 이상 정당방위행위로 평가될 수는 없는 것이므로, 원심이 피고인들의 이 사건 범행이 현재의 부당한 침해를 방위할 의사로 행해졌다기보다는 공격의 의사로 행하여졌다고 인정한 것이 적절하지 못하다고 하더라도, 정당방위행위가 되지 ...\n",
      "--------------------\n",
      "2. 유형: Precedent, ID: 2009도2114, 스코어: 0.6940\n",
      "   이름: 특수공무집행방해[변경된죄명:폭력행위등처벌에관한법률위반(공동폭행)]\n",
      "   키워드: ['사회상규에 위배', '소극적인 방어행위']\n",
      "   참조 법조항: ['제6조(대한민국과 대한민국 국민에 대한 국외범)', '제20조(정당행위)', '제21조(정당방위)', '제136조(공무집행방해)', '제136조', '제260조(폭행, 존속폭행)', '제260조', '제6조 (경합범에 대한 신법의 적용례)', '제6조']\n",
      "   미리보기: 비록 경찰관들의 위법한 상경 제지 행위에 대항하기 위하여 한 것이라 하더라도, 피고인들이 다른 시위참가자들과 공동하여 위와 같이 경찰관들을 때리고 진압방패와 채증장비를 빼앗는 등의 폭행행위를 한 것은 소극적인 방어행위를 넘어서 공격의 의사를 포함하여 이루어진 것으로서 그 수단과 방법에 있어서 상당성이 인정된다고 보기 어려우며 긴급하고 불가피한 수단이었다고 볼 수도 없으므로, 이를 사회상규에 위배되지 아니하는 정당행위나 현재의 부당한 침해를 방어하기 위한 정당방위에 해당한다고 볼 수 없다.\n",
      "그럼에도 불구하고, 원심은 그 판시와 같은 ...\n",
      "--------------------\n",
      "3. 유형: Precedent, ID: 83누383, 스코어: 0.6791\n",
      "   이름: 영업정지처분무효확인\n",
      "   키워드: ['법령 위반행위']\n",
      "   참조 법조항: ['제1조(범죄의 성립과 처벌)', '제34조(간접정범, 특수한 교사, 방조에 대한 형의 가중)', '제37조(경합범)', '제38조(경합범과 처벌례)', '제34조', '제1조 (구형법 기타 법령과 형의 경중)', '제1조 (시행일)']\n",
      "   미리보기: 정당한 절차에 의하지 않고 구두에 의한 하도급계약을 체결하여 공사를 시작한 때에건설업법 제34조 제3항의 위반행위를 범한 것이 되니 그 위반행위를 이유로 한 행정상의 제재처분(행위당시에는 필요적 취소사유)을 하려면 그 위반행위 이후 법령의 변경에 의하여 처분의 종류를 달리(영업정지 사유로) 규정하였다 하더라도 그 법률적용에 관한특별한 규정이 없다면 위반행위 당시에 시행되던 법령을 근거로 처분을 하여야 마땅하다.\n",
      "--------------------\n",
      "\n",
      "Neo4j 드라이버 연결 종료\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 검색 함수 선택 (세 가지 중 하나 사용)\n",
    "search_function = multi_step_rag  # 또는 multi_step_rag 또는 graph_enhanced_rag\n",
    "\n",
    "# 테스트 쿼리\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = search_function(driver, query, embedding_model, top_k=3)\n",
    "\n",
    "# 드라이버 연결 종료\n",
    "driver.close()\n",
    "print(\"\\nNeo4j 드라이버 연결 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe44527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 그래프 기반 검색 실행: '정당방위의 요건은 무엇인가?' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_82042/1334283577.py:12: DeprecationWarning: Using a driver after it has been closed is deprecated. Future versions of the driver will raise an error.\n",
      "  with driver.session(database=\"neo4j\") as session:\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: \"\\n            // 1. 벡터 검색으로 시작 법조항 찾기\\n            CALL db.index.vector.queryNodes('article_embedding', 5, $query_embedding) \\n            YIELD node as article, score as article_score\\n            \\n            // 2. 해당 법조항과 연결된 판례와 키워드 찾기\\n            OPTIONAL MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article)\\n            OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\\n            \\n            // 3. 결과 집계 및 점수 계산\\n            WITH article, article_score, precedent, \\n                 collect(DISTINCT keyword.text) as keywords,\\n                 count(precedent) as precedent_count\\n            \\n            // 법조항 점수 = 벡터 점수 + 판례 인용 수에 따른 보너스\\n            WITH article, article_score + (precedent_count * 0.01) as final_score,\\n                 precedent_count, keywords\\n            \\n            RETURN article.id as id, \\n                   'Article' as type, \\n                   article.text as text, \\n                   final_score as score,\\n                   precedent_count,\\n                   keywords\\n            ORDER BY final_score DESC\\n            LIMIT $article_limit\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색 완료: 3.51초 소요\n",
      "\n",
      "--- 검색 결과 ---\n",
      "1. 유형: Article, ID: 제21조(정당방위), 스코어: 0.7724\n",
      "   관련 판례 수: 7\n",
      "   관련 키워드: ['공소시효', '정지', '연장', '배제', '특례조항', '소급적용', '경과규정']\n",
      "   미리보기: 제21조(정당방위) ①자기 또는 타인의 법익에 대한 현재의 부당한 침해를 방위하기 위한 행위는\n",
      "상당한 이유가 있는 때에는 벌하지 아니한다.\n",
      "②방위행위가 그 정도를 초과한 때에는 정황에 의하여 그 형을 감경 또는 면제할 수 있다.\n",
      "③전항의 경우에 그 행위가 야간 기타 불안스러운 상태하에서 공포, 경악, 흥분 또는 당황으로\n",
      "인한 때에는 벌하지 아니한다.\n",
      "--------------------\n",
      "2. 유형: Article, ID: 제21조(정당방위), 스코어: 0.7624\n",
      "   관련 판례 수: 6\n",
      "   관련 키워드: ['성범죄', '선고형', '경합범', '성폭력처벌법', '개정', '신상정보 등록기간']\n",
      "   미리보기: 제21조(정당방위) ①자기 또는 타인의 법익에 대한 현재의 부당한 침해를 방위하기 위한 행위는\n",
      "상당한 이유가 있는 때에는 벌하지 아니한다.\n",
      "②방위행위가 그 정도를 초과한 때에는 정황에 의하여 그 형을 감경 또는 면제할 수 있다.\n",
      "③전항의 경우에 그 행위가 야간 기타 불안스러운 상태하에서 공포, 경악, 흥분 또는 당황으로\n",
      "인한 때에는 벌하지 아니한다.\n",
      "--------------------\n",
      "3. 유형: Precedent, ID: 92도2540, 스코어: 0.7387\n",
      "   이름: 살인\n",
      "   키워드: ['타인의 법익', '상당한 이유']\n",
      "   참조 법조항: ['제10조(심신장애자)', '제21조(정당방위)', '제308조(사자의 명예훼손)', '제308조', '제10조 (폐지되는 법률등)']\n",
      "   미리보기: 정당방위의 성립요건으로서의 방어행위에는 순수한 수비적 방어뿐 아니라 적극적 반격을 포함하는 반격방어의 형태도 포함됨은 소론과 같다고 하겠으나, 그 방어행위는 자기 또는 타인의 법익침해를 방위하기 위한 행위로서 상당한 이유가 있어야 하는 것인데, 피고인들의 판시 행위가 위에서 본 바와 같이 그 상당성을 결여한 것인 이상 정당방위행위로 평가될 수는 없는 것이므로, 원심이 피고인들의 이 사건 범행이 현재의 부당한 침해를 방위할 의사로 행해졌다기보다는 공격의 의사로 행하여졌다고 인정한 것이 적절하지 못하다고 하더라도, 정당방위행위가 되지 ...\n",
      "--------------------\n",
      "\n",
      "Neo4j 드라이버 연결 종료\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 검색 함수 선택 (세 가지 중 하나 사용)\n",
    "search_function = graph_enhanced_rag  # 또는 multi_step_rag 또는 graph_enhanced_rag\n",
    "\n",
    "# 테스트 쿼리\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = search_function(driver, query, embedding_model, top_k=3)\n",
    "\n",
    "# 드라이버 연결 종료\n",
    "driver.close()\n",
    "print(\"\\nNeo4j 드라이버 연결 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86ae1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
