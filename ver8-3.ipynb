{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59e24c6",
   "metadata": {},
   "source": [
    "claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5285abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 설정 완료 및 필요 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "한국 형법 RAG 에이전트 시스템\n",
    "================================\n",
    "Korean Criminal Law Retrieval-Augmented Generation Agent System\n",
    "\n",
    "모듈화된 효율적인 한국 형법 Question-Answering 시스템\n",
    "- 데이터 모델링, Repository 패턴, 파이프라인 아키텍처 적용\n",
    "- KMMLU Criminal-Law 카테고리 평가용\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "from typing import List, Dict, Any, Optional, Union, Tuple, Set\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 외부 라이브러리\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from neo4j import GraphDatabase\n",
    "from openai import OpenAI\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 설정\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# 폴더 생성\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"dataset\", exist_ok=True)\n",
    "\n",
    "print(\"환경 설정 완료 및 필요 라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e632018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 모델 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터 모델 클래스\n",
    "# ================\n",
    "\n",
    "@dataclass\n",
    "class Article:\n",
    "    \"\"\"법조항 정보를 담는 클래스\"\"\"\n",
    "    id: str\n",
    "    text: str\n",
    "    embedding: Optional[List[float]] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"딕셔너리 변환\"\"\"\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"text\": self.text,\n",
    "            \"embedding\": self.embedding\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Precedent:\n",
    "    \"\"\"판례 정보를 담는 클래스\"\"\"\n",
    "    id: str\n",
    "    name: Optional[str] = None\n",
    "    judgment_summary: Optional[str] = None\n",
    "    full_summary: Optional[str] = None\n",
    "    keywords: List[str] = field(default_factory=list)\n",
    "    referenced_rules: List[str] = field(default_factory=list)\n",
    "    referenced_cases: List[str] = field(default_factory=list)\n",
    "    embedding: Optional[List[float]] = None\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"딕셔너리 변환\"\"\"\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"name\": self.name,\n",
    "            \"judgment_summary\": self.judgment_summary,\n",
    "            \"full_summary\": self.full_summary,\n",
    "            \"keywords\": self.keywords,\n",
    "            \"referenced_rules\": self.referenced_rules,\n",
    "            \"referenced_cases\": self.referenced_cases,\n",
    "            \"embedding\": self.embedding\n",
    "        }\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"검색 결과를 담는 클래스\"\"\"\n",
    "    id: str\n",
    "    type: str  # \"Article\" 또는 \"Precedent\"\n",
    "    score: float\n",
    "    text: str\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"딕셔너리 변환\"\"\"\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"type\": self.type,\n",
    "            \"score\": self.score,\n",
    "            \"text\": self.text,\n",
    "            \"metadata\": self.metadata\n",
    "        }\n",
    "\n",
    "print(\"데이터 모델 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11bddb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j 리포지토리 베이스 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# Neo4j 리포지토리 클래스\n",
    "# =====================\n",
    "\n",
    "class Neo4jRepository:\n",
    "    \"\"\"Neo4j 데이터베이스 연결 및 기본 작업을 위한 베이스 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, uri: str, username: str, password: str, database: str = \"neo4j\"):\n",
    "        \"\"\"Neo4j 연결 초기화\n",
    "        \n",
    "        Args:\n",
    "            uri: Neo4j 서버 URI\n",
    "            username: 사용자명\n",
    "            password: 비밀번호\n",
    "            database: 데이터베이스 이름\n",
    "        \"\"\"\n",
    "        self.uri = uri\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        self.driver = None\n",
    "        \n",
    "    def connect(self) -> None:\n",
    "        \"\"\"Neo4j 데이터베이스에 연결\"\"\"\n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(\n",
    "                self.uri, \n",
    "                auth=(self.username, self.password)\n",
    "            )\n",
    "            self.driver.verify_connectivity()\n",
    "            print(\"Successfully connected to Neo4j.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to connect to Neo4j: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def close(self) -> None:\n",
    "        \"\"\"연결 종료\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "            self.driver = None\n",
    "            print(\"Neo4j connection closed.\")\n",
    "    \n",
    "    def run_query(self, query: str, parameters: Dict[str, Any] = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Neo4j 쿼리 실행\n",
    "        \n",
    "        Args:\n",
    "            query: Cypher 쿼리\n",
    "            parameters: 쿼리 파라미터\n",
    "            \n",
    "        Returns:\n",
    "            쿼리 결과\n",
    "        \"\"\"\n",
    "        if not self.driver:\n",
    "            self.connect()\n",
    "            \n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return [record.data() for record in result]\n",
    "            \n",
    "    def setup_constraints_and_indexes(self, embedding_dimension: int) -> None:\n",
    "        \"\"\"제약조건 및 인덱스 설정\n",
    "        \n",
    "        Args:\n",
    "            embedding_dimension: 임베딩 벡터 차원\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 고유성 제약조건 설정\n",
    "            self.run_query(\"CREATE CONSTRAINT article_id IF NOT EXISTS FOR (a:Article) REQUIRE a.id IS UNIQUE\")\n",
    "            self.run_query(\"CREATE CONSTRAINT precedent_id IF NOT EXISTS FOR (p:Precedent) REQUIRE p.id IS UNIQUE\")\n",
    "            self.run_query(\"CREATE CONSTRAINT keyword_text IF NOT EXISTS FOR (k:Keyword) REQUIRE k.text IS UNIQUE\")\n",
    "            \n",
    "            # 벡터 인덱스 생성\n",
    "            try:\n",
    "                self.run_query(\n",
    "                    \"CREATE VECTOR INDEX article_embedding IF NOT EXISTS \"\n",
    "                    \"FOR (a:Article) ON (a.embedding) \"\n",
    "                    f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {embedding_dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "                )\n",
    "                print(\"Article vector index created or already exists.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Article vector index: {e}\")\n",
    "                \n",
    "            try:\n",
    "                self.run_query(\n",
    "                    \"CREATE VECTOR INDEX precedent_embedding IF NOT EXISTS \"\n",
    "                    \"FOR (p:Precedent) ON (p.embedding) \"\n",
    "                    f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {embedding_dimension}, `vector.similarity_function`: 'cosine'}}}}\"\n",
    "                )\n",
    "                print(\"Precedent vector index created or already exists.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating Precedent vector index: {e}\")\n",
    "                \n",
    "            # 인덱스가 활성화될 때까지 대기\n",
    "            print(\"Waiting for indexes to populate...\")\n",
    "            self.run_query(\"CALL db.awaitIndexes(300)\")\n",
    "            print(\"Indexes are now online.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up constraints and indexes: {e}\")\n",
    "            raise\n",
    "\n",
    "print(\"Neo4j 리포지토리 베이스 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb968f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법조항 리포지토리 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class ArticleRepository(Neo4jRepository):\n",
    "    \"\"\"법조항 관련 데이터베이스 작업을 처리하는 클래스\"\"\"\n",
    "    \n",
    "    def create_article(self, article: Article) -> None:\n",
    "        \"\"\"법조항 노드 생성\n",
    "        \n",
    "        Args:\n",
    "            article: 법조항 객체\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        MERGE (a:Article {id: $article_id})\n",
    "        SET a.text = $content,\n",
    "            a.embedding = $embedding\n",
    "        \"\"\"\n",
    "        self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"article_id\": article.id,\n",
    "                \"content\": article.text,\n",
    "                \"embedding\": article.embedding\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def create_bulk_articles(self, articles: List[Article], batch_size: int = 50) -> int:\n",
    "        \"\"\"다수의 법조항 노드 생성\n",
    "        \n",
    "        Args:\n",
    "            articles: 법조항 객체 리스트\n",
    "            batch_size: 배치 크기\n",
    "            \n",
    "        Returns:\n",
    "            생성된 법조항 수\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 벌크 연산을 위한 쿼리 최적화\n",
    "        batch_query = \"\"\"\n",
    "        UNWIND $articles AS article\n",
    "        MERGE (a:Article {id: article.id})\n",
    "        SET a.text = article.text,\n",
    "            a.embedding = article.embedding\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(0, len(articles), batch_size):\n",
    "            batch = articles[i:i+batch_size]\n",
    "            \n",
    "            # 유효한 항목만 필터링\n",
    "            valid_articles = []\n",
    "            for article in batch:\n",
    "                if not article.text:\n",
    "                    print(f\"Skipping article {article.id} due to empty content.\")\n",
    "                    continue\n",
    "                \n",
    "                valid_articles.append({\n",
    "                    \"id\": article.id,\n",
    "                    \"text\": article.text,\n",
    "                    \"embedding\": article.embedding\n",
    "                })\n",
    "                \n",
    "            if valid_articles:\n",
    "                try:\n",
    "                    self.run_query(batch_query, {\"articles\": valid_articles})\n",
    "                    count += len(valid_articles)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing article batch: {e}\")\n",
    "                    \n",
    "                    # 실패 시 개별 처리로 폴백\n",
    "                    for article_data in valid_articles:\n",
    "                        try:\n",
    "                            article = Article(\n",
    "                                id=article_data[\"id\"],\n",
    "                                text=article_data[\"text\"],\n",
    "                                embedding=article_data[\"embedding\"]\n",
    "                            )\n",
    "                            self.create_article(article)\n",
    "                            count += 1\n",
    "                        except Exception as e2:\n",
    "                            print(f\"Error processing article {article_data['id']}: {e2}\")\n",
    "            \n",
    "            if (i + batch_size) % (batch_size * 5) == 0:\n",
    "                print(f\"  Processed {i + batch_size}/{len(articles)} articles...\")\n",
    "                \n",
    "        end_time = time.time()\n",
    "        print(f\"Finished creating {count} Article nodes in {end_time - start_time:.2f} seconds.\")\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def find_article_by_id(self, article_id: str) -> Optional[Article]:\n",
    "        \"\"\"ID로 법조항 찾기\n",
    "        \n",
    "        Args:\n",
    "            article_id: 법조항 ID\n",
    "            \n",
    "        Returns:\n",
    "            법조항 객체 또는 None\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        MATCH (a:Article {id: $article_id})\n",
    "        RETURN a.id as id, a.text as text, a.embedding as embedding\n",
    "        \"\"\"\n",
    "        results = self.run_query(query, {\"article_id\": article_id})\n",
    "        \n",
    "        if not results:\n",
    "            return None\n",
    "            \n",
    "        result = results[0]\n",
    "        return Article(\n",
    "            id=result[\"id\"],\n",
    "            text=result[\"text\"],\n",
    "            embedding=result[\"embedding\"]\n",
    "        )\n",
    "    \n",
    "    def search_articles_by_vector(self, query_embedding: List[float], limit: int = 5) -> List[SearchResult]:\n",
    "        \"\"\"벡터 유사도 기반 법조항 검색 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            query_embedding: 쿼리 임베딩\n",
    "            limit: 최대 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            검색 결과 리스트\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        CALL db.index.vector.queryNodes('article_embedding', $limit, $query_embedding) \n",
    "        YIELD node, score\n",
    "        RETURN node.id AS id, node.text AS text, score\n",
    "        \"\"\"\n",
    "        results = self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"limit\": limit,\n",
    "                \"query_embedding\": query_embedding\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SearchResult(\n",
    "                id=result[\"id\"],\n",
    "                type=\"Article\",\n",
    "                score=result[\"score\"],\n",
    "                text=result[\"text\"]\n",
    "            )\n",
    "            for result in results\n",
    "        ]\n",
    "    \n",
    "    def search_articles_related_to_precedents(self, query_embedding: List[float], top_k: int = 8) -> List[SearchResult]:\n",
    "        \"\"\"판례 관계를 고려한 법조항 검색 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            query_embedding: 쿼리 임베딩\n",
    "            top_k: 최대 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            검색 결과 리스트\n",
    "        \"\"\"\n",
    "        # 최적화된 쿼리: 불필요한 중간 집계 제거, 인덱스 활용 극대화\n",
    "        query = \"\"\"\n",
    "        // 1. 벡터 검색으로 시작 법조항 찾기 - 더 많은 후보를 가져옴\n",
    "        CALL db.index.vector.queryNodes('article_embedding', $initial_limit, $query_embedding) \n",
    "        YIELD node as article, score as article_score\n",
    "        \n",
    "        // 2. 법조항과 판례 관계 및 공통 키워드 계산\n",
    "        WITH article, article_score\n",
    "        \n",
    "        // 판례 관계 파악 \n",
    "        OPTIONAL MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article)\n",
    "        WITH article, article_score, count(precedent) as precedent_count\n",
    "        \n",
    "        // 3. 최종 점수 계산 (벡터 점수 + 판례 인용 보너스)\n",
    "        WITH article, \n",
    "            article_score + (precedent_count * 0.02) as final_score,\n",
    "            precedent_count\n",
    "        \n",
    "        // 판례와 키워드 정보 수집\n",
    "        OPTIONAL MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article)\n",
    "        OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "        \n",
    "        // 4. 결과 집계 및 반환\n",
    "        WITH article, final_score, precedent_count, \n",
    "             collect(DISTINCT keyword.text) as keywords\n",
    "        \n",
    "        RETURN article.id as id, \n",
    "               article.text as text, \n",
    "               final_score as score,\n",
    "               precedent_count,\n",
    "               keywords\n",
    "        ORDER BY final_score DESC\n",
    "        LIMIT $top_k\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"initial_limit\": top_k * 3,  # 더 많은 후보를 검색해 관계 점수를 반영\n",
    "                \"top_k\": top_k,\n",
    "                \"query_embedding\": query_embedding\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SearchResult(\n",
    "                id=result[\"id\"],\n",
    "                type=\"Article\",\n",
    "                score=result[\"score\"],\n",
    "                text=result[\"text\"],\n",
    "                metadata={\n",
    "                    \"precedent_count\": result[\"precedent_count\"],\n",
    "                    \"related_keywords\": result[\"keywords\"]\n",
    "                }\n",
    "            )\n",
    "            for result in results\n",
    "        ]\n",
    "\n",
    "print(\"법조항 리포지토리 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70cfb28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "판례 리포지토리 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "class PrecedentRepository(Neo4jRepository):\n",
    "    \"\"\"판례 관련 데이터베이스 작업을 처리하는 클래스\"\"\"\n",
    "    \n",
    "    def create_precedent(self, precedent: Precedent) -> None:\n",
    "        \"\"\"판례 노드 생성\n",
    "        \n",
    "        Args:\n",
    "            precedent: 판례 객체\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        MERGE (p:Precedent {id: $case_id})\n",
    "        SET p.name = $case_name,\n",
    "            p.judgment_summary = $judgment_summary,\n",
    "            p.full_summary = $full_summary,\n",
    "            p.embedding = $embedding\n",
    "        \"\"\"\n",
    "        self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"case_id\": precedent.id,\n",
    "                \"case_name\": precedent.name,\n",
    "                \"judgment_summary\": precedent.judgment_summary,\n",
    "                \"full_summary\": precedent.full_summary,\n",
    "                \"embedding\": precedent.embedding\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # 키워드 노드 생성 및 관계 설정 (최적화: 벌크 처리)\n",
    "        if precedent.keywords:\n",
    "            keywords_query = \"\"\"\n",
    "            UNWIND $keywords AS keyword_text\n",
    "            MERGE (k:Keyword {text: keyword_text})\n",
    "            WITH k\n",
    "            MATCH (p:Precedent {id: $case_id})\n",
    "            MERGE (p)-[:HAS_KEYWORD]->(k)\n",
    "            \"\"\"\n",
    "            self.run_query(\n",
    "                keywords_query,\n",
    "                {\n",
    "                    \"keywords\": precedent.keywords,\n",
    "                    \"case_id\": precedent.id\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        # 참조 법조항 관계 설정 (최적화: 벌크 처리)\n",
    "        if precedent.referenced_rules:\n",
    "            rules_query = \"\"\"\n",
    "            MATCH (p:Precedent {id: $case_id})\n",
    "            UNWIND $article_refs AS article_ref\n",
    "            MATCH (a:Article)\n",
    "            WHERE a.id STARTS WITH article_ref\n",
    "            MERGE (p)-[:REFERENCES_ARTICLE]->(a)\n",
    "            \"\"\"\n",
    "            self.run_query(\n",
    "                rules_query,\n",
    "                {\n",
    "                    \"case_id\": precedent.id,\n",
    "                    \"article_refs\": precedent.referenced_rules\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    def create_bulk_precedents(self, precedents: List[Precedent], batch_size: int = 25) -> int:\n",
    "        \"\"\"다수의 판례 노드 생성\n",
    "        \n",
    "        Args:\n",
    "            precedents: 판례 객체 리스트\n",
    "            batch_size: 배치 크기\n",
    "            \n",
    "        Returns:\n",
    "            생성된 판례 수\n",
    "        \"\"\"\n",
    "        count = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 벌크 연산을 위한 쿼리 최적화\n",
    "        batch_query = \"\"\"\n",
    "        UNWIND $precedents AS precedent\n",
    "        MERGE (p:Precedent {id: precedent.id})\n",
    "        SET p.name = precedent.name,\n",
    "            p.judgment_summary = precedent.judgment_summary,\n",
    "            p.full_summary = precedent.full_summary,\n",
    "            p.embedding = precedent.embedding\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(0, len(precedents), batch_size):\n",
    "            batch = precedents[i:i+batch_size]\n",
    "            \n",
    "            # 유효한 항목만 필터링\n",
    "            valid_precedents = []\n",
    "            for precedent in batch:\n",
    "                text_to_embed = precedent.full_summary or precedent.judgment_summary\n",
    "                if not text_to_embed:\n",
    "                    print(f\"Skipping precedent {precedent.id} due to empty summary.\")\n",
    "                    continue\n",
    "                \n",
    "                valid_precedents.append({\n",
    "                    \"id\": precedent.id,\n",
    "                    \"name\": precedent.name,\n",
    "                    \"judgment_summary\": precedent.judgment_summary,\n",
    "                    \"full_summary\": precedent.full_summary,\n",
    "                    \"embedding\": precedent.embedding\n",
    "                })\n",
    "            \n",
    "            if valid_precedents:\n",
    "                try:\n",
    "                    # 1. 노드 생성\n",
    "                    self.run_query(batch_query, {\"precedents\": valid_precedents})\n",
    "                    \n",
    "                    # 2. 키워드 및 관계 설정\n",
    "                    for precedent in batch:\n",
    "                        if precedent.full_summary or precedent.judgment_summary:\n",
    "                            # 키워드 노드 및 관계 설정\n",
    "                            if precedent.keywords:\n",
    "                                self.run_query(\n",
    "                                    \"\"\"\n",
    "                                    UNWIND $keywords AS keyword_text\n",
    "                                    MERGE (k:Keyword {text: keyword_text})\n",
    "                                    WITH k\n",
    "                                    MATCH (p:Precedent {id: $case_id})\n",
    "                                    MERGE (p)-[:HAS_KEYWORD]->(k)\n",
    "                                    \"\"\",\n",
    "                                    {\n",
    "                                        \"keywords\": precedent.keywords,\n",
    "                                        \"case_id\": precedent.id\n",
    "                                    }\n",
    "                                )\n",
    "                            \n",
    "                            # 참조 법조항 관계 설정\n",
    "                            if precedent.referenced_rules:\n",
    "                                self.run_query(\n",
    "                                    \"\"\"\n",
    "                                    MATCH (p:Precedent {id: $case_id})\n",
    "                                    UNWIND $article_refs AS article_ref\n",
    "                                    MATCH (a:Article)\n",
    "                                    WHERE a.id STARTS WITH article_ref\n",
    "                                    MERGE (p)-[:REFERENCES_ARTICLE]->(a)\n",
    "                                    \"\"\",\n",
    "                                    {\n",
    "                                        \"case_id\": precedent.id,\n",
    "                                        \"article_refs\": precedent.referenced_rules\n",
    "                                    }\n",
    "                                )\n",
    "                            \n",
    "                            count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing precedent batch: {e}\")\n",
    "                    \n",
    "                    # 실패 시 개별 처리로 폴백\n",
    "                    for precedent in batch:\n",
    "                        text_to_embed = precedent.full_summary or precedent.judgment_summary\n",
    "                        if text_to_embed:\n",
    "                            try:\n",
    "                                self.create_precedent(precedent)\n",
    "                                count += 1\n",
    "                            except Exception as e2:\n",
    "                                print(f\"Error processing precedent {precedent.id}: {e2}\")\n",
    "            \n",
    "            if (i + batch_size) % (batch_size * 2) == 0:\n",
    "                print(f\"  Processed {i + batch_size}/{len(precedents)} precedents...\")\n",
    "                \n",
    "        end_time = time.time()\n",
    "        print(f\"Finished creating {count} Precedent nodes in {end_time - start_time:.2f} seconds.\")\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def search_precedents_by_vector(self, query_embedding: List[float], limit: int = 5) -> List[SearchResult]:\n",
    "        \"\"\"벡터 유사도 기반 판례 검색 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            query_embedding: 쿼리 임베딩\n",
    "            limit: 최대 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            검색 결과 리스트\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        CALL db.index.vector.queryNodes('precedent_embedding', $limit, $query_embedding) \n",
    "        YIELD node, score\n",
    "        \n",
    "        // 관계 정보 한 번에 가져오기 (최적화)\n",
    "        OPTIONAL MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "        OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "        \n",
    "        // 결과 집계 및 반환\n",
    "        RETURN node.id AS id, \n",
    "               node.name AS name, \n",
    "               node.full_summary AS text, \n",
    "               score,\n",
    "               collect(DISTINCT a.id) as referenced_articles,\n",
    "               collect(DISTINCT k.text) as keywords\n",
    "        \"\"\"\n",
    "        results = self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"limit\": limit,\n",
    "                \"query_embedding\": query_embedding\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SearchResult(\n",
    "                id=result[\"id\"],\n",
    "                type=\"Precedent\",\n",
    "                score=result[\"score\"],\n",
    "                text=result[\"text\"],\n",
    "                metadata={\n",
    "                    \"name\": result[\"name\"],\n",
    "                    \"referenced_articles\": result[\"referenced_articles\"],\n",
    "                    \"keywords\": result[\"keywords\"]\n",
    "                }\n",
    "            )\n",
    "            for result in results\n",
    "        ]\n",
    "    \n",
    "    def search_precedents_by_article(self, \n",
    "                                    article_id: str, \n",
    "                                    query_embedding: List[float], \n",
    "                                    query_keywords: List[str] = None, \n",
    "                                    limit: int = 2) -> List[SearchResult]:\n",
    "        \"\"\"특정 법조항과 관련된 판례 검색 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            article_id: 법조항 ID\n",
    "            query_embedding: 쿼리 임베딩\n",
    "            query_keywords: 쿼리 키워드\n",
    "            limit: 최대 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            검색 결과 리스트\n",
    "        \"\"\"\n",
    "        # 최적화된 쿼리\n",
    "        query = \"\"\"\n",
    "        // 1. 특정 법조항을 참조하는 판례 찾기 + 벡터 유사도 동시 계산\n",
    "        MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article:Article)\n",
    "        WHERE article.id STARTS WITH $article_id\n",
    "        \n",
    "        // 2. 벡터 유사도 계산 (더 효율적인 처리)\n",
    "        CALL {\n",
    "            WITH precedent\n",
    "            CALL db.index.vector.queryNodes('precedent_embedding', 100, $query_embedding) \n",
    "            YIELD node, score\n",
    "            WHERE node = precedent\n",
    "            RETURN node as precedent, score as vector_score\n",
    "        }\n",
    "        \n",
    "        // 3. 키워드 관계 정보 수집 및 보너스 점수 계산\n",
    "        OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "        WITH precedent, vector_score, \n",
    "             collect(DISTINCT keyword.text) as keywords,\n",
    "             sum(CASE WHEN $query_keywords IS NULL THEN 0\n",
    "                  WHEN keyword.text IN $query_keywords\n",
    "                  THEN 0.05 ELSE 0 END) as keyword_bonus\n",
    "        \n",
    "        // 4. 다른 법조항 참조 정보 수집\n",
    "        OPTIONAL MATCH (precedent)-[:REFERENCES_ARTICLE]->(ref_article:Article)\n",
    "        \n",
    "        // 5. 최종 결과 반환\n",
    "        RETURN precedent.id as id,\n",
    "               precedent.name as name,\n",
    "               precedent.full_summary as text,\n",
    "               vector_score + keyword_bonus as score,\n",
    "               keywords,\n",
    "               collect(DISTINCT ref_article.id) as referenced_articles\n",
    "        ORDER BY score DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "        \n",
    "        results = self.run_query(\n",
    "            query,\n",
    "            {\n",
    "                \"article_id\": article_id,\n",
    "                \"query_embedding\": query_embedding,\n",
    "                \"query_keywords\": query_keywords or [],\n",
    "                \"limit\": limit\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SearchResult(\n",
    "                id=result[\"id\"],\n",
    "                type=\"Precedent\",\n",
    "                score=result[\"score\"],\n",
    "                text=result[\"text\"],\n",
    "                metadata={\n",
    "                    \"name\": result[\"name\"],\n",
    "                    \"keywords\": result[\"keywords\"],\n",
    "                    \"referenced_articles\": result[\"referenced_articles\"]\n",
    "                }\n",
    "            )\n",
    "            for result in results\n",
    "        ]\n",
    "\n",
    "print(\"판례 리포지토리 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8757696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로더 및 텍스트 처리기 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로더 및 처리기\n",
    "# ==================\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"데이터 로드 및 전처리를 위한 클래스\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_articles_from_pdf(pdf_path: str) -> Dict[str, Article]:\n",
    "        \"\"\"PDF에서 법조항 로드 - 개선된 버전\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: PDF 파일 경로\n",
    "            \n",
    "        Returns:\n",
    "            법조항 딕셔너리 (ID -> Article)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            pages = loader.load()\n",
    "            full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "            \n",
    "            # 전체 텍스트에서 모든 조항 시작 위치 찾기\n",
    "            article_pattern = r'제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?'\n",
    "            matches = list(re.finditer(article_pattern, full_text))\n",
    "            \n",
    "            articles = {}\n",
    "            for i in range(len(matches)):\n",
    "                current_match = matches[i]\n",
    "                current_article_id = current_match.group(0).strip()  # 현재 조항 ID\n",
    "                \n",
    "                # 현재 조항 시작 위치\n",
    "                start_pos = current_match.start()\n",
    "                \n",
    "                # 다음 조항 시작 위치 (없으면 텍스트 끝까지)\n",
    "                end_pos = matches[i+1].start() if i < len(matches)-1 else len(full_text)\n",
    "                \n",
    "                # 현재 조항의 전체 내용 (ID 포함)\n",
    "                article_text = full_text[start_pos:end_pos].strip()\n",
    "                \n",
    "                # 저장 (ID는 조항 번호만)\n",
    "                articles[current_article_id] = Article(id=current_article_id, text=article_text)\n",
    "            \n",
    "            print(f\"Processed {len(articles)} articles from PDF\")\n",
    "            return articles\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading articles from PDF: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_precedents_from_json(directory_path: str, limit: int = None) -> List[Precedent]:\n",
    "        \"\"\"JSON 파일에서 판례 로드 - 개선된 버전\n",
    "        \n",
    "        Args:\n",
    "            directory_path: JSON 파일 디렉토리 경로\n",
    "            limit: 최대 로드할 판례 수\n",
    "            \n",
    "        Returns:\n",
    "            판례 객체 리스트\n",
    "        \"\"\"\n",
    "        precedents = []\n",
    "        \n",
    "        try:\n",
    "            file_list = os.listdir(directory_path)\n",
    "            json_files = [f for f in file_list if f.endswith(\".json\")]\n",
    "            \n",
    "            if limit:\n",
    "                json_files = json_files[:limit]\n",
    "            \n",
    "            # 병렬 처리로 성능 향상\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=min(10, os.cpu_count() * 2)) as executor:\n",
    "                future_to_file = {\n",
    "                    executor.submit(DataLoader._load_single_precedent, os.path.join(directory_path, filename)): \n",
    "                    filename for filename in json_files\n",
    "                }\n",
    "                \n",
    "                for future in tqdm(concurrent.futures.as_completed(future_to_file), \n",
    "                                  total=len(json_files), \n",
    "                                  desc=\"Loading precedents\"):\n",
    "                    filename = future_to_file[future]\n",
    "                    try:\n",
    "                        precedent = future.result()\n",
    "                        if precedent:\n",
    "                            precedents.append(precedent)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {filename}: {e}\")\n",
    "            \n",
    "            print(f\"Loaded {len(precedents)} precedents.\")\n",
    "            return precedents\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading precedents from JSON: {e}\")\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_single_precedent(filepath: str) -> Optional[Precedent]:\n",
    "        \"\"\"단일 판례 JSON 파일 로드 (병렬 처리용)\n",
    "        \n",
    "        Args:\n",
    "            filepath: JSON 파일 경로\n",
    "            \n",
    "        Returns:\n",
    "            판례 객체 또는 None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "                # 기존에 라벨링 되어있었음\n",
    "                precedent_info = {\n",
    "                    \"id\": data.get(\"info\", {}).get(\"caseNoID\", os.path.basename(filepath).replace(\".json\", \"\")),\n",
    "                    \"name\": data.get(\"info\", {}).get(\"caseNm\"),\n",
    "                    \"judgment_summary\": data.get(\"jdgmn\"),\n",
    "                    \"full_summary\": \" \".join([s.get(\"summ_contxt\", \"\") for s in data.get(\"Summary\", [])]),\n",
    "                    \"keywords\": [kw.get(\"keyword\") for kw in data.get(\"keyword_tagg\", []) if kw.get(\"keyword\")],\n",
    "                    \"referenced_rules\": data.get(\"Reference_info\", {}).get(\"reference_rules\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_rules\") else [],\n",
    "                    \"referenced_cases\": data.get(\"Reference_info\", {}).get(\"reference_court_case\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_court_case\") else [],\n",
    "                }\n",
    "                \n",
    "                # 참조 법조항 정제 (조항 번호만)\n",
    "                cleaned_rules = []\n",
    "                rule_pattern = re.compile(r'제\\d+조(?:의\\d+)?')  # 패턴 찾기: \"제X조\" or \"제X조의Y\"\n",
    "                \n",
    "                for rule in precedent_info[\"referenced_rules\"]:\n",
    "                    # 각 규칙 문자열에서 모든 일치 항목 찾기\n",
    "                    matches = rule_pattern.findall(rule.strip())\n",
    "                    cleaned_rules.extend(matches)\n",
    "                    \n",
    "                precedent_info[\"referenced_rules\"] = list(set(cleaned_rules))  # 중복 제거\n",
    "                \n",
    "                # Precedent 객체 생성\n",
    "                precedent = Precedent(\n",
    "                    id=precedent_info[\"id\"],\n",
    "                    name=precedent_info[\"name\"],\n",
    "                    judgment_summary=precedent_info[\"judgment_summary\"],\n",
    "                    full_summary=precedent_info[\"full_summary\"],\n",
    "                    keywords=precedent_info[\"keywords\"],\n",
    "                    referenced_rules=precedent_info[\"referenced_rules\"],\n",
    "                    referenced_cases=precedent_info[\"referenced_cases\"]\n",
    "                )\n",
    "                \n",
    "                return precedent\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not decode JSON from {os.path.basename(filepath)}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {os.path.basename(filepath)}: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "class TextProcessor:\n",
    "    \"\"\"텍스트 처리 유틸리티 클래스 - 최적화된 버전\"\"\"\n",
    "    \n",
    "    # 불용어 정의를 클래스 변수로 (한 번만 로드)\n",
    "    stopwords = [\n",
    "        \"무엇\", \"어떤\", \"어떻게\", \"언제\", \"누구\", \"왜\", \"어디\", \"경우\", \"관하여\", \"대하여\", \n",
    "        \"은\", \"는\", \"이\", \"가\", \"을\", \"를\", \"에\", \"의\", \"와\", \"과\", \"로\", \"으로\",\n",
    "        \"있다\", \"없다\", \"경우\", \"때\", \"것\", \"등\", \"수\", \"그\", \"이\", \"저\", \"그렇게\",\n",
    "        \"그런\", \"이런\", \"저런\", \"하는\", \"다음\", \"또는\", \"또한\", \"그리고\", \"만약\", \"만일\"\n",
    "    ]\n",
    "    \n",
    "    # 주요 법률 용어 사전\n",
    "    legal_terms = {\n",
    "        # 형법 기본 원칙\n",
    "        \"고의\": 3, \"과실\": 3, \"인과관계\": 3, \"위법성\": 3, \"책임\": 3, \n",
    "        \"구성요건\": 3, \"위법성조각사유\": 3, \"책임조각사유\": 3,\n",
    "        \n",
    "        # 정당화 사유\n",
    "        \"정당방위\": 3, \"긴급피난\": 3, \"자구행위\": 3, \"피해자동의\": 3, \"정당행위\": 3, \n",
    "        \"업무로인한행위\": 3, \"강요된행위\": 3,\n",
    "        \n",
    "        # 범죄의 실행 단계\n",
    "        \"미수\": 3, \"기수\": 3, \"예비\": 3, \"음모\": 3, \"중지\": 3, \"불능미수\": 3,\n",
    "        \n",
    "        # 공범 관련\n",
    "        \"공범\": 3, \"교사\": 3, \"방조\": 3, \"공동정범\": 3, \"간접정범\": 3, \"종범\": 3,\n",
    "        \n",
    "        # 형벌 관련\n",
    "        \"형\": 2, \"징역\": 2, \"벌금\": 2, \"집행유예\": 2, \"선고유예\": 2, \"누범\": 2,\n",
    "        \n",
    "        # 법이론\n",
    "        \"법익\": 2, \"작위\": 2, \"부작위\": 2, \"결과범\": 2, \"거동범\": 2, \"상당인과관계\": 2,\n",
    "        \n",
    "        # 기타 형법 용어\n",
    "        \"불법\": 2, \"과잉방위\": 2, \"우발적\": 2, \"착오\": 2, \"원인에서자유로운행위\": 2\n",
    "    }\n",
    "    \n",
    "    # 동의어 매핑\n",
    "    synonyms = {\n",
    "        \"고의\": [\"범의\", \"의도적\", \"계획적\"],\n",
    "        \"과실\": [\"부주의\", \"태만\", \"소홀\"],\n",
    "        \"위법성\": [\"불법성\", \"위법\", \"불법\"],\n",
    "        \"책임\": [\"형사책임\", \"귀책\", \"비난가능성\"],\n",
    "        \"미수\": [\"미완성\", \"불성공\"],\n",
    "        \"정당방위\": [\"자기방어\", \"방어행위\"]\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_keywords(text: str) -> List[str]:\n",
    "        \"\"\"텍스트에서 주요 키워드 추출 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            text: 입력 텍스트\n",
    "            \n",
    "        Returns:\n",
    "            키워드 리스트\n",
    "        \"\"\"\n",
    "        # 기본 키워드 추출 (2글자 이상)\n",
    "        words = re.findall(r'\\w{2,}', text)\n",
    "        basic_keywords = [w for w in words if w not in TextProcessor.stopwords]\n",
    "        \n",
    "        # 인접한 단어들도 함께 고려 (복합 키워드)\n",
    "        bigrams = []\n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i] not in TextProcessor.stopwords or words[i+1] not in TextProcessor.stopwords:\n",
    "                bigram = words[i] + words[i+1]\n",
    "                if len(bigram) >= 4:  # 4글자 이상 복합어만 고려\n",
    "                    bigrams.append(bigram)\n",
    "        \n",
    "        # 가중치 및 동의어 적용\n",
    "        weighted_keywords = []\n",
    "        \n",
    "        for keyword in basic_keywords + bigrams:\n",
    "            if keyword in TextProcessor.legal_terms:\n",
    "                # 가중치만큼 반복 추가\n",
    "                weighted_keywords.extend([keyword] * TextProcessor.legal_terms[keyword])\n",
    "                \n",
    "                # 동의어도 추가\n",
    "                if keyword in TextProcessor.synonyms:\n",
    "                    for synonym in TextProcessor.synonyms[keyword]:\n",
    "                        weighted_keywords.append(synonym)\n",
    "            else:\n",
    "                weighted_keywords.append(keyword)\n",
    "        \n",
    "        # 빈도수 계산 및 필터링\n",
    "        from collections import Counter\n",
    "        counter = Counter(weighted_keywords)\n",
    "        \n",
    "        # 키워드가 적으면 낮은 기준 적용\n",
    "        min_count = 1 if len(counter) < 10 else 2\n",
    "        \n",
    "        final_keywords = [k for k, v in counter.items() if v >= min_count]\n",
    "        \n",
    "        # 키워드가 너무 적으면 원래 키워드 반환\n",
    "        if len(final_keywords) < 3:\n",
    "            return weighted_keywords[:10]  # 최대 10개만 사용\n",
    "        \n",
    "        return final_keywords[:15]  # 최대 15개 키워드만 사용 (성능 최적화)\n",
    "    \n",
    "    @staticmethod\n",
    "    def summarize_text(text: str, question: str, is_article: bool = True) -> str:\n",
    "        \"\"\"텍스트 요약 및 관련 부분 강조 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            text: 입력 텍스트\n",
    "            question: 질문 \n",
    "            is_article: 법조항 텍스트 여부\n",
    "            \n",
    "        Returns:\n",
    "            요약된 텍스트\n",
    "        \"\"\"\n",
    "        # 텍스트가 이미 짧으면 그대로 반환\n",
    "        min_len = 500 if is_article else 300\n",
    "        if len(text) < min_len:\n",
    "            return text\n",
    "        \n",
    "        # 키워드 추출\n",
    "        keywords = TextProcessor.extract_keywords(question)\n",
    "        \n",
    "        # 문장 분리 (정규식 컴파일로 성능 향상)\n",
    "        sentence_pattern = re.compile(r'(?<=[.!?])\\s+|(?<=\\n)')\n",
    "        sentences = sentence_pattern.split(text)\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        # 문장별 점수 계산\n",
    "        scored_sentences = []\n",
    "        \n",
    "        # 법조항 및 법률 용어 패턴 컴파일 (반복 사용 최적화)\n",
    "        article_pattern = re.compile(r'제\\d+조')\n",
    "        legal_term_pattern = re.compile(r'(판시|판결|법리|해석|적용|요건|효과|정당|위법|책임)')\n",
    "        conclusion_pattern = re.compile(r'(따라서|그러므로|결론적으로|이유로|판단한다)')\n",
    "        important_pattern = re.compile(r'(~으로 한다|~라 함은|~을 말한다|다만|단,|제외한다)')\n",
    "        \n",
    "        for i, sentence in enumerate(sentences):\n",
    "            # 기본 점수\n",
    "            score = 0\n",
    "            \n",
    "            # 키워드 매칭 점수\n",
    "            for keyword in keywords:\n",
    "                if keyword in sentence:\n",
    "                    # 중요 법률 용어는 더 높은 가중치\n",
    "                    if keyword in [\"구성요건\", \"위법성\", \"책임\", \"정당방위\", \"긴급피난\", \n",
    "                                \"고의\", \"과실\", \"미수\", \"예비\", \"음모\", \"공범\"]:\n",
    "                        score += 3\n",
    "                    else:\n",
    "                        score += 1\n",
    "            \n",
    "            # 법조항 번호 포함 문장은 높은 가중치\n",
    "            if article_pattern.search(sentence):\n",
    "                score += 5\n",
    "            \n",
    "            # 법률적 중요 문장 패턴에 가중치\n",
    "            if important_pattern.search(sentence):\n",
    "                score += 3\n",
    "            \n",
    "            # 법률 용어가 많은 문장은 높은 가중치\n",
    "            term_count = len(legal_term_pattern.findall(sentence))\n",
    "            score += min(term_count, 3)  # 최대 3점\n",
    "            \n",
    "            # 결론 표현 포함 시 높은 점수\n",
    "            if conclusion_pattern.search(sentence):\n",
    "                score += 3\n",
    "            \n",
    "            # 위치 가중치\n",
    "            if i == 0:  # 첫 문장 (제목이나 조항 번호일 가능성)\n",
    "                score += 5\n",
    "            elif i == len(sentences) - 1:  # 마지막 문장 (결론일 가능성)\n",
    "                score += 2\n",
    "            elif i <= 2:  # 앞부분 문장들 (정의나 개요일 가능성)\n",
    "                score += 1\n",
    "            \n",
    "            scored_sentences.append((sentence, score, i))\n",
    "        \n",
    "        # 법조항과 판례별 다른 전략 적용\n",
    "        if is_article:\n",
    "            # 점수 기준으로 상위 문장 선택\n",
    "            min_score = max(1, sorted([score for _, score, _ in scored_sentences], reverse=True)[0] * 0.3)\n",
    "            relevant_sentences = [(s, score, i) for s, score, i in scored_sentences if score >= min_score]\n",
    "            \n",
    "            # 최소 문장 수 보장\n",
    "            min_sentences = min(8, len(sentences))\n",
    "            if len(relevant_sentences) < min_sentences:\n",
    "                relevant_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:min_sentences]\n",
    "        else:\n",
    "            # 판례는 더 많은 문장 포함\n",
    "            top_count = max(5, min(len(sentences) // 3, 10))\n",
    "            relevant_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:top_count]\n",
    "        \n",
    "        # 원래 순서로 정렬\n",
    "        ordered_sentences = sorted(relevant_sentences, key=lambda x: x[2])\n",
    "        \n",
    "        # 법조항 번호와 제목은 항상 포함\n",
    "        if is_article and len(ordered_sentences) > 0 and 0 not in [i for _, _, i in ordered_sentences]:\n",
    "            ordered_sentences.insert(0, (sentences[0], 0, 0))\n",
    "        \n",
    "        result = \" \".join([s for s, _, _ in ordered_sentences])\n",
    "        \n",
    "        # 결과가 너무 짧으면 원본 반환\n",
    "        min_ratio = 0.3 if is_article else 0.25\n",
    "        if len(result) < len(text) * min_ratio:\n",
    "            return text[:1500] if len(text) > 2000 else text  # 너무 긴 텍스트는 앞부분만 사용\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_context(search_results: List[SearchResult], question: str) -> str:\n",
    "        \"\"\"검색 결과에서 질문에 최적화된 컨텍스트 구성 - 개선된 버전\n",
    "        \n",
    "        Args:\n",
    "            search_results: 검색 결과 리스트\n",
    "            question: 질문\n",
    "            \n",
    "        Returns:\n",
    "            포맷팅된 컨텍스트\n",
    "        \"\"\"\n",
    "        # 검색 결과가 없으면 빈 컨텍스트 반환\n",
    "        if not search_results:\n",
    "            return \"관련 형법 자료를 찾지 못했습니다.\"\n",
    "            \n",
    "        # 검색 결과 중 상위 결과에 대해 질문 관련성 재평가\n",
    "        question_lower = question.lower()\n",
    "        scored_results = []\n",
    "        \n",
    "        for result in search_results:\n",
    "            relevance_score = result.score\n",
    "            \n",
    "            # 텍스트 내 키워드 매칭 검사로 관련성 점수 보정\n",
    "            for keyword in TextProcessor.extract_keywords(question):\n",
    "                if keyword in result.text.lower():\n",
    "                    relevance_score += 0.05\n",
    "            \n",
    "            # 법 조항 ID가 질문에 언급된 경우 높은 가중치\n",
    "            if result.type == \"Article\" and result.id in question:\n",
    "                relevance_score += 0.3\n",
    "                \n",
    "            # 판례 이름이 질문에 언급된 경우\n",
    "            if result.type == \"Precedent\" and result.metadata.get(\"name\") and result.metadata[\"name\"] in question:\n",
    "                relevance_score += 0.2\n",
    "                \n",
    "            scored_results.append((result, relevance_score))\n",
    "        \n",
    "        # 관련성 점수로 재정렬\n",
    "        scored_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        reranked_results = [r for r, _ in scored_results]\n",
    "        \n",
    "        # 검색 결과 타입별 분류\n",
    "        results_by_type = {\"Article\": [], \"Precedent\": []}\n",
    "        for result in reranked_results:\n",
    "            results_by_type[result.type].append(result)\n",
    "        \n",
    "        # 법조항 컨텍스트 구성\n",
    "        article_contexts = []\n",
    "        for article in results_by_type[\"Article\"][:5]:  # 최대 5개\n",
    "            # 법조항 요약\n",
    "            summarized_text = TextProcessor.summarize_text(article.text, question, is_article=True)\n",
    "            \n",
    "            # 점수에 따른 강조\n",
    "            if article.score > 0.7:\n",
    "                article_contexts.append(f\"【중요 법조항: {article.id}】\\n{summarized_text}\")\n",
    "            else:\n",
    "                article_contexts.append(f\"【{article.id}】\\n{summarized_text}\")\n",
    "                \n",
    "            # 관련 키워드가 있으면 표시\n",
    "            if article.metadata.get(\"related_keywords\"):\n",
    "                keywords = article.metadata[\"related_keywords\"]\n",
    "                if keywords and len(keywords) > 0:\n",
    "                    keywords_str = \", \".join(keywords[:5])\n",
    "                    article_contexts[-1] += f\"\\n[관련 키워드: {keywords_str}]\"\n",
    "        \n",
    "        # 판례 컨텍스트 구성\n",
    "        precedent_contexts = []\n",
    "        for precedent in results_by_type[\"Precedent\"][:3]:  # 최대 3개\n",
    "            # 판례 요약\n",
    "            summarized_text = TextProcessor.summarize_text(precedent.text, question, is_article=False)\n",
    "            \n",
    "            # 판례명이 있으면 표시\n",
    "            name_str = f\" - {precedent.metadata.get('name', '')}\" if precedent.metadata.get(\"name\") else \"\"\n",
    "            precedent_contexts.append(f\"【판례 {precedent.id}{name_str}】\\n{summarized_text}\")\n",
    "            \n",
    "            # 참조 법조항이 있으면 표시\n",
    "            if precedent.metadata.get(\"referenced_articles\"):\n",
    "                refs = \", \".join(precedent.metadata[\"referenced_articles\"][:3])\n",
    "                precedent_contexts[-1] += f\"\\n[참조 법조항: {refs}]\"\n",
    "                \n",
    "            # 키워드가 있으면 표시\n",
    "            if precedent.metadata.get(\"keywords\"):\n",
    "                keywords_str = \", \".join(precedent.metadata[\"keywords\"][:5])\n",
    "                precedent_contexts[-1] += f\"\\n[관련 키워드: {keywords_str}]\"\n",
    "        \n",
    "        # 질문 분석 및 분류\n",
    "        question_category = \"\"\n",
    "        if any(term in question_lower for term in [\"구성요건\", \"범죄성립\", \"해당\", \"요건\"]):\n",
    "            question_category = \"구성요건 분석 문제\"\n",
    "        elif any(term in question_lower for term in [\"위법\", \"정당\", \"방위\", \"피난\", \"적법\"]):\n",
    "            question_category = \"위법성 판단 문제\"\n",
    "        elif any(term in question_lower for term in [\"책임\", \"비난\", \"책임능력\", \"강요\", \"초법규\"]):\n",
    "            question_category = \"책임 판단 문제\"\n",
    "        elif any(term in question_lower for term in [\"미수\", \"예비\", \"음모\", \"중지\", \"불능\"]):\n",
    "            question_category = \"미수 관련 문제\"\n",
    "        elif any(term in question_lower for term in [\"형\", \"형벌\", \"형량\", \"처벌\", \"징역\", \"벌금\"]):\n",
    "            question_category = \"형벌 관련 문제\"\n",
    "        elif any(term in question_lower for term in [\"공범\", \"공동정범\", \"교사\", \"방조\", \"종범\"]):\n",
    "            question_category = \"공범 관련 문제\"\n",
    "        else:\n",
    "            question_category = \"일반 형법 문제\"\n",
    "            \n",
    "        # 전체 컨텍스트 구성\n",
    "        formatted_context = \"\\n\\n\".join([\n",
    "            f\"### 형법 관련 참고 자료 ({question_category}) ###\",\n",
    "            \"## 관련 법조항:\",\n",
    "            \"\\n\\n\".join(article_contexts) if article_contexts else \"관련 법조항 정보가 없습니다.\",\n",
    "            \"## 관련 판례:\",\n",
    "            \"\\n\\n\".join(precedent_contexts) if precedent_contexts else \"관련 판례 정보가 없습니다.\",\n",
    "            \"### 참고사항: 형법 해석 시 구성요건-위법성-책임 순서로 판단하며, 법조항과 판례를 함께 고려하십시오. ###\"\n",
    "        ])\n",
    "        \n",
    "        return formatted_context\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_answer(text: str) -> Optional[str]:\n",
    "        \"\"\"텍스트에서 A, B, C, D 중 답변 추출 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            text: 입력 텍스트\n",
    "            \n",
    "        Returns:\n",
    "            추출된 답변 (A, B, C, D) 또는 None\n",
    "        \"\"\"\n",
    "        # 정규표현식 패턴들\n",
    "        patterns = [\n",
    "            # 직접 응답 패턴\n",
    "            r'^([A-D])$',\n",
    "            r'^답(?:변|안|)(?:은|): ?([A-D])',\n",
    "            r'정답(?:은|): ?([A-D])',\n",
    "            r'([A-D])(?:가|이|을|를) 선택',\n",
    "            r'([A-D])(?:가|이|이) 정답',\n",
    "            r'([A-D])(?:가|이|을|를) (?:고른다|고릅니다|고르겠습니다)',\n",
    "            \n",
    "            # 간접 응답 패턴\n",
    "            r'따라서 (?:정답은 |답은 |)([A-D])',\n",
    "            r'([A-D])(?:가|이|은|는) (?:가장 적절|가장 정확|옳은)',\n",
    "            \n",
    "            # 결론 문장 패턴\n",
    "            r'(?:최종적으로|결론적으로|종합하면|따라서|분석 결과|이상의 이유로).{1,50}(?:정답은|답은|옳은 것은|맞는 것은) ?([A-D])',\n",
    "            r'(?:선택지|옵션) ?([A-D])(?:가|이|은|는) (?:정답|맞습니다|맞다|적절|적합|옳은|타당)',\n",
    "            r'정답은 선택지 ?([A-D])',\n",
    "            r'선택지 ?([A-D])(?:을|를)? ?(?:선택합니다|고릅니다|고르겠습니다|골라야 합니다)',\n",
    "            \n",
    "            # 비교 분석 패턴\n",
    "            r'(?:따라서|그러므로|그래서|이에).{0,30}([A-D])(?:이외|를 제외하고|빼고).{0,20}(?:모두|다른 선택지|다른 것)(?:는|은) (?:틀리|오답|부적절|타당하지 않)',\n",
    "            r'선택지 ([A-D])(?:만|이).{0,30}(?:정확|옳|적절|타당|맞)',\n",
    "            \n",
    "            # 부정 표현을 통한 정답 유추\n",
    "            r'(?:선택지|옵션) ([A-D])(?:을|를)? ?제외한.{1,20}(?:틀리|오답|부적절)',\n",
    "            r'([A-D])(?:을|를)? ?제외한.{1,20}(?:나머지|다른).{1,20}(?:틀리|오답|부적절)',\n",
    "        ]\n",
    "        \n",
    "        # 대문자 또는 소문자 답변을 모두 허용 (대문자로 통일)\n",
    "        normalized_text = text.upper()\n",
    "        \n",
    "        # 패턴 적용\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, normalized_text, re.IGNORECASE | re.MULTILINE)\n",
    "            if match:\n",
    "                return match.group(1).upper()\n",
    "        \n",
    "        # 문장별 검색 (마지막 문장들에 집중)\n",
    "        lines = normalized_text.split('\\n')\n",
    "        \n",
    "        # 마지막 3개 문장 우선 검색 (결론이 주로 마지막에 위치)\n",
    "        last_lines = lines[-3:] if len(lines) >= 3 else lines\n",
    "        for line in last_lines:\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, line, re.IGNORECASE)\n",
    "                if match:\n",
    "                    return match.group(1).upper()\n",
    "        \n",
    "        # 문맥 기반 접근\n",
    "        options = ['A', 'B', 'C', 'D']\n",
    "        \n",
    "        # 가장 강조된 선택지 찾기\n",
    "        option_emphasis = {option: 0 for option in options}\n",
    "        \n",
    "        for option in options:\n",
    "            # 긍정적 언급 패턴 (가중치: +2)\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}이 옳다\") * 2\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}가 맞다\") * 2\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}이 정답\") * 2\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}만 옳다\") * 2\n",
    "            option_emphasis[option] += normalized_text.count(f\"정답은 {option}\") * 2\n",
    "            \n",
    "            # 일반적 언급 패턴 (가중치: +1)\n",
    "            option_emphasis[option] += normalized_text.count(f\"선택지 {option}\")\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}.\")\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}이 \")\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}가 \")\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}은 \")\n",
    "            option_emphasis[option] += normalized_text.count(f\"{option}는 \")\n",
    "            \n",
    "            # 부정 표현 (가중치: -2)\n",
    "            option_emphasis[option] -= normalized_text.count(f\"{option}이 아니\") * 2\n",
    "            option_emphasis[option] -= normalized_text.count(f\"{option}가 아니\") * 2\n",
    "            option_emphasis[option] -= normalized_text.count(f\"{option}은 틀린\") * 2\n",
    "            option_emphasis[option] -= normalized_text.count(f\"{option}는 틀린\") * 2\n",
    "            option_emphasis[option] -= normalized_text.count(f\"{option}은 부적절\") * 2\n",
    "        \n",
    "        # 최종 결정: 긍정적 언급이 가장 많은 선택지 또는 부정적 언급이 가장 적은 선택지\n",
    "        if any(emphasis > 0 for emphasis in option_emphasis.values()):\n",
    "            return max(option_emphasis.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # 출현 빈도 기반 추측 (모든 방법이 실패했을 때)\n",
    "        option_counts = {option: normalized_text.count(option) for option in options}\n",
    "        if any(count > 0 for count in option_counts.values()):\n",
    "            return max(option_counts.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # 응답에서 아무 것도 찾지 못한 경우\n",
    "        return None\n",
    "\n",
    "print(\"데이터 로더 및 텍스트 처리기 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50c4b2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그래프 검색 서비스 클래스 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# RAG 검색 서비스\n",
    "# =============\n",
    "\n",
    "class GraphSearchService:\n",
    "    \"\"\"그래프 기반 검색 서비스 - 최적화된 버전\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 neo4j_uri: str, \n",
    "                 neo4j_username: str, \n",
    "                 neo4j_password: str,\n",
    "                 embedding_model: Any,\n",
    "                 embedding_dimension: int = 1536):\n",
    "        \"\"\"검색 서비스 초기화\n",
    "        \n",
    "        Args:\n",
    "            neo4j_uri: Neo4j 서버 URI\n",
    "            neo4j_username: 사용자명 \n",
    "            neo4j_password: 비밀번호\n",
    "            embedding_model: 임베딩 모델\n",
    "            embedding_dimension: 임베딩 벡터 차원\n",
    "        \"\"\"\n",
    "        self.article_repo = ArticleRepository(neo4j_uri, neo4j_username, neo4j_password)\n",
    "        self.precedent_repo = PrecedentRepository(neo4j_uri, neo4j_username, neo4j_password)\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        \n",
    "        # 연결 및 스키마 설정\n",
    "        self.article_repo.connect()\n",
    "        self.article_repo.setup_constraints_and_indexes(embedding_dimension)\n",
    "        \n",
    "        # 캐시 초기화 (검색 성능 향상)\n",
    "        self.query_cache = {}\n",
    "    \n",
    "    def search(self, query_text: str, top_k: int = 8) -> List[SearchResult]:\n",
    "        \"\"\"질의에 대한 관련 컨텍스트 검색 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            query_text: 검색 질의 텍스트\n",
    "            top_k: 반환할 최대 결과 수\n",
    "            \n",
    "        Returns:\n",
    "            검색 결과 리스트\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 캐시 검사 (동일 쿼리 반복 실행 최적화)\n",
    "        cache_key = f\"{query_text}_{top_k}\"\n",
    "        if cache_key in self.query_cache:\n",
    "            print(f\"Cache hit for query: {query_text[:30]}...\")\n",
    "            return self.query_cache[cache_key]\n",
    "        \n",
    "        try:\n",
    "            # 임베딩 생성\n",
    "            query_embedding = self.embedding_model.embed_query(query_text)\n",
    "            \n",
    "            # 키워드 추출\n",
    "            keywords = TextProcessor.extract_keywords(query_text)\n",
    "            \n",
    "            # 법조항 검색 (그래프 관계 활용)\n",
    "            article_results = self.article_repo.search_articles_related_to_precedents(\n",
    "                query_embedding, \n",
    "                top_k=top_k\n",
    "            )\n",
    "            \n",
    "            # 관련 판례 검색\n",
    "            precedent_results = []\n",
    "            \n",
    "            # 상위 법조항에 대해 판례 검색 (병렬 처리)\n",
    "            if article_results:\n",
    "                async def fetch_related_precedents():\n",
    "                    tasks = []\n",
    "                    for article in article_results[:3]:  # 상위 3개 법조항만\n",
    "                        tasks.append(self._async_search_precedents(article.id, query_embedding, keywords))\n",
    "                    \n",
    "                    all_results = await asyncio.gather(*tasks)\n",
    "                    return [precedent for sublist in all_results for precedent in sublist]\n",
    "                \n",
    "                # 비동기 실행\n",
    "                loop = asyncio.new_event_loop()\n",
    "                asyncio.set_event_loop(loop)\n",
    "                try:\n",
    "                    precedent_results = loop.run_until_complete(fetch_related_precedents())\n",
    "                finally:\n",
    "                    loop.close()\n",
    "            \n",
    "            # 결과가 충분하지 않으면 직접 벡터 검색 추가\n",
    "            if len(precedent_results) < 2:\n",
    "                direct_precedent_results = self.precedent_repo.search_precedents_by_vector(\n",
    "                    query_embedding,\n",
    "                    limit=3\n",
    "                )\n",
    "                \n",
    "                # 중복 제거하며 추가\n",
    "                for precedent in direct_precedent_results:\n",
    "                    if not any(p.id == precedent.id for p in precedent_results):\n",
    "                        precedent_results.append(precedent)\n",
    "            \n",
    "            # 모든 결과 통합 및 점수 기준 정렬\n",
    "            all_results = article_results + precedent_results\n",
    "            all_results.sort(key=lambda x: x.score, reverse=True)\n",
    "            \n",
    "            # 최종 결과 선택\n",
    "            final_results = all_results[:top_k]\n",
    "            \n",
    "            # 결과 캐싱\n",
    "            self.query_cache[cache_key] = final_results\n",
    "            \n",
    "            end_time = time.time()\n",
    "            print(f\"Search completed in {end_time - start_time:.2f} seconds\")\n",
    "            \n",
    "            return final_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in graph search: {e}\")\n",
    "            \n",
    "            # 백업: 기본 벡터 검색\n",
    "            try:\n",
    "                # 임베딩 생성 (재시도)\n",
    "                query_embedding = self.embedding_model.embed_query(query_text)\n",
    "                \n",
    "                # 간단한 벡터 검색\n",
    "                article_results = self.article_repo.search_articles_by_vector(\n",
    "                    query_embedding, \n",
    "                    limit=top_k//2\n",
    "                )\n",
    "                \n",
    "                precedent_results = self.precedent_repo.search_precedents_by_vector(\n",
    "                    query_embedding,\n",
    "                    limit=top_k//2\n",
    "                )\n",
    "                \n",
    "                # 결과 통합 및 정렬\n",
    "                all_results = article_results + precedent_results\n",
    "                all_results.sort(key=lambda x: x.score, reverse=True)\n",
    "                \n",
    "                print(\"Fallback search completed successfully\")\n",
    "                return all_results[:top_k]\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"Fallback search failed: {e2}\")\n",
    "                return []\n",
    "    \n",
    "    async def _async_search_precedents(self, article_id: str, query_embedding: List[float], keywords: List[str]) -> List[SearchResult]:\n",
    "        \"\"\"법조항 관련 판례 비동기 검색 (병렬 처리용)\"\"\"\n",
    "        return self.precedent_repo.search_precedents_by_article(\n",
    "            article_id,\n",
    "            query_embedding,\n",
    "            query_keywords=keywords,\n",
    "            limit=2\n",
    "        )\n",
    "    \n",
    "    def close(self) -> None:\n",
    "        \"\"\"리소스 정리\"\"\"\n",
    "        self.article_repo.close()\n",
    "        # 캐시 정리\n",
    "        self.query_cache.clear()\n",
    "        print(\"Graph search service resources released.\")\n",
    "\n",
    "print(\"그래프 검색 서비스 클래스 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b47ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메인 파이프라인\n",
    "# ============\n",
    "\n",
    "class LegalRAGPipeline:\n",
    "    \"\"\"법률 RAG 파이프라인 - 최적화된 버전\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 openai_api_key: str, \n",
    "                 neo4j_uri: str, \n",
    "                 neo4j_username: str, \n",
    "                 neo4j_password: str):\n",
    "        \"\"\"파이프라인 초기화\n",
    "        \n",
    "        Args:\n",
    "            openai_api_key: OpenAI API 키\n",
    "            neo4j_uri: Neo4j 서버 URI\n",
    "            neo4j_username: Neo4j 사용자명\n",
    "            neo4j_password: Neo4j 비밀번호\n",
    "        \"\"\"\n",
    "        self.openai_client = OpenAI(api_key=openai_api_key)\n",
    "        self.openai_api_key = openai_api_key\n",
    "        \n",
    "        # 더 효율적인 임베딩 설정 (batch 지원)\n",
    "        self.embedding_model = OpenAIEmbeddings(\n",
    "            model='text-embedding-3-small', \n",
    "            api_key=openai_api_key,\n",
    "            openai_api_key=openai_api_key,\n",
    "            chunk_size=100  # API 호출 배치 크기\n",
    "        )\n",
    "        self.embedding_dimension = 1536  # text-embedding-3-small 차원\n",
    "        \n",
    "        self.search_service = GraphSearchService(\n",
    "            neo4j_uri,\n",
    "            neo4j_username,\n",
    "            neo4j_password,\n",
    "            self.embedding_model,\n",
    "            self.embedding_dimension\n",
    "        )\n",
    "        \n",
    "        self.text_processor = TextProcessor()\n",
    "        \n",
    "        # LLM 모델 설정\n",
    "        self.llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            openai_api_key=openai_api_key,\n",
    "            temperature=0.1  # 예측 안정성 향상\n",
    "        )\n",
    "    \n",
    "    def load_data(self, pdf_path: str, precedent_dir: str, precedent_limit: int = 1000) -> Tuple[Dict[str, Article], List[Precedent]]:\n",
    "        \"\"\"데이터 로드 및 그래프 구축 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: 법조항 PDF 경로\n",
    "            precedent_dir: 판례 디렉토리 경로\n",
    "            precedent_limit: 최대 로드할 판례 수\n",
    "            \n",
    "        Returns:\n",
    "            (법조항 딕셔너리, 판례 리스트)\n",
    "        \"\"\"\n",
    "        print(\"1. 데이터 로드 시작...\")\n",
    "        \n",
    "        # 데이터 로드\n",
    "        articles = DataLoader.load_articles_from_pdf(pdf_path)\n",
    "        precedents = DataLoader.load_precedents_from_json(precedent_dir, limit=precedent_limit)\n",
    "        \n",
    "        print(f\"2. 데이터 로드 완료: {len(articles)} 법조항, {len(precedents)} 판례\")\n",
    "        \n",
    "        # 임베딩 생성 (배치 처리)\n",
    "        print(\"3. 법조항 임베딩 생성 시작...\")\n",
    "        \n",
    "        # 임베딩 함수를 정의\n",
    "        def generate_embeddings_batch(items, is_articles=True):\n",
    "            texts = []\n",
    "            item_ids = []\n",
    "            \n",
    "            # 텍스트 수집\n",
    "            for item_id, item in items:\n",
    "                if is_articles:\n",
    "                    texts.append(item.text)\n",
    "                else:\n",
    "                    text_to_embed = item.full_summary or item.judgment_summary\n",
    "                    if text_to_embed:\n",
    "                        texts.append(text_to_embed)\n",
    "                        item_ids.append(item_id)\n",
    "            \n",
    "            # 빈 텍스트 확인\n",
    "            if not texts:\n",
    "                return\n",
    "                \n",
    "            # 배치 임베딩 수행\n",
    "            embeddings = self.embedding_model.embed_documents(texts)\n",
    "            \n",
    "            # 결과 매핑\n",
    "            for i, (item_id, embedding) in enumerate(zip(item_ids, embeddings)):\n",
    "                if is_articles:\n",
    "                    articles[item_id].embedding = embedding\n",
    "                else:\n",
    "                    precedents[item_id].embedding = embedding\n",
    "        \n",
    "        # 법조항 배치 처리 (500개 단위)\n",
    "        article_items = list(articles.items())\n",
    "        batch_size = 100\n",
    "        \n",
    "        for i in range(0, len(article_items), batch_size):\n",
    "            batch = article_items[i:i+batch_size]\n",
    "            generate_embeddings_batch(batch, is_articles=True)\n",
    "            if (i + batch_size) % (batch_size * 5) == 0:\n",
    "                print(f\"  법조항 임베딩 진행중: {i + batch_size}/{len(article_items)}...\")\n",
    "        \n",
    "        print(\"4. 판례 임베딩 생성 시작...\")\n",
    "        \n",
    "        # 판례 배치 처리\n",
    "        precedent_items = [(i, p) for i, p in enumerate(precedents)]\n",
    "        for i in range(0, len(precedent_items), batch_size):\n",
    "            batch = precedent_items[i:i+batch_size]\n",
    "            generate_embeddings_batch(batch, is_articles=False)\n",
    "            if (i + batch_size) % (batch_size * 5) == 0:\n",
    "                print(f\"  판례 임베딩 진행중: {i + batch_size}/{len(precedent_items)}...\")\n",
    "        \n",
    "        print(\"5. 임베딩 생성 완료\")\n",
    "        \n",
    "        # 그래프 구축\n",
    "        print(\"6. Neo4j 그래프 구축 시작...\")\n",
    "        \n",
    "        article_repo = ArticleRepository(\n",
    "            self.search_service.article_repo.uri,\n",
    "            self.search_service.article_repo.username,\n",
    "            self.search_service.article_repo.password\n",
    "        )\n",
    "        article_repo.connect()\n",
    "        article_count = article_repo.create_bulk_articles(list(articles.values()))\n",
    "        \n",
    "        precedent_repo = PrecedentRepository(\n",
    "            self.search_service.precedent_repo.uri,\n",
    "            self.search_service.precedent_repo.username,\n",
    "            self.search_service.precedent_repo.password\n",
    "        )\n",
    "        precedent_repo.connect()\n",
    "        precedent_count = precedent_repo.create_bulk_precedents(precedents)\n",
    "        \n",
    "        # 연결 종료\n",
    "        article_repo.close()\n",
    "        precedent_repo.close()\n",
    "        \n",
    "        print(f\"7. 그래프 구축 완료: {article_count} 법조항, {precedent_count} 판례 노드 생성\")\n",
    "        \n",
    "        return articles, precedents\n",
    "    \n",
    "    def create_batch_requests(self, questions_df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "        \"\"\"배치 API 요청 생성 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            questions_df: 질문 데이터프레임\n",
    "            \n",
    "        Returns:\n",
    "            배치 요청 리스트\n",
    "        \"\"\"\n",
    "        batch_requests = []\n",
    "        \n",
    "        # 토큰 제한을 고려한 최대 문맥 길이\n",
    "        MAX_CONTEXT_LENGTH = 5000\n",
    "        \n",
    "        # 모든 질문에 대해 RAG 검색 실행\n",
    "        retrieved_contexts = {}\n",
    "        \n",
    "        print(\"RAG 검색으로 문맥 검색 시작...\")\n",
    "        for idx, row in tqdm(questions_df.iterrows(), total=len(questions_df), desc=\"문맥 검색\"):\n",
    "            question = row['question']\n",
    "            try:\n",
    "                # RAG 검색으로 문맥 가져오기\n",
    "                search_results = self.search_service.search(question, top_k=8)\n",
    "                retrieved_contexts[idx] = search_results\n",
    "            except Exception as e:\n",
    "                print(f\"Error in RAG search for question {idx}: {e}\")\n",
    "                retrieved_contexts[idx] = []\n",
    "        print(\"RAG 검색 완료\")\n",
    "        \n",
    "        # 형법 전문가 시스템 프롬프트\n",
    "        system_prompt = \"\"\"당신은 법률 분야, 특히 한국 형법 전문가입니다. 주어진 질문을 해결하기 위해 다음 단계를 따르세요:\n",
    "\n",
    "1. 문제의 핵심 쟁점 파악 - 구성요건, 위법성, 책임 중 어디에 해당하는지 \n",
    "2. 관련 법조항 분석 - 제시된 법조항의 요건과 효과 정확히 파악\n",
    "3. 판례 법리 적용 - 유사 판례의 해석론 적용\n",
    "4. 체계적 분석 - 형법 해석의 기본 원칙에 따라 단계별 분석\n",
    "\n",
    "답변은 A, B, C, D 중 하나만 선택하며, 형법의 정확한 해석과 적용에 근거하여 결정하세요. 확신할 수 없더라도 제공된 문맥을 토대로 가장 정확한 답변을 선택해야 합니다.\"\"\"\n",
    "        \n",
    "        # 배치 요청 준비\n",
    "        print(\"배치 요청 준비 시작...\")\n",
    "        for idx, row in tqdm(questions_df.iterrows(), total=len(questions_df), desc=\"배치 요청 준비\"):\n",
    "            question = row['question']\n",
    "            options = {\n",
    "                'A': row['A'],\n",
    "                'B': row['B'], \n",
    "                'C': row['C'],\n",
    "                'D': row['D']\n",
    "            }\n",
    "            \n",
    "            # 검색된 문맥 가져오기\n",
    "            search_results = retrieved_contexts.get(idx, [])\n",
    "            \n",
    "            # 최적화된 컨텍스트 구성\n",
    "            if search_results:\n",
    "                context_str = self.text_processor.format_context(search_results, question)\n",
    "                # 문맥이 너무 길면 잘라내기\n",
    "                if len(context_str) > MAX_CONTEXT_LENGTH:\n",
    "                    context_str = context_str[:MAX_CONTEXT_LENGTH] + \"... (문맥이 너무 길어 일부 생략됨)\"\n",
    "            else:\n",
    "                context_str = \"관련 문맥 정보가 없습니다. 주어진 질문과 선택지만으로 판단하세요.\"\n",
    "            \n",
    "            # 향상된 프롬프트 작성\n",
    "            prompt = f\"\"\"다음은 한국 형법에 관한 객관식 문제입니다. 제공된 문맥 정보를 참고하여 가장 적절한 답변을 선택하세요.\n",
    "\n",
    "## 질문\n",
    "{question}\n",
    "\n",
    "## 선택지\n",
    "A. {options['A']}\n",
    "B. {options['B']}\n",
    "C. {options['C']}\n",
    "D. {options['D']}\n",
    "\n",
    "## 관련 문맥 정보\n",
    "{context_str}\n",
    "\n",
    "## 분석 단계\n",
    "1. 문제 유형 파악: 구성요건/위법성/책임/기타 중 어떤 문제인지 결정\n",
    "2. 해당 법조항 분석: 문맥에서 제공된 법조항의 요건과 효과를 정확히 이해\n",
    "3. 판례 검토: 유사한 판례의 법리 원칙을 식별하고 적용\n",
    "4. 선택지 분석: 각 선택지가 왜 맞는지 또는 틀린지 법적 근거를 들어 설명\n",
    "5. 최종 선택: 가장 정확한 선택지 하나 결정\n",
    "\n",
    "## 최종 답변\n",
    "형법 원칙에 따라 분석한 결과, 정답은 (A/B/C/D) 입니다.\n",
    "\"\"\"\n",
    "            \n",
    "            # 배치 요청 생성\n",
    "            request = {\n",
    "                \"custom_id\": f\"q_{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/chat/completions\",\n",
    "                \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ],\n",
    "                    \"max_tokens\": 400,\n",
    "                    \"temperature\": 0.1  # 낮은 temperature로 일관된 답변 촉진\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            batch_requests.append(request)\n",
    "        \n",
    "        print(f\"배치 요청 준비 완료: 총 {len(batch_requests)}개 요청 생성\")\n",
    "        return batch_requests\n",
    "    \n",
    "    def run_batch_api(self, batch_requests: List[Dict[str, Any]], output_dir: str = \"results\") -> str:\n",
    "        \"\"\"배치 API 실행 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            batch_requests: 배치 요청 리스트\n",
    "            output_dir: 결과 저장 디렉토리\n",
    "            \n",
    "        Returns:\n",
    "            배치 출력 파일 경로\n",
    "        \"\"\"\n",
    "        # 결과 디렉토리 생성\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # JSONL 파일로 저장\n",
    "        batch_file_path = f\"{output_dir}/criminal_law_batch_input_{timestamp}.jsonl\"\n",
    "        with open(batch_file_path, 'w', encoding='utf-8') as f:\n",
    "            for request in batch_requests:\n",
    "                f.write(json.dumps(request, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        print(f\"배치 파일 저장 완료: {batch_file_path} (총 {len(batch_requests)}개 요청)\")\n",
    "        \n",
    "        # 배치 파일 업로드\n",
    "        try:\n",
    "            batch_input_file = self.openai_client.files.create(\n",
    "                file=open(batch_file_path, \"rb\"),\n",
    "                purpose=\"batch\"\n",
    "            )\n",
    "            batch_input_file_id = batch_input_file.id\n",
    "            print(f\"배치 파일 업로드 완료: ID={batch_input_file_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"배치 파일 업로드 실패: {e}\")\n",
    "            # 실패 시 중단\n",
    "            raise\n",
    "        \n",
    "        # 배치 작업 생성\n",
    "        try:\n",
    "            batch_job = self.openai_client.batches.create(\n",
    "                input_file_id=batch_input_file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window=\"24h\",\n",
    "                metadata={\"description\": \"Criminal Law benchmark evaluation\"}\n",
    "            )\n",
    "            batch_id = batch_job.id\n",
    "            print(f\"배치 작업 생성 완료: ID={batch_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"배치 작업 생성 실패: {e}\")\n",
    "            # 실패 시 중단\n",
    "            raise\n",
    "        \n",
    "        # 배치 작업 상태 확인 및 대기\n",
    "        print(\"배치 작업 진행 상황 모니터링 시작...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 상태 체크 간격 설정\n",
    "        check_intervals = [30] * 20 + [60] * 10 + [120]  # 처음 10분: 30초, 다음 10분: 1분, 이후: 2분\n",
    "        interval_idx = 0\n",
    "        \n",
    "        status = None\n",
    "        while True:\n",
    "            try:\n",
    "                status = self.openai_client.batches.retrieve(batch_id)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                # 진행 상황 표시\n",
    "                completed = status.request_counts.completed if status.request_counts else 0\n",
    "                total = status.request_counts.total if status.request_counts else 0\n",
    "                \n",
    "                progress = f\"{completed}/{total}\" if total > 0 else \"N/A\"\n",
    "                print(f\"[{datetime.now().strftime('%H:%M:%S')}] 상태: {status.status}, 진행: {progress}, 경과 시간: {elapsed_time:.2f}초\")\n",
    "                \n",
    "                if status.status in ['completed', 'failed', 'cancelled', 'expired']:\n",
    "                    break\n",
    "                \n",
    "                # 체크 간격 조정\n",
    "                if interval_idx < len(check_intervals) - 1:\n",
    "                    interval_idx += 1\n",
    "                \n",
    "                time.sleep(check_intervals[interval_idx])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"상태 확인 중 오류 발생: {e}\")\n",
    "                time.sleep(60)  # 오류 발생 시 1분 대기 후 재시도\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"배치 작업 완료: 상태={status.status}, 소요 시간={total_time:.2f}초\")\n",
    "        \n",
    "        # 작업이 성공적으로 완료된 경우 결과 처리\n",
    "        output_file_path = f\"{output_dir}/criminal_law_batch_output_{timestamp}.jsonl\"\n",
    "        \n",
    "        if status.status == 'completed':\n",
    "            output_file_id = status.output_file_id\n",
    "            print(f\"배치 결과 파일 다운로드 시작: ID={output_file_id}\")\n",
    "            \n",
    "            # 결과 파일 다운로드\n",
    "            try:\n",
    "                file_response = self.openai_client.files.content(output_file_id)\n",
    "                \n",
    "                # 결과 파일 저장\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(file_response.text)\n",
    "                \n",
    "                print(f\"배치 결과 파일 저장 완료: {output_file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"결과 파일 다운로드 실패: {e}\")\n",
    "                raise\n",
    "        else:\n",
    "            print(f\"배치 작업이 정상적으로 완료되지 않음: 상태={status.status}\")\n",
    "            if hasattr(status, 'errors') and status.errors:\n",
    "                print(\"오류 내용:\")\n",
    "                for error in status.errors:\n",
    "                    print(f\"  - {error}\")\n",
    "            raise Exception(f\"배치 작업 실패: {status.status}\")\n",
    "        \n",
    "        return output_file_path\n",
    "    \n",
    "    def evaluate_results(self, \n",
    "                         batch_output_path: str, \n",
    "                         questions_df: pd.DataFrame,\n",
    "                         output_dir: str = \"results\") -> Dict[str, Any]:\n",
    "        \"\"\"결과 평가 - 최적화된 버전\n",
    "        \n",
    "        Args:\n",
    "            batch_output_path: 배치 출력 파일 경로\n",
    "            questions_df: 질문 데이터프레임\n",
    "            output_dir: 결과 저장 디렉토리\n",
    "            \n",
    "        Returns:\n",
    "            평가 결과 요약\n",
    "        \"\"\"\n",
    "        timestamp = os.path.basename(batch_output_path).split('_')[-1].split('.')[0]\n",
    "        \n",
    "        print(f\"배치 결과 평가 시작: {batch_output_path}\")\n",
    "        \n",
    "        # 배치 결과 로드\n",
    "        batch_results = []\n",
    "        with open(batch_output_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    batch_results.append(json.loads(line))\n",
    "        \n",
    "        print(f\"배치 결과 로드 완료: 총 {len(batch_results)}개 결과\")\n",
    "        \n",
    "        # 정확도 평가\n",
    "        correct_count = 0\n",
    "        results_with_answers = []\n",
    "        \n",
    "        # 카테고리별 성능 추적을 위한 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7ca9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_results(self, \n",
    "                    batch_output_path: str, \n",
    "                    questions_df: pd.DataFrame,\n",
    "                    output_dir: str = \"results\") -> Dict[str, Any]:\n",
    "    \"\"\"결과 평가 - 정교한 분석 버전\n",
    "    \n",
    "    Args:\n",
    "        batch_output_path: 배치 출력 파일 경로\n",
    "        questions_df: 질문 데이터프레임\n",
    "        output_dir: 결과 저장 디렉토리\n",
    "        \n",
    "    Returns:\n",
    "        평가 결과 요약\n",
    "    \"\"\"\n",
    "    timestamp = os.path.basename(batch_output_path).split('_')[-1].split('.')[0]\n",
    "    \n",
    "    print(f\"배치 결과 평가 시작: {batch_output_path}\")\n",
    "    \n",
    "    # 배치 결과 로드\n",
    "    batch_results = []\n",
    "    with open(batch_output_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                batch_results.append(json.loads(line))\n",
    "    \n",
    "    print(f\"배치 결과 로드 완료: 총 {len(batch_results)}개 결과\")\n",
    "    \n",
    "    # 정확도 평가\n",
    "    correct_count = 0\n",
    "    results_with_answers = []\n",
    "    \n",
    "    # 카테고리별 성능 추적\n",
    "    question_types = {\n",
    "        '구성요건': {'correct': 0, 'total': 0},\n",
    "        '위법성': {'correct': 0, 'total': 0},\n",
    "        '책임': {'correct': 0, 'total': 0},\n",
    "        '미수/공범': {'correct': 0, 'total': 0},\n",
    "        '형벌': {'correct': 0, 'total': 0}, \n",
    "        '기타': {'correct': 0, 'total': 0}\n",
    "    }\n",
    "    \n",
    "    # 오답 패턴 분석\n",
    "    error_patterns = {\n",
    "        'A로 예측했으나 실제 정답은 B': 0,\n",
    "        'A로 예측했으나 실제 정답은 C': 0,\n",
    "        'A로 예측했으나 실제 정답은 D': 0,\n",
    "        'B로 예측했으나 실제 정답은 A': 0,\n",
    "        'B로 예측했으나 실제 정답은 C': 0,\n",
    "        'B로 예측했으나 실제 정답은 D': 0,\n",
    "        'C로 예측했으나 실제 정답은 A': 0,\n",
    "        'C로 예측했으나 실제 정답은 B': 0,\n",
    "        'C로 예측했으나 실제 정답은 D': 0,\n",
    "        'D로 예측했으나 실제 정답은 A': 0,\n",
    "        'D로 예측했으나 실제 정답은 B': 0,\n",
    "        'D로 예측했으나 실제 정답은 C': 0\n",
    "    }\n",
    "    \n",
    "    # 신뢰도 분석 (응답의 확신도에 따른 정확도)\n",
    "    confidence_levels = {\n",
    "        '높음': {'correct': 0, 'total': 0},\n",
    "        '중간': {'correct': 0, 'total': 0},\n",
    "        '낮음': {'correct': 0, 'total': 0}\n",
    "    }\n",
    "    \n",
    "    # 결과 분석을 위한 정규 표현식 패턴\n",
    "    confidence_high = re.compile(r'(확실|분명|명백|틀림없|확신|100%|매우 높|강한 확신)')\n",
    "    confidence_low = re.compile(r'(불확실|어려운|애매|모호|낮은 확신|불명확|확신할 수 없)')\n",
    "    \n",
    "    # 질문 유형 분류 패턴\n",
    "    type_patterns = {\n",
    "        '구성요건': re.compile(r'(구성요건|범죄의?\\s*성립|성립요건|행위 태양|주체|객체|행위|결과)'),\n",
    "        '위법성': re.compile(r'(위법성|정당방위|긴급피난|자구행위|피해자동의|의사)'),\n",
    "        '책임': re.compile(r'(책임|책임능력|원인에서 자유로운 행위|강요된 행위|기대가능성|심신|정상|초법규)'),\n",
    "        '미수/공범': re.compile(r'(미수|공범|예비|음모|중지|불능|교사|방조|종범|공동정범|간접정범)'),\n",
    "        '형벌': re.compile(r'(형벌|처벌|양형|누범|선고유예|집행유예|가중|감경)')\n",
    "    }\n",
    "    \n",
    "    for result in batch_results:\n",
    "        custom_id = result['custom_id']\n",
    "        idx = int(custom_id.split('_')[1])\n",
    "        \n",
    "        if result.get('error') is not None:\n",
    "            print(f\"Error in result {custom_id}: {result['error']}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response_text = result['response']['body']['choices'][0]['message']['content'].strip()\n",
    "            \n",
    "            # 응답에서 답변 추출 (A, B, C, D 중 하나)\n",
    "            predicted_answer = self.text_processor.extract_answer(response_text)\n",
    "            \n",
    "            if predicted_answer is None:\n",
    "                print(f\"Could not extract answer from response for question {idx}: {response_text[:100]}...\")\n",
    "                continue\n",
    "            \n",
    "            # 정답과 비교 (CSV에서는 1-indexed, 1=A, 2=B, 3=C, 4=D)\n",
    "            correct_answer = chr(64 + questions_df.iloc[idx]['answer'])  # 1->A, 2->B, 3->C, 4->D\n",
    "            is_correct = (predicted_answer == correct_answer)\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "            else:\n",
    "                # 오답 패턴 추적\n",
    "                error_key = f'{predicted_answer}로 예측했으나 실제 정답은 {correct_answer}'\n",
    "                if error_key in error_patterns:\n",
    "                    error_patterns[error_key] += 1\n",
    "            \n",
    "            # 질문 유형 분류\n",
    "            question_type = '기타'\n",
    "            question_text = questions_df.iloc[idx]['question'].lower()\n",
    "            \n",
    "            for type_name, pattern in type_patterns.items():\n",
    "                if pattern.search(question_text):\n",
    "                    question_type = type_name\n",
    "                    break\n",
    "                    \n",
    "            # 유형별 정확도 추적\n",
    "            if question_type in question_types:\n",
    "                question_types[question_type]['total'] += 1\n",
    "                if is_correct:\n",
    "                    question_types[question_type]['correct'] += 1\n",
    "            \n",
    "            # 신뢰도 분석\n",
    "            confidence_level = '중간'  # 기본값\n",
    "            if confidence_high.search(response_text):\n",
    "                confidence_level = '높음'\n",
    "            elif confidence_low.search(response_text):\n",
    "                confidence_level = '낮음'\n",
    "                \n",
    "            confidence_levels[confidence_level]['total'] += 1\n",
    "            if is_correct:\n",
    "                confidence_levels[confidence_level]['correct'] += 1\n",
    "            \n",
    "            # 전체 결과 수집\n",
    "            results_with_answers.append({\n",
    "                'question_id': idx,\n",
    "                'question': questions_df.iloc[idx]['question'],\n",
    "                'predicted': predicted_answer,\n",
    "                'actual': correct_answer,\n",
    "                'is_correct': is_correct,\n",
    "                'confidence': confidence_level,\n",
    "                'question_type': question_type,\n",
    "                'response': response_text\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing result for question {idx}: {e}\")\n",
    "    \n",
    "    accuracy = correct_count / len(results_with_answers) if results_with_answers else 0\n",
    "    print(f\"정확도: {accuracy:.4f} ({correct_count}/{len(results_with_answers)})\")\n",
    "    \n",
    "    # 유형별 정확도 계산\n",
    "    type_accuracies = {}\n",
    "    for q_type, stats in question_types.items():\n",
    "        if stats['total'] > 0:\n",
    "            type_accuracies[q_type] = stats['correct'] / stats['total']\n",
    "            print(f\"{q_type} 유형 정확도: {type_accuracies[q_type]:.4f} ({stats['correct']}/{stats['total']})\")\n",
    "    \n",
    "    # 신뢰도 수준별 정확도 계산\n",
    "    confidence_accuracies = {}\n",
    "    for conf_level, stats in confidence_levels.items():\n",
    "        if stats['total'] > 0:\n",
    "            confidence_accuracies[conf_level] = stats['correct'] / stats['total']\n",
    "            print(f\"{conf_level} 신뢰도 응답 정확도: {confidence_accuracies[conf_level]:.4f} ({stats['correct']}/{stats['total']})\")\n",
    "    \n",
    "    # 결과를 CSV 파일로 저장\n",
    "    results_df = pd.DataFrame(results_with_answers)\n",
    "    results_file = f\"{output_dir}/criminal_law_results_{timestamp}.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f\"상세 결과 CSV 파일 저장 완료: {results_file}\")\n",
    "    \n",
    "    # 결과 시각화 및 분석 차트 생성\n",
    "    if len(results_with_answers) > 0:\n",
    "        # 결과 시각화 디렉토리 생성\n",
    "        viz_dir = f\"{output_dir}/visualizations\"\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. 혼동 행렬 시각화\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        confusion_data = {\n",
    "            'A': {'A': 0, 'B': 0, 'C': 0, 'D': 0},\n",
    "            'B': {'A': 0, 'B': 0, 'C': 0, 'D': 0},\n",
    "            'C': {'A': 0, 'B': 0, 'C': 0, 'D': 0},\n",
    "            'D': {'A': 0, 'B': 0, 'C': 0, 'D': 0}\n",
    "        }\n",
    "        \n",
    "        for result in results_with_answers:\n",
    "            confusion_data[result['actual']][result['predicted']] += 1\n",
    "            \n",
    "        conf_matrix = np.array([\n",
    "            [confusion_data['A']['A'], confusion_data['A']['B'], confusion_data['A']['C'], confusion_data['A']['D']],\n",
    "            [confusion_data['B']['A'], confusion_data['B']['B'], confusion_data['B']['C'], confusion_data['B']['D']],\n",
    "            [confusion_data['C']['A'], confusion_data['C']['B'], confusion_data['C']['C'], confusion_data['C']['D']],\n",
    "            [confusion_data['D']['A'], confusion_data['D']['B'], confusion_data['D']['C'], confusion_data['D']['D']]\n",
    "        ])\n",
    "        \n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=['A', 'B', 'C', 'D'],\n",
    "                   yticklabels=['A', 'B', 'C', 'D'])\n",
    "        plt.title('혼동 행렬 (Confusion Matrix)')\n",
    "        plt.xlabel('예측 답변')\n",
    "        plt.ylabel('실제 정답')\n",
    "        plt.tight_layout()\n",
    "        confusion_file = f\"{viz_dir}/confusion_matrix_{timestamp}.png\"\n",
    "        plt.savefig(confusion_file)\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. 질문 유형별 정확도 시각화\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        types = []\n",
    "        accs = []\n",
    "        counts = []\n",
    "        \n",
    "        for q_type, stats in question_types.items():\n",
    "            if stats['total'] > 0:\n",
    "                types.append(q_type)\n",
    "                accs.append(stats['correct'] / stats['total'])\n",
    "                counts.append(stats['total'])\n",
    "        \n",
    "        # 카운트에 비례하는 막대 너비 설정\n",
    "        max_count = max(counts) if counts else 1\n",
    "        widths = [0.3 + 0.7 * (count / max_count) for count in counts]\n",
    "        \n",
    "        # 막대 그래프 생성, 높이는 정확도, 너비는 카운트에 비례\n",
    "        for i, (q_type, acc, width) in enumerate(zip(types, accs, widths)):\n",
    "            plt.barh(i, acc, height=width, color='skyblue')\n",
    "            plt.text(acc + 0.02, i, f'{acc:.3f} ({question_types[q_type][\"correct\"]}/{question_types[q_type][\"total\"]})')\n",
    "        \n",
    "        plt.yticks(range(len(types)), types)\n",
    "        plt.xlabel('정확도')\n",
    "        plt.title('질문 유형별 정확도')\n",
    "        plt.xlim(0, 1.1)\n",
    "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        type_acc_file = f\"{viz_dir}/type_accuracy_{timestamp}.png\"\n",
    "        plt.savefig(type_acc_file)\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. 신뢰도별 정확도 시각화\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        confs = []\n",
    "        conf_accs = []\n",
    "        conf_counts = []\n",
    "        \n",
    "        for conf, stats in confidence_levels.items():\n",
    "            if stats['total'] > 0:\n",
    "                confs.append(conf)\n",
    "                conf_accs.append(stats['correct'] / stats['total'])\n",
    "                conf_counts.append(stats['total'])\n",
    "        \n",
    "        bars = plt.bar(confs, conf_accs, color=['green', 'yellow', 'red'])\n",
    "        plt.title('신뢰도 수준별 정확도')\n",
    "        plt.ylabel('정확도')\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # 막대 위에 카운트 표시\n",
    "        for i, (bar, count, acc) in enumerate(zip(bars, conf_counts, conf_accs)):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, acc + 0.02, \n",
    "                   f'{acc:.3f}\\n({count}개)', \n",
    "                   ha='center', va='bottom')\n",
    "            \n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        conf_acc_file = f\"{viz_dir}/confidence_accuracy_{timestamp}.png\"\n",
    "        plt.savefig(conf_acc_file)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"분석 결과 시각화 파일 저장 완료: {viz_dir}/\")\n",
    "    \n",
    "    # 결과 요약 정보\n",
    "    summary = {\n",
    "        'timestamp': timestamp,\n",
    "        'total_questions': len(questions_df),\n",
    "        'processed_questions': len(results_with_answers),\n",
    "        'correct_answers': correct_count,\n",
    "        'accuracy': accuracy,\n",
    "        'type_accuracies': type_accuracies,\n",
    "        'confidence_accuracies': confidence_accuracies,\n",
    "        'error_patterns': error_patterns,\n",
    "        'results_file': results_file,\n",
    "        'batch_output_file': batch_output_path,\n",
    "        'visualization_files': {\n",
    "            'confusion_matrix': confusion_file if len(results_with_answers) > 0 else None,\n",
    "            'type_accuracy': type_acc_file if len(results_with_answers) > 0 else None,\n",
    "            'confidence_accuracy': conf_acc_file if len(results_with_answers) > 0 else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 요약 파일 저장\n",
    "    summary_file = f\"{output_dir}/criminal_law_benchmark_summary_{timestamp}.json\"\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"벤치마크 평가 완료. 최종 정확도: {accuracy:.4f}\")\n",
    "    print(f\"결과 요약 파일: {summary_file}\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb04ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(self, \n",
    "                questions_csv_path: str, \n",
    "                output_dir: str = \"results\",\n",
    "                skip_data_loading: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"전체 파이프라인 실행 - 통합 최적화 버전\n",
    "    \n",
    "    Args:\n",
    "        questions_csv_path: 질문 CSV 파일 경로\n",
    "        output_dir: 결과 저장 디렉토리\n",
    "        skip_data_loading: 데이터 로딩 단계 건너뛰기 여부\n",
    "        \n",
    "    Returns:\n",
    "        평가 결과 요약\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(\"=== 한국 형법 RAG 파이프라인 실행 시작 ===\")\n",
    "    print(f\"시작 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 데이터 로드 (선택적)\n",
    "    if not skip_data_loading:\n",
    "        print(\"\\n=== 단계 1: 데이터 로드 및 그래프 구축 ===\")\n",
    "        pdf_path = './dataset/criminal-law.pdf'\n",
    "        precedent_dir = './dataset/precedent_label/'\n",
    "        \n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"경고: {pdf_path} 파일이 존재하지 않습니다!\")\n",
    "            return {\"error\": f\"파일을 찾을 수 없음: {pdf_path}\"}\n",
    "            \n",
    "        if not os.path.exists(precedent_dir):\n",
    "            print(f\"경고: {precedent_dir} 디렉토리가 존재하지 않습니다!\")\n",
    "            return {\"error\": f\"디렉토리를 찾을 수 없음: {precedent_dir}\"}\n",
    "            \n",
    "        self.load_data(pdf_path, precedent_dir)\n",
    "    else:\n",
    "        print(\"\\n=== 단계 1: 데이터 로드 건너뛰기 (skip_data_loading=True) ===\")\n",
    "    \n",
    "    # 질문 로드\n",
    "    try:\n",
    "        print(\"\\n=== 단계 2: 질문 데이터 로드 ===\")\n",
    "        questions_df = pd.read_csv(questions_csv_path)\n",
    "        print(f\"CSV 파일에서 {len(questions_df)} 개의 질문 로드 완료\")\n",
    "        \n",
    "        # 데이터 정합성 확인\n",
    "        required_columns = ['question', 'answer', 'A', 'B', 'C', 'D']\n",
    "        missing_columns = [col for col in required_columns if col not in questions_df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            error_msg = f\"CSV 파일 형식 오류: 다음 열이 없습니다: {', '.join(missing_columns)}\"\n",
    "            print(f\"오류: {error_msg}\")\n",
    "            return {\"error\": error_msg}\n",
    "            \n",
    "        # 데이터 유효성 검사\n",
    "        if questions_df['answer'].min() < 1 or questions_df['answer'].max() > 4:\n",
    "            print(\"경고: 'answer' 열의 값이 유효하지 않습니다. 값은 1-4 사이여야 합니다.\")\n",
    "            \n",
    "        # 진행률 출력을 위한 전체 단계 수\n",
    "        total_steps = 3 if skip_data_loading else 4\n",
    "        current_step = 2\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"질문 데이터 로드 실패: {e}\")\n",
    "        return {\"error\": f\"CSV 로드 오류: {str(e)}\"}\n",
    "    \n",
    "    try:\n",
    "        # 배치 요청 생성\n",
    "        print(f\"\\n=== 단계 {current_step + 1}/{total_steps}: 배치 요청 생성 및 실행 ===\")\n",
    "        batch_requests = self.create_batch_requests(questions_df)\n",
    "        \n",
    "        # 배치 API 실행\n",
    "        batch_output_path = self.run_batch_api(batch_requests, output_dir)\n",
    "        current_step += 1\n",
    "        \n",
    "        # 결과 평가\n",
    "        print(f\"\\n=== 단계 {current_step + 1}/{total_steps}: 결과 평가 및 분석 ===\")\n",
    "        summary = self.evaluate_results(batch_output_path, questions_df, output_dir)\n",
    "        \n",
    "        # 리소스 정리\n",
    "        print(\"\\n=== 리소스 정리 중... ===\")\n",
    "        self.search_service.close()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        # 총 실행 시간 추가\n",
    "        summary['execution_time_seconds'] = total_time\n",
    "        summary['execution_time_formatted'] = f\"{total_time // 3600:.0f}시간 {(total_time % 3600) // 60:.0f}분 {total_time % 60:.2f}초\"\n",
    "        \n",
    "        print(f\"\\n=== 파이프라인 실행 완료 ===\")\n",
    "        print(f\"총 실행 시간: {summary['execution_time_formatted']}\")\n",
    "        print(f\"정확도: {summary['accuracy']:.4f} ({summary['correct_answers']}/{summary['processed_questions']})\")\n",
    "        \n",
    "        return summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"파이프라인 실행 중 오류 발생: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"execution_time_seconds\": total_time,\n",
    "            \"execution_time_formatted\": f\"{total_time // 3600:.0f}시간 {(total_time % 3600) // 60:.0f}분 {total_time % 60:.2f}초\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "122286bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국 형법 RAG 에이전트 시스템 시작하는 중...\n",
      "파이프라인 초기화 중...\n",
      "프로그램 실행 중 예상치 못한 오류 발생: 1 validation error for OpenAIEmbeddings\n",
      "openai_api_key\n",
      "  Extra inputs are not permitted [type=extra_forbidden, input_value='sk-proj-xc7byHaIfHgPJpCb...QExXYBRZuFZonNzN9O1y2cA', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22028/898157036.py\", line 70, in main\n",
      "    pipeline = LegalRAGPipeline(\n",
      "  File \"/var/folders/mh/1w84fr7s5kxcwc2l24qrjjwc0000gn/T/ipykernel_22028/1719764201.py\", line 24, in __init__\n",
      "    self.embedding_model = OpenAIEmbeddings(\n",
      "  File \"/opt/anaconda3/envs/venv/lib/python3.9/site-packages/pydantic/main.py\", line 253, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for OpenAIEmbeddings\n",
      "openai_api_key\n",
      "  Extra inputs are not permitted [type=extra_forbidden, input_value='sk-proj-xc7byHaIfHgPJpCb...QExXYBRZuFZonNzN9O1y2cA', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\n"
     ]
    }
   ],
   "source": [
    "# 메인 실행 함수\n",
    "# ===========\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수 - 개선된 버전\"\"\"\n",
    "    print(\"한국 형법 RAG 에이전트 시스템 시작하는 중...\")\n",
    "    \n",
    "    # 환경 변수 로드\n",
    "    load_dotenv()\n",
    "    \n",
    "    # 환경 설정\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "    neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "    neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    \n",
    "    # 필수 환경 변수 확인\n",
    "    missing_vars = []\n",
    "    if not openai_api_key:\n",
    "        missing_vars.append(\"OPENAI_API_KEY\")\n",
    "    if not neo4j_uri:\n",
    "        missing_vars.append(\"NEO4J_URI\")\n",
    "    if not neo4j_username:\n",
    "        missing_vars.append(\"NEO4J_USERNAME\")\n",
    "    if not neo4j_password:\n",
    "        missing_vars.append(\"NEO4J_PASSWORD\")\n",
    "        \n",
    "    if missing_vars:\n",
    "        print(f\"오류: 다음 환경 변수가 설정되지 않았습니다: {', '.join(missing_vars)}\")\n",
    "        print(\"프로그램을 실행하기 전 .env 파일에 모든 환경 변수를 설정해주세요.\")\n",
    "        return\n",
    "    \n",
    "    # 필요한 디렉토리 구조 확인\n",
    "    os.makedirs(\"dataset\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # 입력 파일 확인\n",
    "    questions_csv_path = './dataset/Criminal-Law-test.csv'\n",
    "    if not os.path.exists(questions_csv_path):\n",
    "        print(f\"오류: 질문 파일을 찾을 수 없습니다: {questions_csv_path}\")\n",
    "        print(\"dataset 디렉토리에 CriminalLawtest.csv 파일이 있는지 확인하세요.\")\n",
    "        return\n",
    "    \n",
    "    # 판례 데이터와 형법 PDF 파일 확인\n",
    "    pdf_path = './dataset/criminal-law.pdf'\n",
    "    precedent_dir = './dataset/precedent_label/'\n",
    "    \n",
    "    skip_data_loading = True  # 기본값\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"경고: 형법 PDF 파일을 찾을 수 없습니다: {pdf_path}\")\n",
    "        print(\"PDF 파일이 없으면 데이터 로딩 단계를 건너뛸 수 없습니다.\")\n",
    "    \n",
    "    if not os.path.exists(precedent_dir) or not os.path.isdir(precedent_dir):\n",
    "        print(f\"경고: 판례 디렉토리를 찾을 수 없습니다: {precedent_dir}\")\n",
    "        print(\"판례 디렉토리가 없으면 데이터 로딩 단계를 건너뛸 수 없습니다.\")\n",
    "    \n",
    "    if not os.path.exists(pdf_path) or not os.path.exists(precedent_dir):\n",
    "        # 사용자에게 데이터 로딩 여부 확인\n",
    "        user_input = input(\"데이터 파일이 없습니다. 그래도 진행하시겠습니까? (데이터가 이미 Neo4j에 로드되어 있다면 'y' 입력): \")\n",
    "        skip_data_loading = user_input.lower() == 'y'\n",
    "        \n",
    "        if not skip_data_loading:\n",
    "            print(\"프로그램을 종료합니다. 필요한 데이터 파일을 준비한 후 다시 실행하세요.\")\n",
    "            return\n",
    "    \n",
    "    try:\n",
    "        # 파이프라인 생성 및 실행\n",
    "        print(\"파이프라인 초기화 중...\")\n",
    "        pipeline = LegalRAGPipeline(\n",
    "            openai_api_key,\n",
    "            neo4j_uri,\n",
    "            neo4j_username,\n",
    "            neo4j_password\n",
    "        )\n",
    "        \n",
    "        # 데이터 설정\n",
    "        output_dir = \"results\"\n",
    "        \n",
    "        # 파이프라인 실행\n",
    "        summary = pipeline.run_pipeline(\n",
    "            questions_csv_path,\n",
    "            output_dir,\n",
    "            skip_data_loading=skip_data_loading\n",
    "        )\n",
    "        \n",
    "        # 오류 확인\n",
    "        if \"error\" in summary:\n",
    "            print(f\"\\n실행 중 오류가 발생했습니다: {summary['error']}\")\n",
    "            if \"execution_time_formatted\" in summary:\n",
    "                print(f\"총 실행 시간: {summary['execution_time_formatted']}\")\n",
    "            return\n",
    "        \n",
    "        # 결과 요약 출력\n",
    "        print(\"\\n=== 파이프라인 실행 요약 ===\")\n",
    "        print(f\"총 질문 수: {summary['total_questions']}\")\n",
    "        print(f\"처리된 질문 수: {summary['processed_questions']}\")\n",
    "        print(f\"정답 수: {summary['correct_answers']}\")\n",
    "        print(f\"정확도: {summary['accuracy']:.4f}\")\n",
    "        print(f\"총 실행 시간: {summary['execution_time_formatted']}\")\n",
    "        print(f\"결과 파일: {summary['results_file']}\")\n",
    "        print(f\"배치 출력 파일: {summary['batch_output_file']}\")\n",
    "        \n",
    "        # 유형별 정확도 출력\n",
    "        if 'type_accuracies' in summary:\n",
    "            print(\"\\n=== 질문 유형별 정확도 ===\")\n",
    "            for q_type, acc in summary['type_accuracies'].items():\n",
    "                print(f\"{q_type}: {acc:.4f}\")\n",
    "                \n",
    "        print(\"\\n작업이 성공적으로 완료되었습니다!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"프로그램 실행 중 예상치 못한 오류 발생: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b779371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter 노트북에서 대화형으로 실행하기 위한 코드\n",
    "\n",
    "def run_benchmark_interactively():\n",
    "    \"\"\"Jupyter 노트북에서 대화형으로 벤치마크 실행\"\"\"\n",
    "    # 환경 변수 로드\n",
    "    load_dotenv()\n",
    "    \n",
    "    # 환경 설정\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    neo4j_uri = os.getenv(\"NEO4J_URI\")\n",
    "    neo4j_username = os.getenv(\"NEO4J_USERNAME\")\n",
    "    neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "    \n",
    "    # 필수 환경 변수 확인\n",
    "    missing_vars = []\n",
    "    if not openai_api_key:\n",
    "        missing_vars.append(\"OPENAI_API_KEY\")\n",
    "    if not neo4j_uri:\n",
    "        missing_vars.append(\"NEO4J_URI\")\n",
    "    if not neo4j_username:\n",
    "        missing_vars.append(\"NEO4J_USERNAME\")\n",
    "    if not neo4j_password:\n",
    "        missing_vars.append(\"NEO4J_PASSWORD\")\n",
    "        \n",
    "    if missing_vars:\n",
    "        print(f\"오류: 다음 환경 변수가 설정되지 않았습니다: {', '.join(missing_vars)}\")\n",
    "        print(\"노트북을 실행하기 전 .env 파일에 모든 환경 변수를 설정해주세요.\")\n",
    "        return None\n",
    "    \n",
    "    # 파이프라인 초기화\n",
    "    pipeline = LegalRAGPipeline(\n",
    "        openai_api_key,\n",
    "        neo4j_uri,\n",
    "        neo4j_username,\n",
    "        neo4j_password\n",
    "    )\n",
    "    \n",
    "    print(\"한국 형법 RAG 에이전트 시스템이 준비되었습니다.\")\n",
    "    return pipeline\n",
    "\n",
    "# 파이프라인 객체 생성\n",
    "pipeline = run_benchmark_interactively()\n",
    "\n",
    "if pipeline:\n",
    "    # 데이터 파일 확인 및 경로 설정\n",
    "    questions_csv_path = './dataset/CriminalLawtest.csv'\n",
    "    pdf_path = './dataset/criminal-law.pdf'\n",
    "    precedent_dir = './dataset/precedent_label/'\n",
    "    \n",
    "    files_exist = True\n",
    "    if not os.path.exists(questions_csv_path):\n",
    "        print(f\"경고: 질문 파일을 찾을 수 없습니다: {questions_csv_path}\")\n",
    "        files_exist = False\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"경고: 형법 PDF 파일을 찾을 수 없습니다: {pdf_path}\")\n",
    "    if not os.path.exists(precedent_dir) or not os.path.isdir(precedent_dir):\n",
    "        print(f\"경고: 판례 디렉토리를 찾을 수 없습니다: {precedent_dir}\")\n",
    "    \n",
    "    if files_exist:\n",
    "        print(\"\\n다음 중 실행할 작업을 선택하세요:\")\n",
    "        print(\"1. 전체 파이프라인 실행 (데이터 로드 포함)\")\n",
    "        print(\"2. 데이터 로드 건너뛰고 벤치마크만 실행 (Neo4j에 이미 데이터가 있는 경우)\")\n",
    "        print(\"3. 특정 질문에 대해 RAG 테스트 실행\")\n",
    "        \n",
    "        # Jupyter에서는 화면에 직접 출력하고, 다음 셀에서 사용자 입력을 받습니다.\n",
    "        print(\"\\n다음 셀에서 선택한 옵션에 해당하는 코드를 실행하세요.\")\n",
    "    else:\n",
    "        print(\"\\n필요한 파일이 없습니다. 파일을 준비한 후 다시 시도하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ab31eeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 옵션 2 실행\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mrun_benchmark_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 실행하려면 주석 해제\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m, in \u001b[0;36mrun_benchmark_only\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_benchmark_only\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpipeline\u001b[49m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m파이프라인이 초기화되지 않았습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# 옵션 2: 데이터 로드 건너뛰고 벤치마크만 실행\n",
    "def run_benchmark_only():\n",
    "    if not pipeline:\n",
    "        print(\"파이프라인이 초기화되지 않았습니다.\")\n",
    "        return\n",
    "        \n",
    "    questions_csv_path = './dataset/CriminalLawtest.csv'\n",
    "    output_dir = \"results\"\n",
    "    \n",
    "    print(\"=== 벤치마크만 실행 시작 (데이터 로드 건너뜀) ===\")\n",
    "    summary = pipeline.run_pipeline(\n",
    "        questions_csv_path,\n",
    "        output_dir,\n",
    "        skip_data_loading=True  # 데이터 로드 건너뜀\n",
    "    )\n",
    "    \n",
    "    if \"error\" in summary:\n",
    "        print(f\"오류 발생: {summary['error']}\")\n",
    "    else:\n",
    "        print(\"\\n=== 실행 결과 요약 ===\")\n",
    "        print(f\"정확도: {summary['accuracy']:.4f} ({summary['correct_answers']}/{summary['processed_questions']})\")\n",
    "        print(f\"총 실행 시간: {summary['execution_time_formatted']}\")\n",
    "        \n",
    "    return summary\n",
    "\n",
    "# 옵션 2 실행\n",
    "summary = run_benchmark_only()  # 실행하려면 주석 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17b5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
