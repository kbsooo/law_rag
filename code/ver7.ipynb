{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b41bb46",
   "metadata": {},
   "source": [
    "# 난잡한거 정리 좀 하고 성능 높여보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀1: import\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from neo4j import GraphDatabase\n",
    "import random\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from openai import OpenAI\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀2: 이것저것 로드\n",
    "load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Embedding model 설정\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small', api_key=OPENAI_API_KEY)\n",
    "embedding_dimension = 1536 # text-embedding-3-small 차원\n",
    "\n",
    "# Data path\n",
    "pdf_path = './dataset/criminal-law.pdf'\n",
    "precedent_dir = './dataset/precedent_label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad90472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀3: Load PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "# pages = loader.load()[2:] # 첫 두 페이지 생략 (표지랑 목차)\n",
    "pages = loader.load() # 아님말고\n",
    "full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "\n",
    "# 전체 텍스트에서 모든 조항 시작 위치 찾기\n",
    "article_pattern = r'제\\d+조(?:의\\d+)?(?:\\s*\\(.+?\\))?'\n",
    "matches = list(re.finditer(article_pattern, full_text))\n",
    "\n",
    "articles = {}\n",
    "for i in range(len(matches)):\n",
    "  current_match = matches[i]\n",
    "  current_article_id = current_match.group(0).strip() # 현재 조항 ID\n",
    "  \n",
    "  # 현재 조항 시작 위치\n",
    "  start_pos = current_match.start()\n",
    "  \n",
    "  # 다음 조항 시작 위치 (없으면 텍스트 끝까지)\n",
    "  end_pos = matches[i+1].start() if i < len(matches)-1 else len(full_text)\n",
    "  \n",
    "  # 현재 조항의 전체 내용 (ID 포함)\n",
    "  article_text = full_text[start_pos:end_pos].strip()\n",
    "  \n",
    "  # 저장 (ID는 조항 번호만)\n",
    "  articles[current_article_id] = article_text\n",
    "  \n",
    "print(f\"Processed {len(articles)} article from PDF\")\n",
    "\n",
    "# 예시 출력\n",
    "if articles:\n",
    "  article_ids = list(articles.keys())\n",
    "  \n",
    "  print(\"\\n--- 처음 5개 조항 ---\")\n",
    "  for i in range(min(5, len(article_ids))):\n",
    "    article_id = article_ids[i]\n",
    "    content = articles[article_id]\n",
    "    print(f\"\\n--- Article: {article_id} ---\")\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)\n",
    "    \n",
    "  print(\"\\n--- 마지막 5개 조항 ---\")\n",
    "  for i in range(max(0, len(article_ids)-10), len(article_ids)):\n",
    "    article_id = article_ids[i]\n",
    "    content = articles[article_id]\n",
    "    print(f\"\\n--- Article: {article_id} ---\")\n",
    "    print(content[:200] + \"...\" if len(content) > 200 else content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb553ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀4: Load precedent JSON files (판례 불러오기)\n",
    "precedents = []\n",
    "for filename in os.listdir(precedent_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        filepath = os.path.join(precedent_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                # 기존에 라벨링 되어있었음\n",
    "                precedent_info = {\n",
    "                    \"case_id\": data.get(\"info\", {}).get(\"caseNoID\", filename.replace(\".json\", \"\")), # 사건번호 (없으면 파일명 사용)\n",
    "                    \"case_name\": data.get(\"info\", {}).get(\"caseNm\"), # 사건명\n",
    "                    \"judgment_summary\": data.get(\"jdgmn\"), # 판결 요약\n",
    "                    \"full_summary\": \" \".join([s.get(\"summ_contxt\", \"\") for s in data.get(\"Summary\", [])]), # 전체 요약 텍스트\n",
    "                    \"keywords\": [kw.get(\"keyword\") for kw in data.get(\"keyword_tagg\", []) if kw.get(\"keyword\")], # 키워드 목록\n",
    "                    \"referenced_rules\": data.get(\"Reference_info\", {}).get(\"reference_rules\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_rules\") else [], # 참조 법조항\n",
    "                    \"referenced_cases\": data.get(\"Reference_info\", {}).get(\"reference_court_case\", \"\").split(',') if data.get(\"Reference_info\", {}).get(\"reference_court_case\") else [], # 참조 판례\n",
    "                }\n",
    "                # 참조 법조항 정제 (조항 번호만)\n",
    "                cleaned_rules = []\n",
    "                rule_pattern = re.compile(r'제\\d+조(?:의\\d+)?') # 패턴 찾기: \"제X조\" or \"제X조의Y\"\n",
    "                for rule in precedent_info[\"referenced_rules\"]:\n",
    "                    # 각 규칙 문자열에서 모든 일치 항목 찾기\n",
    "                    matches = rule_pattern.findall(rule.strip())\n",
    "                    cleaned_rules.extend(matches)\n",
    "                precedent_info[\"referenced_rules\"] = list(set(cleaned_rules)) # 중복 제거하여 고유한 조항 번호만 유지\n",
    "\n",
    "                precedents.append(precedent_info)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Warning: Could not decode JSON from {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(precedents)} precedents.\")\n",
    "# 예시 출력\n",
    "if precedents:\n",
    "    print(\"\\n--- Example Precedent ---\")\n",
    "    print(json.dumps(precedents[0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀5: 로드된 판례 중 무작위로 1,000개만 선택 (시간 문제 때문에...)\n",
    "random.seed(42)  # 재현성을 위한 시드 설정\n",
    "\n",
    "# 전체 판례 수 저장\n",
    "total_precedents = len(precedents)\n",
    "\n",
    "# 무작위로 1,000개 선택 (또는 전체 판례 수가 1,000개보다 적다면 모두 선택)\n",
    "sample_size = min(1000, total_precedents)\n",
    "precedents = random.sample(precedents, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18520772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀6: Neo4j 데이터베이스에 연결\n",
    "try:\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "    driver.verify_connectivity()  # 연결 확인\n",
    "    print(\"Successfully connected to Neo4j.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to Neo4j: {e}\")\n",
    "    # 연결 실패 시 실행 중단\n",
    "    raise\n",
    "\n",
    "# 빠른 조회와 임베딩 검색을 위한 제약조건과 인덱스 생성 함수\n",
    "def setup_neo4j(driver, dimension):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        # 고유성을 위한 제약조건 설정\n",
    "        session.run(\"CREATE CONSTRAINT article_id IF NOT EXISTS FOR (a:Article) REQUIRE a.id IS UNIQUE\")  # 법조항 ID 고유성 제약\n",
    "        session.run(\"CREATE CONSTRAINT precedent_id IF NOT EXISTS FOR (p:Precedent) REQUIRE p.id IS UNIQUE\")  # 판례 ID 고유성 제약\n",
    "        session.run(\"CREATE CONSTRAINT keyword_text IF NOT EXISTS FOR (k:Keyword) REQUIRE k.text IS UNIQUE\")  # 키워드 텍스트 고유성 제약\n",
    "\n",
    "        # 법조항(Article)에 대한 벡터 인덱스 생성\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX article_embedding IF NOT EXISTS \"  # 존재하지 않는 경우에만 생성\n",
    "                \"FOR (a:Article) ON (a.embedding) \"  # Article 노드의 embedding 속성에 대한 인덱스\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"  # 벡터 차원 및 유사도 함수 설정\n",
    "            )\n",
    "            print(\"Article vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Article vector index (may require Neo4j 5.11+ and APOC): {e}\")  # Neo4j 버전 문제일 수 있음\n",
    "            print(\"Continuing without vector index creation for Article.\")  # 인덱스 없이 계속 진행\n",
    "\n",
    "        # 판례(Precedent)에 대한 벡터 인덱스 생성\n",
    "        try:\n",
    "            session.run(\n",
    "                \"CREATE VECTOR INDEX precedent_embedding IF NOT EXISTS \"  # 존재하지 않는 경우에만 생성\n",
    "                \"FOR (p:Precedent) ON (p.embedding) \"  # Precedent 노드의 embedding 속성에 대한 인덱스\n",
    "                f\"OPTIONS {{indexConfig: {{`vector.dimensions`: {dimension}, `vector.similarity_function`: 'cosine'}}}}\"  # 벡터 차원 및 유사도 함수 설정\n",
    "            )\n",
    "            print(\"Precedent vector index created or already exists.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating Precedent vector index (may require Neo4j 5.11+ and APOC): {e}\")  # Neo4j 버전 문제일 수 있음\n",
    "            print(\"Continuing without vector index creation for Precedent.\")  # 인덱스 없이 계속 진행\n",
    "\n",
    "        # 인덱스가 활성화될 때까지 대기 (중요!)\n",
    "        print(\"Waiting for indexes to populate...\")\n",
    "        session.run(\"CALL db.awaitIndexes(300)\")  # 최대 300초(5분) 동안 대기\n",
    "        print(\"Indexes should be online.\")  # 인덱스 활성화 완료\n",
    "\n",
    "\n",
    "setup_neo4j(driver, embedding_dimension)  # 설정 함수 호출, embedding_dimension은 임베딩 벡터의 차원 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaea3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀7: 법조항 노드 생성 및 임베딩 생성/저장 (이미 했으면 생략가능)\n",
    "def create_article_nodes(driver, articles_dict, embed_model):\n",
    "    print(f\"Creating {len(articles_dict)} Article nodes...\")  # 생성할 법조항 노드 수 출력\n",
    "    count = 0\n",
    "    start_time = time.time()  # 실행 시간 측정 시작\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for article_id, content in articles_dict.items():\n",
    "            if not content:  # 내용이 비어있는 경우 건너뛰기\n",
    "                print(f\"Skipping article {article_id} due to empty content.\")\n",
    "                continue\n",
    "            try:\n",
    "                # 텍스트에 대한 임베딩 생성\n",
    "                embedding = embed_model.embed_query(content)\n",
    "\n",
    "                # Neo4j에 노드 생성\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (a:Article {id: $article_id})  # 해당 ID의 법조항이 있으면 찾고, 없으면 생성\n",
    "                    SET a.text = $content,               # 법조항 텍스트 설정\n",
    "                        a.embedding = $embedding         # 임베딩 벡터 설정\n",
    "                    \"\"\",\n",
    "                    article_id=article_id,\n",
    "                    content=content,\n",
    "                    embedding=embedding\n",
    "                )\n",
    "                count += 1\n",
    "                if count % 50 == 0:  # 50개마다 진행상황 출력\n",
    "                    print(f\"  Processed {count}/{len(articles_dict)} articles...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article {article_id}: {e}\")  # 오류 발생 시 메시지 출력\n",
    "\n",
    "    end_time = time.time()  # 실행 시간 측정 종료\n",
    "    print(f\"Finished creating {count} Article nodes in {end_time - start_time:.2f} seconds.\")  # 총 처리 시간 출력\n",
    "\n",
    "create_article_nodes(driver, articles, embedding_model)  # 함수 실행: 법조항 노드 생성 및 임베딩 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ee5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀8: 판례 노드, 키워드 노드 생성 및 관계 설정 (이미 했으면 생략가능)\n",
    "def create_precedent_nodes_and_relationships(driver, precedents_list, embed_model):\n",
    "    print(f\"Creating {len(precedents_list)} Precedent nodes and relationships...\")  # 생성할 판례 노드 수 출력\n",
    "    count = 0\n",
    "    start_time = time.time()  # 실행 시간 측정 시작\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for precedent in precedents_list:\n",
    "            # 임베딩에 사용할 텍스트: 전체 요약이 있으면 사용, 없으면 판결 요약 사용\n",
    "            text_to_embed = precedent.get(\"full_summary\") or precedent.get(\"judgment_summary\")\n",
    "            if not text_to_embed:\n",
    "                print(f\"Skipping precedent {precedent.get('case_id')} due to empty summary.\")  # 요약이 없는 경우 건너뛰기\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # 텍스트 임베딩 생성\n",
    "                embedding = embed_model.embed_query(text_to_embed)\n",
    "\n",
    "                # 판례 노드 생성\n",
    "                session.run(\n",
    "                    \"\"\"\n",
    "                    MERGE (p:Precedent {id: $case_id})  # 해당 ID의 판례가 있으면 찾고, 없으면 생성\n",
    "                    SET p.name = $case_name,            # 판례명 설정\n",
    "                        p.judgment_summary = $judgment_summary,  # 판결 요약 설정\n",
    "                        p.full_summary = $full_summary,          # 전체 요약 설정\n",
    "                        p.embedding = $embedding         # 임베딩 벡터 설정\n",
    "                    \"\"\",\n",
    "                    case_id=precedent[\"case_id\"],\n",
    "                    case_name=precedent[\"case_name\"],\n",
    "                    judgment_summary=precedent[\"judgment_summary\"],\n",
    "                    full_summary=precedent[\"full_summary\"],\n",
    "                    embedding=embedding\n",
    "                )\n",
    "\n",
    "                # 키워드 노드 생성 및 판례와의 관계 설정\n",
    "                for keyword_text in precedent[\"keywords\"]:\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MERGE (k:Keyword {text: $keyword_text})  # 키워드 노드 생성 또는 찾기\n",
    "                        WITH k\n",
    "                        MATCH (p:Precedent {id: $case_id})       # 판례 노드 찾기\n",
    "                        MERGE (p)-[:HAS_KEYWORD]->(k)            # 판례와 키워드 간 관계 생성\n",
    "                        \"\"\",\n",
    "                        keyword_text=keyword_text,\n",
    "                        case_id=precedent[\"case_id\"]\n",
    "                    )\n",
    "\n",
    "                # 참조된 법조항과의 관계 생성\n",
    "                # 참고: 앞서 추출한 정제된 법조항 ID를 사용합니다\n",
    "                # \"제X조\" 형식을 기반으로 매칭합니다.\n",
    "                for article_id_ref in precedent[\"referenced_rules\"]:\n",
    "                     # 참조된 ID로 시작하는 법조항 노드 찾기(예: \"제21조\"는 \"제21조(정당방위)\"와 매칭됨)\n",
    "                     # 정확한 제목이 참조에 없는 경우에도 매칭이 가능하도록 덜 정밀한 방식 사용\n",
    "                    session.run(\n",
    "                        \"\"\"\n",
    "                        MATCH (p:Precedent {id: $case_id})         # 판례 노드 찾기\n",
    "                        MATCH (a:Article)                          # 모든 법조항 노드 찾기\n",
    "                        WHERE a.id STARTS WITH $article_id_ref     # 특정 ID로 시작하는 법조항만 필터링\n",
    "                        MERGE (p)-[:REFERENCES_ARTICLE]->(a)       # 판례가 법조항을 참조하는 관계 생성\n",
    "                        \"\"\",\n",
    "                        case_id=precedent[\"case_id\"],\n",
    "                        article_id_ref=article_id_ref  # 추출된 \"제X조\" 사용\n",
    "                    )\n",
    "\n",
    "                # 선택사항: 다른 참조된 판례와의 관계 생성 (필요한 경우)\n",
    "                # for ref_case_id in precedent[\"referenced_cases\"]:\n",
    "                #    session.run(...) # MERGE (p)-[:REFERENCES_CASE]->(other_p:Precedent {id: ref_case_id})\n",
    "\n",
    "                count += 1\n",
    "                if count % 100 == 0:  # 100개마다 진행상황 출력\n",
    "                    print(f\"  Processed {count}/{len(precedents_list)} precedents...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing precedent {precedent.get('case_id')}: {e}\")  # 오류 발생 시 메시지 출력\n",
    "\n",
    "    end_time = time.time()  # 실행 시간 측정 종료\n",
    "    print(f\"Finished creating {count} Precedent nodes and relationships in {end_time - start_time:.2f} seconds.\")  # 총 처리 시간 출력\n",
    "\n",
    "\n",
    "create_precedent_nodes_and_relationships(driver, precedents, embedding_model)  # 함수 실행: 판례 노드 생성 및 관계 설정\n",
    "\n",
    "# 작업 완료 후 드라이버 연결 종료\n",
    "# driver.close()  # 다음 단계에서 쿼리를 위해 연결 상태 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀9: graph rag 함수\n",
    "def graph_enhanced_rag(driver, query_text, embed_model, top_k=8):\n",
    "    # print(f\"\\n--- 그래프 기반 검색 실행: '{query_text}' ---\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 임베딩 생성\n",
    "    query_embedding = embed_model.embed_query(query_text)\n",
    "    \n",
    "    # 키워드 추출\n",
    "    keywords = [w for w in re.findall(r'\\w+', query_text) if len(w) > 1]\n",
    "    \n",
    "    results = []\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        try:\n",
    "            # 그래프 구조를 활용한 검색\n",
    "            cypher_query = \"\"\"\n",
    "            // 1. 벡터 검색으로 시작 법조항 찾기\n",
    "            CALL db.index.vector.queryNodes('article_embedding', 15, $query_embedding) \n",
    "            YIELD node as article, score as article_score\n",
    "            \n",
    "            // 2. 해당 법조항과 연결된 판례와 키워드 찾기\n",
    "            OPTIONAL MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article)\n",
    "            OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "            \n",
    "            // 3. 결과 집계 및 점수 계산\n",
    "            WITH article, article_score, precedent, \n",
    "                 collect(DISTINCT keyword.text) as keywords,\n",
    "                 count(precedent) as precedent_count\n",
    "            \n",
    "            // 법조항 점수 = 벡터 점수 + 판례 인용 수에 따른 보너스\n",
    "            WITH article, article_score + (precedent_count * 0.01) as final_score,\n",
    "                 precedent_count, keywords\n",
    "            \n",
    "            RETURN article.id as id, \n",
    "                   'Article' as type, \n",
    "                   article.text as text, \n",
    "                   final_score as score,\n",
    "                   precedent_count,\n",
    "                   keywords\n",
    "            ORDER BY final_score DESC\n",
    "            LIMIT $article_limit\n",
    "            \"\"\"\n",
    "            \n",
    "            # 법조항 검색\n",
    "            article_results = session.run(\n",
    "                cypher_query,\n",
    "                query_embedding=query_embedding,\n",
    "                article_limit=top_k\n",
    "            )\n",
    "            \n",
    "            for record in article_results:\n",
    "                results.append({\n",
    "                    \"type\": record[\"type\"],\n",
    "                    \"id\": record[\"id\"],\n",
    "                    \"score\": record[\"score\"],\n",
    "                    \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                    \"precedent_count\": record[\"precedent_count\"],\n",
    "                    \"related_keywords\": record[\"keywords\"]\n",
    "                })\n",
    "            \n",
    "            # 관련 판례 검색\n",
    "            for article_result in results[:3]:  # 상위 3개 법조항에 대해서만\n",
    "                if article_result[\"type\"] == \"Article\":\n",
    "                    precedent_query = \"\"\"\n",
    "                    // 1. 특정 법조항을 참조하는 판례 찾기\n",
    "                    MATCH (precedent:Precedent)-[:REFERENCES_ARTICLE]->(article:Article)\n",
    "                    WHERE article.id STARTS WITH $article_id\n",
    "                    \n",
    "                    // 2. 해당 판례와 키워드\n",
    "                    OPTIONAL MATCH (precedent)-[:HAS_KEYWORD]->(keyword:Keyword)\n",
    "                    \n",
    "                    // 3. 벡터 유사도 계산\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', 20, $query_embedding) \n",
    "                    YIELD node as vector_node, score as vector_score\n",
    "                    WHERE precedent = vector_node\n",
    "                    \n",
    "                    // 4. 검색어와 관련된 키워드가 있는지 확인하여 보너스 점수\n",
    "                    WITH precedent, vector_score, \n",
    "                         collect(DISTINCT keyword.text) as keywords,\n",
    "                         sum(CASE WHEN $query_keywords IS NULL THEN 0\n",
    "                              WHEN any(k IN $query_keywords WHERE keyword.text CONTAINS k) \n",
    "                              THEN 0.05 ELSE 0 END) as keyword_bonus\n",
    "                    \n",
    "                    // 5. 다른 법조항도 참조하는지 확인\n",
    "                    MATCH (precedent)-[:REFERENCES_ARTICLE]->(ref_article:Article)\n",
    "                    \n",
    "                    // 6. 최종 결과 반환\n",
    "                    RETURN precedent.id as id,\n",
    "                           'Precedent' as type,\n",
    "                           precedent.name as name,\n",
    "                           precedent.full_summary as text,\n",
    "                           vector_score + keyword_bonus as score,\n",
    "                           keywords,\n",
    "                           collect(DISTINCT ref_article.id) as referenced_articles\n",
    "                    ORDER BY score DESC\n",
    "                    LIMIT 2\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    precedent_results = session.run(\n",
    "                        precedent_query,\n",
    "                        article_id=article_result[\"id\"],\n",
    "                        query_embedding=query_embedding,\n",
    "                        query_keywords=keywords\n",
    "                    )\n",
    "                    \n",
    "                    for record in precedent_results:\n",
    "                        # 중복 제거\n",
    "                        if not any(r[\"type\"] == \"Precedent\" and r[\"id\"] == record[\"id\"] for r in results):\n",
    "                            results.append({\n",
    "                                \"type\": record[\"type\"],\n",
    "                                \"id\": record[\"id\"],\n",
    "                                \"name\": record[\"name\"],\n",
    "                                \"score\": record[\"score\"],\n",
    "                                \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                                \"keywords\": record[\"keywords\"],\n",
    "                                \"referenced_articles\": record[\"referenced_articles\"]\n",
    "                            })\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"그래프 검색 오류: {e}\")\n",
    "            # 백업: 기본 벡터 검색\n",
    "            try:\n",
    "                # Article 검색\n",
    "                article_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('article_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    RETURN node.id AS id, 'Article' as type, node.text AS text, score\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in article_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"]\n",
    "                    })\n",
    "                \n",
    "                # Precedent 검색\n",
    "                precedent_res = session.run(\n",
    "                    \"\"\"\n",
    "                    CALL db.index.vector.queryNodes('precedent_embedding', $top_k, $query_embedding) \n",
    "                    YIELD node, score\n",
    "                    MATCH (node)-[:REFERENCES_ARTICLE]->(a:Article)\n",
    "                    OPTIONAL MATCH (node)-[:HAS_KEYWORD]->(k:Keyword)\n",
    "                    RETURN node.id AS id, 'Precedent' as type, \n",
    "                           node.name AS name, node.full_summary AS text, \n",
    "                           score,\n",
    "                           collect(DISTINCT a.id) as referenced_articles,\n",
    "                           collect(DISTINCT k.text) as keywords\n",
    "                    \"\"\",\n",
    "                    top_k=top_k,\n",
    "                    query_embedding=query_embedding\n",
    "                )\n",
    "                \n",
    "                for record in precedent_res:\n",
    "                    results.append({\n",
    "                        \"type\": record[\"type\"],\n",
    "                        \"id\": record[\"id\"],\n",
    "                        \"name\": record[\"name\"],\n",
    "                        \"score\": record[\"score\"],\n",
    "                        \"text\": record[\"text\"][:300] + \"...\" if len(record[\"text\"]) > 300 else record[\"text\"],\n",
    "                        \"referenced_articles\": record[\"referenced_articles\"],\n",
    "                        \"keywords\": record[\"keywords\"]\n",
    "                    })\n",
    "            except Exception as e2:\n",
    "                print(f\"백업 검색 오류: {e2}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # print(f\"검색 완료: {end_time - start_time:.2f}초 소요\")\n",
    "\n",
    "    # 결과를 스코어로 정렬\n",
    "    results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    # print(\"\\n--- 검색 결과 ---\")\n",
    "    # for i, res in enumerate(results[:top_k]):\n",
    "    #     print(f\"{i+1}. 유형: {res['type']}, ID: {res['id']}, 스코어: {res['score']:.4f}\")\n",
    "    #     if res['type'] == 'Precedent':\n",
    "    #         print(f\"   이름: {res.get('name')}\")\n",
    "    #         print(f\"   키워드: {res.get('keywords')}\")\n",
    "    #         print(f\"   참조 법조항: {res.get('referenced_articles')}\")\n",
    "    #     elif res['type'] == 'Article':\n",
    "    #         print(f\"   관련 판례 수: {res.get('precedent_count', 0)}\")\n",
    "    #         print(f\"   관련 키워드: {res.get('related_keywords')}\")\n",
    "    #     print(f\"   미리보기: {res['text']}\")\n",
    "    #     print(\"-\" * 20)\n",
    "\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀10: 테스트 쿼리\n",
    "search_function = graph_enhanced_rag \n",
    "\n",
    "# 테스트 쿼리\n",
    "query = \"정당방위의 요건은 무엇인가?\"\n",
    "retrieved_context = search_function(driver, query, embedding_model, top_k=8)\n",
    "\n",
    "# 드라이버 연결 종료\n",
    "driver.close()\n",
    "print(\"\\nNeo4j 드라이버 연결 종료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 11\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def highlight_relevant_parts(text, question):\n",
    "    \"\"\"법조항 텍스트에서 질문과 관련된 부분을 추출하고 강조합니다.\"\"\"\n",
    "    # 질문에서 주요 키워드 추출 (개선된 함수 사용)\n",
    "    keywords = extract_legal_keywords(question)\n",
    "    \n",
    "    # 전체 텍스트가 짧으면 그대로 반환 (길이 기준 확장)\n",
    "    if len(text) < 500:\n",
    "        return text\n",
    "    \n",
    "    # 문장 단위로 분리 (개선된 분리 패턴)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+|(?<=\\n)', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # 관련 점수 계산 (개선된 점수 부여 시스템)\n",
    "    scored_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # 기본 점수\n",
    "        score = 0\n",
    "        \n",
    "        # 키워드 매칭 점수 (개선됨)\n",
    "        for keyword in keywords:\n",
    "            if keyword in sentence:\n",
    "                # 중요 법률 용어는 더 높은 가중치\n",
    "                if keyword in [\"구성요건\", \"위법성\", \"책임\", \"정당방위\", \"긴급피난\", \n",
    "                             \"고의\", \"과실\", \"미수\", \"예비\", \"음모\", \"공범\"]:\n",
    "                    score += 3\n",
    "                else:\n",
    "                    score += 1\n",
    "        \n",
    "        # 법조항 번호 포함 문장은 높은 가중치\n",
    "        if re.search(r'제\\d+조', sentence):\n",
    "            score += 5\n",
    "        \n",
    "        # 법률적 중요 문장 패턴에 가중치\n",
    "        if any(term in sentence for term in [\"~으로 한다\", \"~라 함은\", \"~을 말한다\", \"다만\", \"단,\", \"제외한다\"]):\n",
    "            score += 3\n",
    "        \n",
    "        # 위치 가중치 (개선됨)\n",
    "        if i == 0:  # 첫 문장 (제목이나 조항 번호일 가능성)\n",
    "            score += 5\n",
    "        elif i == len(sentences) - 1:  # 마지막 문장 (결론일 가능성)\n",
    "            score += 2\n",
    "        elif i <= 2:  # 앞부분 문장들 (정의나 개요일 가능성)\n",
    "            score += 1\n",
    "            \n",
    "        scored_sentences.append((sentence, score, i))  # 원래 순서 저장\n",
    "    \n",
    "    # 점수 및 원래 순서 기준 정렬\n",
    "    # 상위 70% 이상 점수 문장 또는 최소 8문장 선택 (너무 적은 문장만 선택되는 것 방지)\n",
    "    min_score = max(1, sorted([score for _, score, _ in scored_sentences], reverse=True)[0] * 0.3)\n",
    "    relevant_sentences = [(s, score, i) for s, score, i in scored_sentences if score >= min_score]\n",
    "    min_sentences = min(8, len(sentences))\n",
    "    \n",
    "    if len(relevant_sentences) < min_sentences:\n",
    "        # 점수순으로 정렬하여 상위 min_sentences개 선택\n",
    "        relevant_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:min_sentences]\n",
    "    \n",
    "    # 원래 순서로 재정렬\n",
    "    ordered_sentences = sorted(relevant_sentences, key=lambda x: x[2])\n",
    "    \n",
    "    # 법조항 번호와 제목은 항상 포함\n",
    "    if len(ordered_sentences) > 0 and (0, sentences[0], 0) not in ordered_sentences:\n",
    "        ordered_sentences.insert(0, (sentences[0], 0, 0))\n",
    "    \n",
    "    result = \" \".join([s for s, _, _ in ordered_sentences])\n",
    "    \n",
    "    # 결과가 원본의 30% 미만이라면 원본 반환 (너무 많은 내용 손실 방지)\n",
    "    if len(result) < len(text) * 0.3:\n",
    "        return text\n",
    "        \n",
    "    return result\n",
    "\n",
    "def summarize_precedent(text, question):\n",
    "    \"\"\"판례 텍스트에서 질문과 관련된 핵심 내용을 요약합니다.\"\"\"\n",
    "    # 질문에서 주요 키워드 추출\n",
    "    keywords = extract_legal_keywords(question)\n",
    "    \n",
    "    # 텍스트가 이미 짧으면 그대로 반환 (기준 확대)\n",
    "    if len(text) < 300:\n",
    "        return text\n",
    "    \n",
    "    # 문장 단위로 분리 (개선된 분리)\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+|(?<=\\n)', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    # 관련 점수 계산 (개선된 점수 시스템)\n",
    "    scored_sentences = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        score = 0\n",
    "        \n",
    "        # 키워드 포함 여부 (더 정교한 매칭)\n",
    "        for keyword in keywords:\n",
    "            if keyword in sentence:\n",
    "                score += 2\n",
    "                # 문장에서 키워드가 중앙에 있으면 추가 점수\n",
    "                position = sentence.find(keyword) / len(sentence)\n",
    "                if 0.2 <= position <= 0.8:\n",
    "                    score += 1\n",
    "        \n",
    "        # 확장된 법률 용어 포함 여부\n",
    "        legal_terms = [\n",
    "            \"판시\", \"판결\", \"법리\", \"해석\", \"적용\", \"요건\", \"효과\", \"정당\", \"위법\", \"책임\",\n",
    "            \"대법원\", \"판례\", \"법원\", \"결정\", \"원심\", \"상고\", \"청구\", \"기각\", \"구성요건\",\n",
    "            \"피고인\", \"원고\", \"법률\", \"양형\", \"해당\", \"인정\"\n",
    "        ]\n",
    "        \n",
    "        term_count = sum(1 for term in legal_terms if term in sentence)\n",
    "        score += min(term_count, 3)  # 최대 3점까지만 추가\n",
    "        \n",
    "        # 결론 표현 포함 시 높은 점수\n",
    "        conclusion_terms = [\"따라서\", \"그러므로\", \"결론적으로\", \"이유로\", \"판단한다\"]\n",
    "        for term in conclusion_terms:\n",
    "            if term in sentence:\n",
    "                score += 3\n",
    "                break\n",
    "        \n",
    "        # 위치 보너스 (더 정교함)\n",
    "        if i == 0:\n",
    "            score += 3  # 첫 문장 (사건 개요일 가능성 높음)\n",
    "        elif i == len(sentences) - 1:\n",
    "            score += 3  # 마지막 문장 (결론일 가능성 높음)\n",
    "        elif 0 < i <= 2:\n",
    "            score += 1  # 초반 문장\n",
    "        elif i >= len(sentences) - 3:\n",
    "            score += 1  # 후반 문장\n",
    "            \n",
    "        scored_sentences.append((sentence, score, i))\n",
    "    \n",
    "    # 상위 문장 선택 (더 많은 문장 포함)\n",
    "    top_count = max(5, min(len(sentences) // 3, 10))  # 전체의 1/3 또는 최소 5문장, 최대 10문장\n",
    "    \n",
    "    # 점수 기준 정렬 및 상위 문장 선택\n",
    "    top_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:top_count]\n",
    "    \n",
    "    # 원래 순서로 재정렬\n",
    "    ordered_sentences = sorted(top_sentences, key=lambda x: x[2])\n",
    "    \n",
    "    result = \" \".join([s for s, _, _ in ordered_sentences])\n",
    "    \n",
    "    # 결과가 너무 짧으면 더 많은 문장 포함\n",
    "    if len(result) < len(text) * 0.25:\n",
    "        top_count = min(len(sentences) // 2, 15)  # 더 많은 문장 선택\n",
    "        top_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)[:top_count]\n",
    "        ordered_sentences = sorted(top_sentences, key=lambda x: x[2])\n",
    "        result = \" \".join([s for s, _, _ in ordered_sentences])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def extract_legal_keywords(text):\n",
    "    \"\"\"질문에서 법률 관련 주요 키워드를 추출합니다.\"\"\"\n",
    "    # 불용어 정의 (확장)\n",
    "    stopwords = [\n",
    "        \"무엇\", \"어떤\", \"어떻게\", \"언제\", \"누구\", \"왜\", \"어디\", \"경우\", \"관하여\", \"대하여\", \n",
    "        \"은\", \"는\", \"이\", \"가\", \"을\", \"를\", \"에\", \"의\", \"와\", \"과\", \"로\", \"으로\",\n",
    "        \"있다\", \"없다\", \"경우\", \"때\", \"것\", \"등\", \"수\", \"그\", \"이\", \"저\", \"그렇게\",\n",
    "        \"그런\", \"이런\", \"저런\", \"하는\", \"다음\", \"또는\", \"또한\", \"그리고\", \"만약\", \"만일\"\n",
    "    ]\n",
    "    \n",
    "    # 주요 법률 용어 정의 (확장)\n",
    "    legal_terms = {\n",
    "        # 형법 기본 원칙\n",
    "        \"고의\": 3, \"과실\": 3, \"인과관계\": 3, \"위법성\": 3, \"책임\": 3, \n",
    "        \"구성요건\": 3, \"위법성조각사유\": 3, \"책임조각사유\": 3,\n",
    "        \n",
    "        # 정당화 사유\n",
    "        \"정당방위\": 3, \"긴급피난\": 3, \"자구행위\": 3, \"피해자동의\": 3, \"정당행위\": 3, \n",
    "        \"업무로인한행위\": 3, \"강요된행위\": 3,\n",
    "        \n",
    "        # 범죄의 실행 단계\n",
    "        \"미수\": 3, \"기수\": 3, \"예비\": 3, \"음모\": 3, \"중지\": 3, \"불능미수\": 3,\n",
    "        \n",
    "        # 공범 관련\n",
    "        \"공범\": 3, \"교사\": 3, \"방조\": 3, \"공동정범\": 3, \"간접정범\": 3, \"종범\": 3,\n",
    "        \n",
    "        # 형벌 관련\n",
    "        \"형\": 2, \"징역\": 2, \"벌금\": 2, \"집행유예\": 2, \"선고유예\": 2, \"누범\": 2,\n",
    "        \n",
    "        # 법이론\n",
    "        \"법익\": 2, \"작위\": 2, \"부작위\": 2, \"결과범\": 2, \"거동범\": 2, \"상당인과관계\": 2,\n",
    "        \n",
    "        # 기타 형법 용어\n",
    "        \"불법\": 2, \"과잉방위\": 2, \"우발적\": 2, \"착오\": 2, \"원인에서자유로운행위\": 2\n",
    "    }\n",
    "    \n",
    "    # 기본 키워드 추출 (2글자 이상)\n",
    "    words = re.findall(r'\\w{2,}', text)\n",
    "    keywords = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    # 인접한 단어들도 함께 고려 (복합 키워드)\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        if words[i] not in stopwords or words[i+1] not in stopwords:\n",
    "            bigram = words[i] + words[i+1]\n",
    "            if len(bigram) >= 4:  # 4글자 이상 복합어만 고려\n",
    "                bigrams.append(bigram)\n",
    "    \n",
    "    # 법률 용어 가중치 적용 및 동의어 추가\n",
    "    weighted_keywords = []\n",
    "    \n",
    "    # 동의어 매핑\n",
    "    synonyms = {\n",
    "        \"고의\": [\"범의\", \"의도적\", \"계획적\"],\n",
    "        \"과실\": [\"부주의\", \"태만\", \"소홀\"],\n",
    "        \"위법성\": [\"불법성\", \"위법\", \"불법\"],\n",
    "        \"책임\": [\"형사책임\", \"귀책\", \"비난가능성\"],\n",
    "        \"미수\": [\"미완성\", \"불성공\"],\n",
    "        \"정당방위\": [\"자기방어\", \"방어행위\"]\n",
    "    }\n",
    "    \n",
    "    for keyword in keywords + bigrams:\n",
    "        if keyword in legal_terms:\n",
    "            # 가중치만큼 반복 추가\n",
    "            weighted_keywords.extend([keyword] * legal_terms[keyword])\n",
    "            \n",
    "            # 동의어도 추가\n",
    "            if keyword in synonyms:\n",
    "                for synonym in synonyms[keyword]:\n",
    "                    weighted_keywords.append(synonym)\n",
    "        else:\n",
    "            weighted_keywords.append(keyword)\n",
    "    \n",
    "    # 키워드 빈도수 계산과 중요도 기반 필터링\n",
    "    counter = Counter(weighted_keywords)\n",
    "    min_count = 1 if len(counter) < 10 else 2  # 키워드가 적으면 모두 사용\n",
    "    \n",
    "    final_keywords = [k for k, v in counter.items() if v >= min_count]\n",
    "    \n",
    "    # 키워드가 너무 적으면 원래 키워드 반환\n",
    "    if len(final_keywords) < 3:\n",
    "        return weighted_keywords\n",
    "    \n",
    "    return final_keywords\n",
    "\n",
    "def optimize_context_construction(search_results, question):\n",
    "    \"\"\"검색 결과에서 질문에 최적화된 컨텍스트를 구성합니다.\"\"\"\n",
    "    # 1. 관련성에 따른 컨텍스트 재배열 (더 많은 결과 포함)\n",
    "    results_by_type = {\"Article\": [], \"Precedent\": []}\n",
    "    for result in search_results:\n",
    "        results_by_type[result[\"type\"]].append(result)\n",
    "    \n",
    "    # 2. 법조항 요약 및 핵심 추출 (더 많은 법조항 포함)\n",
    "    article_contexts = []\n",
    "    for article in results_by_type[\"Article\"][:5]:  # 상위 3개에서 5개로 증가\n",
    "        # 법조항 원문과 요약 모두 포함하여 정보 손실 방지\n",
    "        highlighted_text = highlight_relevant_parts(article[\"text\"], question)\n",
    "        \n",
    "        # 점수가 높은 법조항은 더 강조\n",
    "        if article.get(\"score\", 0) > 0.7:  # 높은 유사도 점수\n",
    "            article_contexts.append(f\"【중요 법조항: {article['id']}】\\n{highlighted_text}\")\n",
    "        else:\n",
    "            article_contexts.append(f\"【{article['id']}】\\n{highlighted_text}\")\n",
    "            \n",
    "        # 관련 키워드가 있으면 함께 표시\n",
    "        if article.get(\"related_keywords\") and len(article.get(\"related_keywords\")) > 0:\n",
    "            keywords_str = \", \".join(article.get(\"related_keywords\")[:5])\n",
    "            article_contexts[-1] += f\"\\n[관련 키워드: {keywords_str}]\"\n",
    "    \n",
    "    # 3. 판례 요약 및 핵심 추출 (더 많은 판례 포함)\n",
    "    precedent_contexts = []\n",
    "    for precedent in results_by_type[\"Precedent\"][:3]:  # 상위 2개에서 3개로 증가\n",
    "        # 판례 요약 처리\n",
    "        summary = summarize_precedent(precedent[\"text\"], question)\n",
    "        \n",
    "        # 판례명이 있으면 함께 표시\n",
    "        name_str = f\" - {precedent.get('name', '')}\" if precedent.get('name') else \"\"\n",
    "        precedent_contexts.append(f\"【판례 {precedent.get('id', '')}{name_str}】\\n{summary}\")\n",
    "        \n",
    "        # 참조 법조항이 있으면 함께 표시\n",
    "        if precedent.get(\"referenced_articles\") and len(precedent.get(\"referenced_articles\")) > 0:\n",
    "            refs = \", \".join(precedent.get(\"referenced_articles\")[:3])\n",
    "            precedent_contexts[-1] += f\"\\n[참조 법조항: {refs}]\"\n",
    "            \n",
    "        # 키워드가 있으면 함께 표시\n",
    "        if precedent.get(\"keywords\") and len(precedent.get(\"keywords\")) > 0:\n",
    "            keywords_str = \", \".join(precedent.get(\"keywords\")[:5])\n",
    "            precedent_contexts[-1] += f\"\\n[관련 키워드: {keywords_str}]\"\n",
    "    \n",
    "    # 4. 정보 밀도 최적화 (형법 특화 구조화)\n",
    "    optimized_context = \"\\n\\n\".join([\n",
    "        \"### 형법 관련 참고 자료 ###\",\n",
    "        \"## 관련 법조항:\",\n",
    "        \"\\n\\n\".join(article_contexts) if article_contexts else \"관련 법조항 정보가 없습니다.\",\n",
    "        \"## 관련 판례:\",\n",
    "        \"\\n\\n\".join(precedent_contexts) if precedent_contexts else \"관련 판례 정보가 없습니다.\",\n",
    "        \"### 참고사항: 형법 해석 시 구성요건-위법성-책임 순서로 판단하며, 법조항과 판례를 함께 고려하십시오. ###\"\n",
    "    ])\n",
    "    \n",
    "    return optimized_context\n",
    "\n",
    "def extract_answer_improved(text):\n",
    "    \"\"\"텍스트에서 A, B, C, D 중 하나를 정교한 방식으로 추출합니다.\"\"\"\n",
    "    # 정규표현식 패턴들 (확장 및 정교화)\n",
    "    patterns = [\n",
    "        # 직접 응답 패턴\n",
    "        r'^([A-D])$',\n",
    "        r'^답(?:변|안|)(?:은|): ?([A-D])',\n",
    "        r'정답(?:은|): ?([A-D])',\n",
    "        r'([A-D])(?:가|이|을|를) 선택',\n",
    "        r'([A-D])(?:가|이|이) 정답',\n",
    "        r'([A-D])(?:가|이|을|를) (?:고른다|고릅니다|고르겠습니다)',\n",
    "        \n",
    "        # 간접 응답 패턴\n",
    "        r'따라서 (?:정답은 |답은 |)([A-D])',\n",
    "        r'([A-D])(?:가|이|은|는) (?:가장 적절|가장 정확|옳은)',\n",
    "        \n",
    "        # 결론 문장 패턴 (확장)\n",
    "        r'(?:최종적으로|결론적으로|종합하면|따라서|분석 결과|이상의 이유로).{1,50}(?:정답은|답은|옳은 것은|맞는 것은) ?([A-D])',\n",
    "        r'(?:선택지|옵션) ?([A-D])(?:가|이|은|는) (?:정답|맞습니다|맞다|적절|적합|옳은|타당)',\n",
    "        r'정답은 선택지 ?([A-D])',\n",
    "        r'선택지 ?([A-D])(?:을|를)? ?(?:선택합니다|고릅니다|고르겠습니다|골라야 합니다)',\n",
    "        \n",
    "        # 비교 분석 패턴\n",
    "        r'(?:따라서|그러므로|그래서|이에).{0,30}([A-D])(?:이외|를 제외하고|빼고).{0,20}(?:모두|다른 선택지|다른 것)(?:는|은) (?:틀리|오답|부적절|타당하지 않)',\n",
    "        r'선택지 ([A-D])(?:만|이).{0,30}(?:정확|옳|적절|타당|맞)',\n",
    "        \n",
    "        # 기존 패턴들\n",
    "        r'^\\s*([A-D])\\s*$',  # 단일 문자 A, B, C, D\n",
    "        r'(?:정답은|answer is|choice is|선택지는|답은)\\s*([A-D])',  # \"정답은 A\" 등\n",
    "        r'(?:선택합니다|선택하겠습니다|선택해야 합니다)\\s*([A-D])',  # \"A를 선택합니다\"\n",
    "        r'([A-D])(?:가|이|을|를)?\\s*(?:정답|맞습니다|적절합니다|선택|적절)',  # \"A가 정답\" 등\n",
    "        r'([A-D])\\s*선택지',  # \"A 선택지\"\n",
    "        \n",
    "        # 부정 표현을 통한 정답 유추\n",
    "        r'(?:선택지|옵션) ([A-D])(?:을|를)? ?제외한.{1,20}(?:틀리|오답|부적절)',\n",
    "        r'([A-D])(?:을|를)? ?제외한.{1,20}(?:나머지|다른).{1,20}(?:틀리|오답|부적절)',\n",
    "    ]\n",
    "    \n",
    "    # 패턴 적용 (우선순위 순서로)\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "        if match:\n",
    "            return match.group(1).upper()  # 대문자로 정규화\n",
    "    \n",
    "    # 문장별 검색 (더 강화)\n",
    "    # 마지막 세 문장에 집중 (결론이 주로 마지막에 위치)\n",
    "    lines = text.split('\\n')\n",
    "    last_lines = lines[-3:] if len(lines) >= 3 else lines\n",
    "    \n",
    "    for line in last_lines:\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, line, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).upper()\n",
    "    \n",
    "    # 모든 문장 검색\n",
    "    for line in lines:\n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, line, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).upper()\n",
    "    \n",
    "    # 빈도 및 문맥 기반 접근 (개선)\n",
    "    options = ['A', 'B', 'C', 'D']\n",
    "    \n",
    "    # 더 정교한 문맥 패턴 검색\n",
    "    context_patterns = {\n",
    "        'A': [r'A\\s*(?:만|이|가)\\s*(?:옳|정답|맞|적절)', r'선택지\\s*A\\s*(?:가|이|은|는)\\s*(?:옳|정답|맞|적절)'],\n",
    "        'B': [r'B\\s*(?:만|이|가)\\s*(?:옳|정답|맞|적절)', r'선택지\\s*B\\s*(?:가|이|은|는)\\s*(?:옳|정답|맞|적절)'],\n",
    "        'C': [r'C\\s*(?:만|이|가)\\s*(?:옳|정답|맞|적절)', r'선택지\\s*C\\s*(?:가|이|은|는)\\s*(?:옳|정답|맞|적절)'],\n",
    "        'D': [r'D\\s*(?:만|이|가)\\s*(?:옳|정답|맞|적절)', r'선택지\\s*D\\s*(?:가|이|은|는)\\s*(?:옳|정답|맞|적절)']\n",
    "    }\n",
    "    \n",
    "    for option, patterns in context_patterns.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                return option\n",
    "    \n",
    "    # 빈도 기반 접근 (확장)\n",
    "    option_counts = {option: 0 for option in options}\n",
    "    \n",
    "    # 다양한 형태의 언급 패턴 고려\n",
    "    for option in options:\n",
    "        option_counts[option] += text.count(f\"선택지 {option}\")\n",
    "        option_counts[option] += text.count(f\"{option}.\")\n",
    "        option_counts[option] += text.count(f\"{option}이 \")\n",
    "        option_counts[option] += text.count(f\"{option}가 \")\n",
    "        option_counts[option] += text.count(f\"{option}은 \")\n",
    "        option_counts[option] += text.count(f\"{option}는 \")\n",
    "        option_counts[option] += text.count(f\"{option}을 \")\n",
    "        option_counts[option] += text.count(f\"{option}를 \")\n",
    "        \n",
    "        # 부정 표현은 빼기\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}이 아닌\")\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}가 아닌\")\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}은 틀린\")\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}는 틀린\")\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}은 부적절\")\n",
    "        option_counts[option] -= 2 * text.count(f\"{option}는 부적절\")\n",
    "    \n",
    "    if any(count > 0 for count in option_counts.values()):\n",
    "        return max(option_counts.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # 단순 문자 존재 확인 (최후의 수단)\n",
    "    option_simple_counts = {option: text.count(option) for option in options}\n",
    "    if any(count > 0 for count in option_simple_counts.values()):\n",
    "        return max(option_simple_counts.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # 응답에서 아무 것도 찾지 못한 경우\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀12: Criminal-Law 평가를 위한 Batch API 사용\n",
    "\n",
    "# CSV 파일 로드\n",
    "df = pd.read_csv('./dataset/Criminal-Law-test.csv')\n",
    "print(f\"Loaded {len(df)} questions from CSV file\")\n",
    "\n",
    "# Neo4j 드라이버 다시 연결\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "print(\"Connected to Neo4j\")\n",
    "\n",
    "# 결과 디렉토리 생성\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 모든 질문에 대해 RAG 검색 실행\n",
    "print(\"Performing RAG search for all questions...\")\n",
    "retrieved_contexts = {}\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Searching contexts\"):\n",
    "    question = row['question']\n",
    "    try:\n",
    "        # RAG 검색으로 문맥 가져오기\n",
    "        contexts = graph_enhanced_rag(driver, question, embedding_model, top_k=8)\n",
    "        retrieved_contexts[idx] = contexts\n",
    "    except Exception as e:\n",
    "        print(f\"Error in RAG search for question {idx}: {e}\")\n",
    "        retrieved_contexts[idx] = []\n",
    "\n",
    "print(f\"Completed RAG search for {len(retrieved_contexts)} questions\")\n",
    "\n",
    "# Batch API 요청 준비\n",
    "# Batch API 요청 준비 (수정된 부분)\n",
    "batch_requests = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing batch requests\"):\n",
    "    question = row['question']\n",
    "    options = {\n",
    "        'A': row['A'],\n",
    "        'B': row['B'], \n",
    "        'C': row['C'],\n",
    "        'D': row['D']\n",
    "    }\n",
    "    \n",
    "    # 검색된 문맥 가져오기\n",
    "    contexts = retrieved_contexts.get(idx, [])\n",
    "    \n",
    "    # 최적화된 컨텍스트 구성 (변경된 부분)\n",
    "    if contexts:\n",
    "        context_str = optimize_context_construction(contexts, question)\n",
    "    else:\n",
    "        context_str = \"관련 문맥 정보가 없습니다.\"\n",
    "    \n",
    "    # 프롬프트 작성 (기존 단계적 추론 부분 유지)\n",
    "    prompt = f\"\"\"다음은 한국 형법에 관한 객관식 문제입니다. 제공된 문맥 정보를 참고하여 가장 적절한 답변을 선택하세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "선택지:\n",
    "A. {options['A']}\n",
    "B. {options['B']}\n",
    "C. {options['C']}\n",
    "D. {options['D']}\n",
    "\n",
    "관련 문맥 정보:\n",
    "{context_str}\n",
    "\n",
    "답변 단계:\n",
    "1) 문제의 핵심 형법 쟁점 파악: 구성요건, 위법성, 책임 중 어떤 단계의 문제인지 분석\n",
    "2) 관련 법조항 적용: 제시된 법조항이 문제에 어떻게 적용되는지 분석\n",
    "3) 판례 원칙 적용: 유사한 판례가 확립한 법리를 문제에 적용\n",
    "4) 각 선택지 법적 분석: 각 선택지가 법조항과 판례에 비추어 왜 맞는지 또는 틀린지 분석\n",
    "5) 최종 선택: 가장 정확한 선택지 선택\n",
    "\n",
    "전체 분석 후 최종 답변은 A, B, C, D 중 하나만 제시하세요.\n",
    "\"\"\"\n",
    "    \n",
    "    # Batch 요청 생성\n",
    "    request = {\n",
    "        \"custom_id\": f\"q_{idx}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"당신은 한국 형법 전문가입니다. 주어진 문맥을 기반으로 가장 적절한 답변을 선택하세요. 답변은 A, B, C, D 중 하나만 명확히 제시하세요.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    batch_requests.append(request)\n",
    "\n",
    "# JSONL 파일로 저장\n",
    "batch_file_path = f\"results/criminal_law_batch_input_{timestamp}.jsonl\"\n",
    "with open(batch_file_path, 'w', encoding='utf-8') as f:\n",
    "    for request in batch_requests:\n",
    "        f.write(json.dumps(request, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Saved {len(batch_requests)} batch requests to {batch_file_path}\")\n",
    "\n",
    "# OpenAI 클라이언트 초기화 및 Batch API 실행\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# 배치 파일 업로드\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(batch_file_path, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "print(f\"Uploaded batch file with ID: {batch_input_file_id}\")\n",
    "\n",
    "# 배치 작업 생성\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\"description\": \"Criminal Law benchmark evaluation\"}\n",
    ")\n",
    "batch_id = batch_job.id\n",
    "print(f\"Created batch job with ID: {batch_id}\")\n",
    "\n",
    "# 배치 작업 상태 확인 함수\n",
    "def check_batch_status(client, batch_id):\n",
    "    \"\"\"배치 작업의 상태를 확인합니다.\"\"\"\n",
    "    batch_status = client.batches.retrieve(batch_id)\n",
    "    return batch_status\n",
    "\n",
    "# 작업이 완료될 때까지 대기\n",
    "print(\"Waiting for batch job to complete...\")\n",
    "start_time = time.time()\n",
    "status = None\n",
    "\n",
    "while True:\n",
    "    status = check_batch_status(client, batch_id)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Current status: {status.status} (Elapsed: {elapsed_time:.2f}s)\")\n",
    "    \n",
    "    if status.status in ['completed', 'failed', 'cancelled', 'expired']:\n",
    "        break\n",
    "    \n",
    "    # 처음 10분은 30초마다, 이후에는 2분마다 체크\n",
    "    if elapsed_time < 600:  # 10분\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        time.sleep(120)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Batch job finished with status: {status.status} in {total_time:.2f} seconds\")\n",
    "\n",
    "# 작업이 성공적으로 완료된 경우 결과 처리\n",
    "if status.status == 'completed':\n",
    "    output_file_id = status.output_file_id\n",
    "    print(f\"Batch job completed successfully. Output file ID: {output_file_id}\")\n",
    "    \n",
    "    # 결과 파일 다운로드\n",
    "    file_response = client.files.content(output_file_id)\n",
    "    batch_results = []\n",
    "    \n",
    "    for line in file_response.text.split('\\n'):\n",
    "        if line.strip():\n",
    "            batch_results.append(json.loads(line))\n",
    "    \n",
    "    print(f\"Downloaded {len(batch_results)} results from the batch job\")\n",
    "    \n",
    "    # 결과 파일 저장 (요구사항대로)\n",
    "    output_file_path = f\"results/criminal_law_batch_output_{timestamp}.jsonl\"\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        for result in batch_results:\n",
    "            f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"Saved batch output to {output_file_path}\")\n",
    "    \n",
    "    # 정확도 평가 준비\n",
    "    def extract_answer(text):\n",
    "        return extract_answer_improved(text)\n",
    "    \n",
    "    # 정확도 평가\n",
    "    correct_count = 0\n",
    "    results_with_answers = []\n",
    "    \n",
    "    for result in batch_results:\n",
    "        custom_id = result['custom_id']\n",
    "        idx = int(custom_id.split('_')[1])\n",
    "        \n",
    "        if result.get('error') is not None:\n",
    "            print(f\"Error in result {custom_id}: {result['error']}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            response_text = result['response']['body']['choices'][0]['message']['content'].strip()\n",
    "            \n",
    "            # 응답에서 답변 추출 (A, B, C, D 중 하나)\n",
    "            answer = extract_answer(response_text)\n",
    "            \n",
    "            if answer is None:\n",
    "                print(f\"Could not extract answer from response for question {idx}: {response_text}\")\n",
    "                continue\n",
    "            \n",
    "            # 정답과 비교 (CSV에서는 1-indexed, 1=A, 2=B, 3=C, 4=D)\n",
    "            correct_answer = chr(64 + df.iloc[idx]['answer'])  # 1->A, 2->B, 3->C, 4->D\n",
    "            is_correct = (answer == correct_answer)\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "            \n",
    "            results_with_answers.append({\n",
    "                'question_id': idx,\n",
    "                'question': df.iloc[idx]['question'],\n",
    "                'predicted': answer,\n",
    "                'actual': correct_answer,\n",
    "                'is_correct': is_correct,\n",
    "                'response': response_text\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing result for question {idx}: {e}\")\n",
    "    \n",
    "    accuracy = correct_count / len(results_with_answers) if results_with_answers else 0\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({correct_count}/{len(results_with_answers)})\")\n",
    "    \n",
    "    # 결과를 CSV 파일로 저장\n",
    "    results_df = pd.DataFrame(results_with_answers)\n",
    "    results_file = f\"results/criminal_law_results_{timestamp}.csv\"\n",
    "    results_df.to_csv(results_file, index=False)\n",
    "    print(f\"Saved detailed results to {results_file}\")\n",
    "\n",
    "    # 결과 요약 정보 저장\n",
    "    summary = {\n",
    "        'timestamp': timestamp,\n",
    "        'total_questions': len(df),\n",
    "        'processed_questions': len(results_with_answers),\n",
    "        'correct_answers': correct_count,\n",
    "        'accuracy': accuracy,\n",
    "        'batch_processing_time_seconds': total_time,\n",
    "        'input_file': batch_file_path,\n",
    "        'output_file': output_file_path,\n",
    "        'results_file': results_file,\n",
    "        'batch_id': batch_id\n",
    "    }\n",
    "    \n",
    "    with open(f\"results/criminal_law_benchmark_summary_{timestamp}.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    print(f\"Benchmark evaluation completed. Final accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Batch job did not complete successfully. Final status: {status.status}\")\n",
    "    if hasattr(status, 'errors') and status.errors:\n",
    "        print(\"Errors:\")\n",
    "        for error in status.errors:\n",
    "            print(f\"  - {error}\")\n",
    "\n",
    "# 드라이버 연결 종료\n",
    "driver.close()\n",
    "print(\"Neo4j driver connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 13: 결과 분석 및 시각화\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "import plotly.io as pio\n",
    "\n",
    "# 기본 테마 설정\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "# 가장 최근 결과 파일 찾기\n",
    "import glob\n",
    "import os\n",
    "result_files = glob.glob(\"results/criminal_law_results_20250412_174738.csv\")\n",
    "latest_result_file = max(result_files, key=os.path.getctime)\n",
    "print(f\"분석할 결과 파일: {latest_result_file}\")\n",
    "\n",
    "# 결과 데이터 로드\n",
    "results_df = pd.read_csv(latest_result_file)\n",
    "print(f\"로드된 결과 수: {len(results_df)}\")\n",
    "\n",
    "# 요약 통계\n",
    "total_questions = len(results_df)\n",
    "correct_answers = results_df['is_correct'].sum()\n",
    "accuracy = correct_answers / total_questions\n",
    "\n",
    "print(\"\\n===== 벤치마크 결과 요약 =====\")\n",
    "print(f\"총 문제 수: {total_questions}\")\n",
    "print(f\"정답 수: {int(correct_answers)}\")\n",
    "print(f\"정확도: {accuracy:.4f} ({int(correct_answers)}/{total_questions})\")\n",
    "\n",
    "# 예측 분포 표시\n",
    "prediction_counts = results_df['predicted'].value_counts()\n",
    "print(\"\\n===== 예측 분포 =====\")\n",
    "for option, count in prediction_counts.items():\n",
    "    print(f\"옵션 {option}: {count}개 ({count/total_questions*100:.1f}%)\")\n",
    "\n",
    "# 실제 정답 분포 표시\n",
    "actual_counts = results_df['actual'].value_counts()\n",
    "print(\"\\n===== 실제 정답 분포 =====\")\n",
    "for option, count in actual_counts.items():\n",
    "    print(f\"옵션 {option}: {count}개 ({count/total_questions*100:.1f}%)\")\n",
    "\n",
    "# 시각화: 옵션 선택 분포 (예측 vs 실제)\n",
    "fig = go.Figure()\n",
    "options = sorted(list(set(prediction_counts.index) | set(actual_counts.index)))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=options,\n",
    "    y=[prediction_counts.get(option, 0) for option in options],\n",
    "    name='모델 예측',\n",
    "    marker_color='rgb(55, 83, 109)'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=options,\n",
    "    y=[actual_counts.get(option, 0) for option in options],\n",
    "    name='실제 정답',\n",
    "    marker_color='rgb(26, 118, 255)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='옵션 선택 분포 (예측 vs 실제)',\n",
    "    xaxis_title='옵션',\n",
    "    yaxis_title='문제 수',\n",
    "    barmode='group',\n",
    "    bargap=0.15,\n",
    "    bargroupgap=0.1,\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 시각화: 혼동 행렬(Confusion Matrix)\n",
    "conf_matrix_data = pd.crosstab(results_df['actual'], results_df['predicted']).values\n",
    "conf_matrix_norm = (conf_matrix_data.T / conf_matrix_data.sum(axis=1)).T  # 행별 정규화\n",
    "\n",
    "options = sorted(list(set(results_df['actual']) | set(results_df['predicted'])))\n",
    "conf_matrix_df = pd.DataFrame(0, index=options, columns=options)\n",
    "for actual in results_df['actual'].unique():\n",
    "    for predicted in results_df[results_df['actual'] == actual]['predicted'].unique():\n",
    "        count = len(results_df[(results_df['actual'] == actual) & (results_df['predicted'] == predicted)])\n",
    "        conf_matrix_df.loc[actual, predicted] = count\n",
    "\n",
    "# 비율로 변환\n",
    "conf_matrix_norm = conf_matrix_df.div(conf_matrix_df.sum(axis=1), axis=0)\n",
    "\n",
    "fig = px.imshow(\n",
    "    conf_matrix_norm,\n",
    "    labels=dict(x=\"예측\", y=\"실제\", color=\"비율\"),\n",
    "    x=options,\n",
    "    y=options,\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    text_auto='.2f'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='혼동 행렬 (Confusion Matrix)',\n",
    "    xaxis_title='예측',\n",
    "    yaxis_title='실제',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 정답률 파이 차트\n",
    "labels = ['정답', '오답']\n",
    "values = [correct_answers, total_questions - correct_answers]\n",
    "colors = ['rgb(46, 204, 113)', 'rgb(231, 76, 60)']\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=labels,\n",
    "    values=values,\n",
    "    hole=.4,\n",
    "    marker_colors=colors\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='정답률',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# 정확도가 높은 문제와 낮은 문제 살펴보기\n",
    "print(\"\\n===== 정답 예시 (5개) =====\")\n",
    "correct_examples = results_df[results_df['is_correct'] == True].head(5)\n",
    "for i, row in correct_examples.iterrows():\n",
    "    print(f\"문제 ID: {row['question_id']}\")\n",
    "    print(f\"질문: {row['question'][:100]}...\" if len(row['question']) > 100 else f\"질문: {row['question']}\")\n",
    "    print(f\"예측/정답: {row['predicted']}/{row['actual']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n===== 오답 예시 (5개) =====\")\n",
    "incorrect_examples = results_df[results_df['is_correct'] == False].head(5)\n",
    "for i, row in incorrect_examples.iterrows():\n",
    "    print(f\"문제 ID: {row['question_id']}\")\n",
    "    print(f\"질문: {row['question'][:100]}...\" if len(row['question']) > 100 else f\"질문: {row['question']}\")\n",
    "    print(f\"예측/정답: {row['predicted']}/{row['actual']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 요약 정보 박스 표시 (강조)\n",
    "summary_html = f\"\"\"\n",
    "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 5px; border-left: 5px solid #4e73df;\">\n",
    "    <h3 style=\"margin-top: 0;\">형법 벤치마크 평가 결과</h3>\n",
    "    <p><b>정확도:</b> {accuracy:.2%} ({int(correct_answers)}/{total_questions})</p>\n",
    "    <p><b>모델:</b> GPT-4o-mini</p>\n",
    "    <p><b>평가 방식:</b> 그래프 기반 RAG + Batch API</p>\n",
    "</div>\n",
    "\"\"\"\n",
    "display(HTML(summary_html))\n",
    "\n",
    "# 각 문제 유형별 정답률 분석 - 추가 CSV 파일 필요 시\n",
    "try:\n",
    "    # 원본 테스트 CSV가 있다면 카테고리별 분석 시도\n",
    "    original_test_df = pd.read_csv('./dataset/CriminalLawtest.csv')\n",
    "    if 'Category' in original_test_df.columns:\n",
    "        # 결과와 원본 테스트 데이터 병합\n",
    "        merged_df = pd.merge(results_df, original_test_df[['question', 'Category']], on='question', how='left')\n",
    "        category_accuracy = merged_df.groupby('Category')['is_correct'].mean().sort_values(ascending=False)\n",
    "        category_counts = merged_df.groupby('Category')['is_correct'].count()\n",
    "        category_correct = merged_df.groupby('Category')['is_correct'].sum()\n",
    "        \n",
    "        print(\"\\n===== 카테고리별 정확도 =====\")\n",
    "        \n",
    "        # 카테고리별 정확도 그래프\n",
    "        fig = px.bar(\n",
    "            x=category_accuracy.index,\n",
    "            y=category_accuracy.values,\n",
    "            color=category_accuracy.values,\n",
    "            color_continuous_scale='RdYlGn',\n",
    "            labels={'x': '카테고리', 'y': '정확도', 'color': '정확도'},\n",
    "            text=[f\"{v:.2f}\" for v in category_accuracy.values]\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='카테고리별 정확도',\n",
    "            xaxis_title='카테고리',\n",
    "            yaxis_title='정확도',\n",
    "            font=dict(size=14),\n",
    "            xaxis={'categoryorder': 'total descending'}\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "        # 표 형태로도 출력\n",
    "        for category, acc in category_accuracy.items():\n",
    "            correct = int(category_correct[category])\n",
    "            count = int(category_counts[category])\n",
    "            print(f\"{category}: {acc:.4f} ({correct}/{count})\")\n",
    "except Exception as e:\n",
    "    print(f\"카테고리별 분석을 수행할 수 없습니다: {e}\")\n",
    "\n",
    "# 예측 정확도 추세 - 문제 번호별\n",
    "results_df['bin'] = results_df['question_id'] // 20  # 20문제씩 그룹화\n",
    "bin_accuracy = results_df.groupby('bin')['is_correct'].mean()\n",
    "bin_labels = [f\"{i*20}-{(i+1)*20-1}\" for i in bin_accuracy.index]\n",
    "\n",
    "fig = px.line(\n",
    "    x=bin_labels,\n",
    "    y=bin_accuracy.values,\n",
    "    markers=True,\n",
    "    labels={'x': '문제 번호 구간', 'y': '정확도'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='문제 번호별 정확도 추세',\n",
    "    xaxis_title='문제 번호 구간',\n",
    "    yaxis_title='정확도',\n",
    "    font=dict(size=14)\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=accuracy, \n",
    "    line_dash=\"dash\", \n",
    "    line_color=\"red\",\n",
    "    annotation_text=f\"평균 정확도: {accuracy:.2f}\",\n",
    "    annotation_position=\"bottom right\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
